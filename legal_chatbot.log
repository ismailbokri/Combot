2025-04-09 23:44:32,050 - WARNING - Config file config.yaml not found, using defaults.
2025-04-09 23:44:32,094 - INFO - Use pytorch device_name: cuda
2025-04-09 23:44:32,094 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-09 23:44:38,722 - INFO - Rebuilding indexes due to updated data...
2025-04-09 23:44:42,002 - INFO - Parsed 1460 legal document chunks
2025-04-09 23:44:42,002 - INFO - Processing batch 1/183: chunks 0 to 7
2025-04-09 23:44:43,663 - INFO - Processing batch 2/183: chunks 8 to 15
2025-04-09 23:44:43,789 - INFO - Processing batch 3/183: chunks 16 to 23
2025-04-09 23:44:43,880 - INFO - Processing batch 4/183: chunks 24 to 31
2025-04-09 23:44:43,930 - INFO - Processing batch 5/183: chunks 32 to 39
2025-04-09 23:44:43,954 - INFO - Processing batch 6/183: chunks 40 to 47
2025-04-09 23:44:43,986 - INFO - Processing batch 7/183: chunks 48 to 55
2025-04-09 23:44:44,009 - INFO - Processing batch 8/183: chunks 56 to 63
2025-04-09 23:44:44,030 - INFO - Processing batch 9/183: chunks 64 to 71
2025-04-09 23:44:44,054 - INFO - Processing batch 10/183: chunks 72 to 79
2025-04-09 23:44:44,077 - INFO - Processing batch 11/183: chunks 80 to 87
2025-04-09 23:44:44,103 - INFO - Processing batch 12/183: chunks 88 to 95
2025-04-09 23:44:44,127 - INFO - Processing batch 13/183: chunks 96 to 103
2025-04-09 23:44:44,151 - INFO - Processing batch 14/183: chunks 104 to 111
2025-04-09 23:44:44,172 - INFO - Processing batch 15/183: chunks 112 to 119
2025-04-09 23:44:44,194 - INFO - Processing batch 16/183: chunks 120 to 127
2025-04-09 23:44:44,213 - INFO - Processing batch 17/183: chunks 128 to 135
2025-04-09 23:44:44,234 - INFO - Processing batch 18/183: chunks 136 to 143
2025-04-09 23:44:44,256 - INFO - Processing batch 19/183: chunks 144 to 151
2025-04-09 23:44:44,274 - INFO - Processing batch 20/183: chunks 152 to 159
2025-04-09 23:44:44,294 - INFO - Processing batch 21/183: chunks 160 to 167
2025-04-09 23:44:44,314 - INFO - Processing batch 22/183: chunks 168 to 175
2025-04-09 23:44:44,334 - INFO - Processing batch 23/183: chunks 176 to 183
2025-04-09 23:44:44,355 - INFO - Processing batch 24/183: chunks 184 to 191
2025-04-09 23:44:44,373 - INFO - Processing batch 25/183: chunks 192 to 199
2025-04-09 23:44:44,395 - INFO - Processing batch 26/183: chunks 200 to 207
2025-04-09 23:44:44,415 - INFO - Processing batch 27/183: chunks 208 to 215
2025-04-09 23:44:44,437 - INFO - Processing batch 28/183: chunks 216 to 223
2025-04-09 23:44:44,458 - INFO - Processing batch 29/183: chunks 224 to 231
2025-04-09 23:44:44,480 - INFO - Processing batch 30/183: chunks 232 to 239
2025-04-09 23:44:44,500 - INFO - Processing batch 31/183: chunks 240 to 247
2025-04-09 23:44:44,521 - INFO - Processing batch 32/183: chunks 248 to 255
2025-04-09 23:44:44,542 - INFO - Processing batch 33/183: chunks 256 to 263
2025-04-09 23:44:44,562 - INFO - Processing batch 34/183: chunks 264 to 271
2025-04-09 23:44:44,584 - INFO - Processing batch 35/183: chunks 272 to 279
2025-04-09 23:44:44,604 - INFO - Processing batch 36/183: chunks 280 to 287
2025-04-09 23:44:44,626 - INFO - Processing batch 37/183: chunks 288 to 295
2025-04-09 23:44:44,647 - INFO - Processing batch 38/183: chunks 296 to 303
2025-04-09 23:44:44,668 - INFO - Processing batch 39/183: chunks 304 to 311
2025-04-09 23:44:44,689 - INFO - Processing batch 40/183: chunks 312 to 319
2025-04-09 23:44:44,709 - INFO - Processing batch 41/183: chunks 320 to 327
2025-04-09 23:44:44,730 - INFO - Processing batch 42/183: chunks 328 to 335
2025-04-09 23:44:44,751 - INFO - Processing batch 43/183: chunks 336 to 343
2025-04-09 23:44:44,772 - INFO - Processing batch 44/183: chunks 344 to 351
2025-04-09 23:44:44,792 - INFO - Processing batch 45/183: chunks 352 to 359
2025-04-09 23:44:44,814 - INFO - Processing batch 46/183: chunks 360 to 367
2025-04-09 23:44:44,835 - INFO - Processing batch 47/183: chunks 368 to 375
2025-04-09 23:44:44,855 - INFO - Processing batch 48/183: chunks 376 to 383
2025-04-09 23:44:44,876 - INFO - Processing batch 49/183: chunks 384 to 391
2025-04-09 23:44:44,894 - INFO - Processing batch 50/183: chunks 392 to 399
2025-04-09 23:44:44,915 - INFO - Processing batch 51/183: chunks 400 to 407
2025-04-09 23:44:44,931 - INFO - Processing batch 52/183: chunks 408 to 415
2025-04-09 23:44:44,952 - INFO - Processing batch 53/183: chunks 416 to 423
2025-04-09 23:44:44,975 - INFO - Processing batch 54/183: chunks 424 to 431
2025-04-09 23:44:44,995 - INFO - Processing batch 55/183: chunks 432 to 439
2025-04-09 23:44:45,015 - INFO - Processing batch 56/183: chunks 440 to 447
2025-04-09 23:44:45,033 - INFO - Processing batch 57/183: chunks 448 to 455
2025-04-09 23:44:45,054 - INFO - Processing batch 58/183: chunks 456 to 463
2025-04-09 23:44:45,074 - INFO - Processing batch 59/183: chunks 464 to 471
2025-04-09 23:44:45,095 - INFO - Processing batch 60/183: chunks 472 to 479
2025-04-09 23:44:45,116 - INFO - Processing batch 61/183: chunks 480 to 487
2025-04-09 23:44:45,137 - INFO - Processing batch 62/183: chunks 488 to 495
2025-04-09 23:44:45,158 - INFO - Processing batch 63/183: chunks 496 to 503
2025-04-09 23:44:45,180 - INFO - Processing batch 64/183: chunks 504 to 511
2025-04-09 23:44:45,201 - INFO - Processing batch 65/183: chunks 512 to 519
2025-04-09 23:44:45,222 - INFO - Processing batch 66/183: chunks 520 to 527
2025-04-09 23:44:45,242 - INFO - Processing batch 67/183: chunks 528 to 535
2025-04-09 23:44:45,262 - INFO - Processing batch 68/183: chunks 536 to 543
2025-04-09 23:44:45,282 - INFO - Processing batch 69/183: chunks 544 to 551
2025-04-09 23:44:45,304 - INFO - Processing batch 70/183: chunks 552 to 559
2025-04-09 23:44:45,319 - INFO - Processing batch 71/183: chunks 560 to 567
2025-04-09 23:44:45,333 - INFO - Processing batch 72/183: chunks 568 to 575
2025-04-09 23:44:45,347 - INFO - Processing batch 73/183: chunks 576 to 583
2025-04-09 23:44:45,361 - INFO - Processing batch 74/183: chunks 584 to 591
2025-04-09 23:44:45,381 - INFO - Processing batch 75/183: chunks 592 to 599
2025-04-09 23:44:45,401 - INFO - Processing batch 76/183: chunks 600 to 607
2025-04-09 23:44:45,422 - INFO - Processing batch 77/183: chunks 608 to 615
2025-04-09 23:44:45,442 - INFO - Processing batch 78/183: chunks 616 to 623
2025-04-09 23:44:45,463 - INFO - Processing batch 79/183: chunks 624 to 631
2025-04-09 23:44:45,483 - INFO - Processing batch 80/183: chunks 632 to 639
2025-04-09 23:44:45,504 - INFO - Processing batch 81/183: chunks 640 to 647
2025-04-09 23:44:45,525 - INFO - Processing batch 82/183: chunks 648 to 655
2025-04-09 23:44:45,546 - INFO - Processing batch 83/183: chunks 656 to 663
2025-04-09 23:44:45,566 - INFO - Processing batch 84/183: chunks 664 to 671
2025-04-09 23:44:45,587 - INFO - Processing batch 85/183: chunks 672 to 679
2025-04-09 23:44:45,609 - INFO - Processing batch 86/183: chunks 680 to 687
2025-04-09 23:44:45,630 - INFO - Processing batch 87/183: chunks 688 to 695
2025-04-09 23:44:45,651 - INFO - Processing batch 88/183: chunks 696 to 703
2025-04-09 23:44:45,671 - INFO - Processing batch 89/183: chunks 704 to 711
2025-04-09 23:44:45,692 - INFO - Processing batch 90/183: chunks 712 to 719
2025-04-09 23:44:45,713 - INFO - Processing batch 91/183: chunks 720 to 727
2025-04-09 23:44:45,734 - INFO - Processing batch 92/183: chunks 728 to 735
2025-04-09 23:44:45,752 - INFO - Processing batch 93/183: chunks 736 to 743
2025-04-09 23:44:45,773 - INFO - Processing batch 94/183: chunks 744 to 751
2025-04-09 23:44:45,794 - INFO - Processing batch 95/183: chunks 752 to 759
2025-04-09 23:44:45,814 - INFO - Processing batch 96/183: chunks 760 to 767
2025-04-09 23:44:45,837 - INFO - Processing batch 97/183: chunks 768 to 775
2025-04-09 23:44:45,856 - INFO - Processing batch 98/183: chunks 776 to 783
2025-04-09 23:44:45,876 - INFO - Processing batch 99/183: chunks 784 to 791
2025-04-09 23:44:45,896 - INFO - Processing batch 100/183: chunks 792 to 799
2025-04-09 23:44:45,917 - INFO - Processing batch 101/183: chunks 800 to 807
2025-04-09 23:44:45,935 - INFO - Processing batch 102/183: chunks 808 to 815
2025-04-09 23:44:45,955 - INFO - Processing batch 103/183: chunks 816 to 823
2025-04-09 23:44:45,976 - INFO - Processing batch 104/183: chunks 824 to 831
2025-04-09 23:44:45,997 - INFO - Processing batch 105/183: chunks 832 to 839
2025-04-09 23:44:46,018 - INFO - Processing batch 106/183: chunks 840 to 847
2025-04-09 23:44:46,037 - INFO - Processing batch 107/183: chunks 848 to 855
2025-04-09 23:44:46,058 - INFO - Processing batch 108/183: chunks 856 to 863
2025-04-09 23:44:46,079 - INFO - Processing batch 109/183: chunks 864 to 871
2025-04-09 23:44:46,100 - INFO - Processing batch 110/183: chunks 872 to 879
2025-04-09 23:44:46,121 - INFO - Processing batch 111/183: chunks 880 to 887
2025-04-09 23:44:46,142 - INFO - Processing batch 112/183: chunks 888 to 895
2025-04-09 23:44:46,163 - INFO - Processing batch 113/183: chunks 896 to 903
2025-04-09 23:44:46,184 - INFO - Processing batch 114/183: chunks 904 to 911
2025-04-09 23:44:46,204 - INFO - Processing batch 115/183: chunks 912 to 919
2025-04-09 23:44:46,225 - INFO - Processing batch 116/183: chunks 920 to 927
2025-04-09 23:44:46,247 - INFO - Processing batch 117/183: chunks 928 to 935
2025-04-09 23:44:46,267 - INFO - Processing batch 118/183: chunks 936 to 943
2025-04-09 23:44:46,288 - INFO - Processing batch 119/183: chunks 944 to 951
2025-04-09 23:44:46,308 - INFO - Processing batch 120/183: chunks 952 to 959
2025-04-09 23:44:46,330 - INFO - Processing batch 121/183: chunks 960 to 967
2025-04-09 23:44:46,351 - INFO - Processing batch 122/183: chunks 968 to 975
2025-04-09 23:44:46,371 - INFO - Processing batch 123/183: chunks 976 to 983
2025-04-09 23:44:46,392 - INFO - Processing batch 124/183: chunks 984 to 991
2025-04-09 23:44:46,413 - INFO - Processing batch 125/183: chunks 992 to 999
2025-04-09 23:44:46,433 - INFO - Processing batch 126/183: chunks 1000 to 1007
2025-04-09 23:44:46,451 - INFO - Processing batch 127/183: chunks 1008 to 1015
2025-04-09 23:44:46,472 - INFO - Processing batch 128/183: chunks 1016 to 1023
2025-04-09 23:44:46,490 - INFO - Processing batch 129/183: chunks 1024 to 1031
2025-04-09 23:44:46,511 - INFO - Processing batch 130/183: chunks 1032 to 1039
2025-04-09 23:44:46,531 - INFO - Processing batch 131/183: chunks 1040 to 1047
2025-04-09 23:44:46,551 - INFO - Processing batch 132/183: chunks 1048 to 1055
2025-04-09 23:44:46,573 - INFO - Processing batch 133/183: chunks 1056 to 1063
2025-04-09 23:44:46,593 - INFO - Processing batch 134/183: chunks 1064 to 1071
2025-04-09 23:44:46,615 - INFO - Processing batch 135/183: chunks 1072 to 1079
2025-04-09 23:44:46,636 - INFO - Processing batch 136/183: chunks 1080 to 1087
2025-04-09 23:44:46,657 - INFO - Processing batch 137/183: chunks 1088 to 1095
2025-04-09 23:44:46,677 - INFO - Processing batch 138/183: chunks 1096 to 1103
2025-04-09 23:44:46,698 - INFO - Processing batch 139/183: chunks 1104 to 1111
2025-04-09 23:44:46,714 - INFO - Processing batch 140/183: chunks 1112 to 1119
2025-04-09 23:44:46,734 - INFO - Processing batch 141/183: chunks 1120 to 1127
2025-04-09 23:44:46,754 - INFO - Processing batch 142/183: chunks 1128 to 1135
2025-04-09 23:44:46,775 - INFO - Processing batch 143/183: chunks 1136 to 1143
2025-04-09 23:44:46,796 - INFO - Processing batch 144/183: chunks 1144 to 1151
2025-04-09 23:44:46,817 - INFO - Processing batch 145/183: chunks 1152 to 1159
2025-04-09 23:44:46,837 - INFO - Processing batch 146/183: chunks 1160 to 1167
2025-04-09 23:44:46,859 - INFO - Processing batch 147/183: chunks 1168 to 1175
2025-04-09 23:44:46,880 - INFO - Processing batch 148/183: chunks 1176 to 1183
2025-04-09 23:44:46,901 - INFO - Processing batch 149/183: chunks 1184 to 1191
2025-04-09 23:44:46,922 - INFO - Processing batch 150/183: chunks 1192 to 1199
2025-04-09 23:44:46,943 - INFO - Processing batch 151/183: chunks 1200 to 1207
2025-04-09 23:44:46,963 - INFO - Processing batch 152/183: chunks 1208 to 1215
2025-04-09 23:44:46,985 - INFO - Processing batch 153/183: chunks 1216 to 1223
2025-04-09 23:44:47,006 - INFO - Processing batch 154/183: chunks 1224 to 1231
2025-04-09 23:44:47,028 - INFO - Processing batch 155/183: chunks 1232 to 1239
2025-04-09 23:44:47,049 - INFO - Processing batch 156/183: chunks 1240 to 1247
2025-04-09 23:44:47,070 - INFO - Processing batch 157/183: chunks 1248 to 1255
2025-04-09 23:44:47,091 - INFO - Processing batch 158/183: chunks 1256 to 1263
2025-04-09 23:44:47,112 - INFO - Processing batch 159/183: chunks 1264 to 1271
2025-04-09 23:44:47,137 - INFO - Processing batch 160/183: chunks 1272 to 1279
2025-04-09 23:44:47,157 - INFO - Processing batch 161/183: chunks 1280 to 1287
2025-04-09 23:44:47,178 - INFO - Processing batch 162/183: chunks 1288 to 1295
2025-04-09 23:44:47,201 - INFO - Processing batch 163/183: chunks 1296 to 1303
2025-04-09 23:44:47,220 - INFO - Processing batch 164/183: chunks 1304 to 1311
2025-04-09 23:44:47,242 - INFO - Processing batch 165/183: chunks 1312 to 1319
2025-04-09 23:44:47,262 - INFO - Processing batch 166/183: chunks 1320 to 1327
2025-04-09 23:44:47,284 - INFO - Processing batch 167/183: chunks 1328 to 1335
2025-04-09 23:44:47,304 - INFO - Processing batch 168/183: chunks 1336 to 1343
2025-04-09 23:44:47,326 - INFO - Processing batch 169/183: chunks 1344 to 1351
2025-04-09 23:44:47,347 - INFO - Processing batch 170/183: chunks 1352 to 1359
2025-04-09 23:44:47,369 - INFO - Processing batch 171/183: chunks 1360 to 1367
2025-04-09 23:44:47,388 - INFO - Processing batch 172/183: chunks 1368 to 1375
2025-04-09 23:44:47,410 - INFO - Processing batch 173/183: chunks 1376 to 1383
2025-04-09 23:44:47,430 - INFO - Processing batch 174/183: chunks 1384 to 1391
2025-04-09 23:44:47,452 - INFO - Processing batch 175/183: chunks 1392 to 1399
2025-04-09 23:44:47,474 - INFO - Processing batch 176/183: chunks 1400 to 1407
2025-04-09 23:44:47,496 - INFO - Processing batch 177/183: chunks 1408 to 1415
2025-04-09 23:44:47,514 - INFO - Processing batch 178/183: chunks 1416 to 1423
2025-04-09 23:44:47,535 - INFO - Processing batch 179/183: chunks 1424 to 1431
2025-04-09 23:44:47,556 - INFO - Processing batch 180/183: chunks 1432 to 1439
2025-04-09 23:44:47,578 - INFO - Processing batch 181/183: chunks 1440 to 1447
2025-04-09 23:44:47,598 - INFO - Processing batch 182/183: chunks 1448 to 1455
2025-04-09 23:44:47,616 - INFO - Processing batch 183/183: chunks 1456 to 1459
2025-04-09 23:44:47,638 - INFO - Saving indexes to disk...
2025-04-09 23:44:47,715 - INFO - Successfully built and saved all indexes
2025-04-09 23:44:47,737 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-09 23:44:47,737 - INFO - [33mPress CTRL+C to quit[0m
2025-04-09 23:45:01,994 - INFO - 127.0.0.1 - - [09/Apr/2025 23:45:01] "GET / HTTP/1.1" 200 -
2025-04-09 23:45:02,083 - INFO - 127.0.0.1 - - [09/Apr/2025 23:45:02] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-09 23:45:02,257 - INFO - 127.0.0.1 - - [09/Apr/2025 23:45:02] "GET /get_conversations HTTP/1.1" 200 -
2025-04-09 23:50:22,043 - INFO - 127.0.0.1 - - [09/Apr/2025 23:50:22] "GET / HTTP/1.1" 200 -
2025-04-09 23:50:22,127 - INFO - 127.0.0.1 - - [09/Apr/2025 23:50:22] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-09 23:50:22,304 - INFO - 127.0.0.1 - - [09/Apr/2025 23:50:22] "GET /get_conversations HTTP/1.1" 200 -
2025-04-09 23:50:35,610 - WARNING - Config file config.yaml not found, using defaults.
2025-04-09 23:50:35,643 - INFO - Use pytorch device_name: cuda
2025-04-09 23:50:35,644 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-09 23:50:41,195 - INFO - Loading pre-built indexes...
2025-04-09 23:50:44,347 - INFO - Loaded 1460 legal document chunks
2025-04-09 23:50:44,369 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-09 23:50:44,369 - INFO - [33mPress CTRL+C to quit[0m
2025-04-09 23:50:49,511 - INFO - 127.0.0.1 - - [09/Apr/2025 23:50:49] "GET / HTTP/1.1" 200 -
2025-04-09 23:50:49,612 - INFO - 127.0.0.1 - - [09/Apr/2025 23:50:49] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-09 23:50:49,715 - INFO - 127.0.0.1 - - [09/Apr/2025 23:50:49] "GET /get_conversations HTTP/1.1" 200 -
2025-04-09 23:51:03,603 - ERROR - Error generating title: Groq API key is not set in the configuration
2025-04-09 23:51:03,613 - INFO - Processing query: 'What are the requirements for starting a business in Tunisia?' for conversation 1
2025-04-09 23:51:03,624 - INFO - Query received: What are the requirements for starting a business in Tunisia?
2025-04-09 23:51:05,197 - INFO - Search scores:
Document 473 (chunk: chunk_446_sub_1): score=0.6039, confidence=100.00%
Document 701 (chunk: chunk_669): score=0.5000, confidence=82.80%
Document 269 (chunk: chunk_256): score=0.4578, confidence=75.81%
Document 877 (chunk: chunk_841): score=0.4505, confidence=74.60%
Document 472 (chunk: chunk_446): score=0.4452, confidence=73.72%
2025-04-09 23:51:05,201 - INFO - Sending request to Groq API with model: deepseek-r1:1.5b
2025-04-09 23:51:05,201 - ERROR - Error generating answer: Groq API key is not set in the configuration
2025-04-09 23:51:05,202 - INFO - Agent workflow completed in 1.60s
2025-04-09 23:51:05,210 - INFO - Request processed in 1.61s (thinking: 0.00s)
2025-04-09 23:51:05,211 - INFO - 127.0.0.1 - - [09/Apr/2025 23:51:05] "POST /ask HTTP/1.1" 200 -
2025-04-09 23:52:17,566 - INFO - 127.0.0.1 - - [09/Apr/2025 23:52:17] "GET / HTTP/1.1" 200 -
2025-04-09 23:52:17,657 - INFO - 127.0.0.1 - - [09/Apr/2025 23:52:17] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-09 23:52:17,832 - INFO - 127.0.0.1 - - [09/Apr/2025 23:52:17] "GET /get_conversations HTTP/1.1" 200 -
2025-04-09 23:52:29,237 - INFO - 127.0.0.1 - - [09/Apr/2025 23:52:29] "GET /get_conversation/1 HTTP/1.1" 200 -
2025-04-09 23:55:30,832 - INFO - 127.0.0.1 - - [09/Apr/2025 23:55:30] "GET / HTTP/1.1" 200 -
2025-04-09 23:55:30,907 - INFO - 127.0.0.1 - - [09/Apr/2025 23:55:30] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-09 23:55:31,099 - INFO - 127.0.0.1 - - [09/Apr/2025 23:55:31] "GET /get_conversations HTTP/1.1" 200 -
2025-04-09 23:55:36,044 - ERROR - Error generating title: Groq API key is not set in the configuration
2025-04-09 23:55:36,053 - INFO - Processing query: 'What are my rights as an employee under Tunisian labor law?' for conversation 2
2025-04-09 23:55:36,055 - INFO - Query received: What are my rights as an employee under Tunisian labor law?
2025-04-09 23:55:36,664 - INFO - Search scores:
Document 230 (chunk: chunk_219): score=0.5000, confidence=100.00%
Document 206 (chunk: chunk_195): score=0.4609, confidence=92.17%
Document 1397 (chunk: chunk_1340): score=0.4461, confidence=89.21%
Document 872 (chunk: chunk_836): score=0.3726, confidence=74.53%
Document 907 (chunk: chunk_869): score=0.3622, confidence=72.43%
2025-04-09 23:55:36,668 - INFO - Sending request to Groq API with model: deepseek-r1:1.5b
2025-04-09 23:55:36,668 - ERROR - Error generating answer: Groq API key is not set in the configuration
2025-04-09 23:55:36,668 - INFO - Agent workflow completed in 0.62s
2025-04-09 23:55:36,678 - INFO - Request processed in 0.63s (thinking: 0.00s)
2025-04-09 23:55:36,678 - INFO - 127.0.0.1 - - [09/Apr/2025 23:55:36] "POST /ask HTTP/1.1" 200 -
2025-04-09 23:57:05,274 - INFO - Processing query: 'Quels sont les éléments nécessaires pour la validité d’une obligation née d’une volonté ?' for conversation 2
2025-04-09 23:57:05,275 - INFO - Query received: Quels sont les éléments nécessaires pour la validité d’une obligation née d’une volonté ?
2025-04-09 23:57:05,308 - INFO - Search scores:
Document 1 (chunk: chunk_1): score=0.6817, confidence=100.00%
Document 343 (chunk: chunk_324): score=0.2843, confidence=41.71%
Document 22 (chunk: chunk_22): score=0.2688, confidence=39.44%
Document 745 (chunk: chunk_713): score=0.2111, confidence=30.97%
Document 267 (chunk: chunk_254): score=0.2104, confidence=30.87%
2025-04-09 23:57:05,309 - INFO - Sending request to Groq API with model: deepseek-r1:1.5b
2025-04-09 23:57:05,309 - ERROR - Error generating answer: Groq API key is not set in the configuration
2025-04-09 23:57:05,311 - INFO - Agent workflow completed in 0.04s
2025-04-09 23:57:05,317 - INFO - Request processed in 0.05s (thinking: 0.00s)
2025-04-09 23:57:05,317 - INFO - 127.0.0.1 - - [09/Apr/2025 23:57:05] "POST /ask HTTP/1.1" 200 -
2025-04-09 23:57:46,049 - INFO - Processing query: 'Une offre envoyée sans délai doit-elle être acceptée immédiatement ?' for conversation 2
2025-04-09 23:57:46,050 - INFO - Query received: Une offre envoyée sans délai doit-elle être acceptée immédiatement ?
2025-04-09 23:57:46,080 - INFO - Search scores:
Document 35 (chunk: chunk_35): score=0.6339, confidence=100.00%
Document 26 (chunk: chunk_26): score=0.6320, confidence=99.71%
Document 34 (chunk: chunk_34): score=0.5589, confidence=88.16%
Document 33 (chunk: chunk_33): score=0.5008, confidence=79.01%
Document 32 (chunk: chunk_32): score=0.4765, confidence=75.18%
2025-04-09 23:57:46,083 - INFO - Sending request to Groq API with model: deepseek-r1:1.5b
2025-04-09 23:57:46,083 - ERROR - Error generating answer: Groq API key is not set in the configuration
2025-04-09 23:57:46,083 - INFO - Agent workflow completed in 0.04s
2025-04-09 23:57:46,090 - INFO - Request processed in 0.05s (thinking: 0.00s)
2025-04-09 23:57:46,090 - INFO - 127.0.0.1 - - [09/Apr/2025 23:57:46] "POST /ask HTTP/1.1" 200 -
2025-04-09 23:58:41,847 - INFO - Processing query: 'Quelle est la différence entre condition suspensive et résolutoire ?' for conversation 2
2025-04-09 23:58:41,848 - INFO - Query received: Quelle est la différence entre condition suspensive et résolutoire ?
2025-04-09 23:58:41,880 - INFO - Search scores:
Document 151 (chunk: chunk_140): score=0.6434, confidence=100.00%
Document 383 (chunk: chunk_364): score=0.5776, confidence=89.77%
Document 134 (chunk: chunk_125): score=0.4678, confidence=72.70%
Document 139 (chunk: chunk_130): score=0.4013, confidence=62.37%
Document 713 (chunk: chunk_681): score=0.3049, confidence=47.39%
2025-04-09 23:58:41,883 - INFO - Sending request to Groq API with model: deepseek-r1:1.5b
2025-04-09 23:58:41,883 - ERROR - Error generating answer: Groq API key is not set in the configuration
2025-04-09 23:58:41,883 - INFO - Agent workflow completed in 0.04s
2025-04-09 23:58:41,890 - INFO - Request processed in 0.05s (thinking: 0.00s)
2025-04-09 23:58:41,891 - INFO - 127.0.0.1 - - [09/Apr/2025 23:58:41] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:00:58,547 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:00:58,572 - INFO - Use pytorch device_name: cuda
2025-04-10 00:00:58,572 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:01:03,467 - INFO - Loading pre-built indexes...
2025-04-10 00:01:06,512 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:01:06,531 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:01:06,531 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:01:12,327 - INFO - 127.0.0.1 - - [10/Apr/2025 00:01:12] "GET / HTTP/1.1" 200 -
2025-04-10 00:01:12,441 - INFO - 127.0.0.1 - - [10/Apr/2025 00:01:12] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:01:12,580 - INFO - 127.0.0.1 - - [10/Apr/2025 00:01:12] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:01:15,794 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:01:16,313 - INFO - Token usage: prompt=106, completion=53, total=159
2025-04-10 00:01:16,322 - INFO - Processing query: 'Quelle est la différence entre condition suspensive et résolutoire ?' for conversation 3
2025-04-10 00:01:16,328 - INFO - Query received: Quelle est la différence entre condition suspensive et résolutoire ?
2025-04-10 00:01:17,376 - INFO - Search scores:
Document 151 (chunk: chunk_140): score=0.6434, confidence=100.00%
Document 383 (chunk: chunk_364): score=0.5776, confidence=89.77%
Document 134 (chunk: chunk_125): score=0.4678, confidence=72.70%
Document 139 (chunk: chunk_130): score=0.4013, confidence=62.37%
Document 713 (chunk: chunk_681): score=0.3049, confidence=47.39%
2025-04-10 00:01:17,379 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:01:17,380 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:01:21,644 - INFO - Token usage: prompt=1314, completion=980, total=2294
2025-04-10 00:01:21,647 - INFO - Agent workflow completed in 5.85s
2025-04-10 00:01:21,655 - INFO - Request processed in 5.86s (thinking: 4.27s)
2025-04-10 00:01:21,656 - INFO - 127.0.0.1 - - [10/Apr/2025 00:01:21] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:09:13,370 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:09:13,406 - INFO - Use pytorch device_name: cuda
2025-04-10 00:09:13,406 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:09:18,946 - INFO - Loading pre-built indexes...
2025-04-10 00:09:22,071 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:09:22,084 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:09:22,085 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:09:27,746 - INFO - 127.0.0.1 - - [10/Apr/2025 00:09:27] "GET / HTTP/1.1" 200 -
2025-04-10 00:09:27,831 - INFO - 127.0.0.1 - - [10/Apr/2025 00:09:27] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:09:27,972 - INFO - 127.0.0.1 - - [10/Apr/2025 00:09:27] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:09:30,789 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:09:31,327 - INFO - Token usage: prompt=102, completion=26, total=128
2025-04-10 00:09:31,337 - INFO - Processing query: 'Que dit la loi sur l'enrichissement sans cause ?' for conversation 4
2025-04-10 00:09:31,343 - INFO - Query received: Que dit la loi sur l'enrichissement sans cause ?
2025-04-10 00:09:32,369 - INFO - Search scores:
Document 66 (chunk: chunk_66): score=0.6333, confidence=100.00%
Document 1151 (chunk: chunk_1100): score=0.6046, confidence=95.46%
Document 81 (chunk: chunk_81): score=0.4715, confidence=74.45%
Document 70 (chunk: chunk_70): score=0.4336, confidence=68.46%
Document 1400 (chunk: chunk_1343): score=0.3731, confidence=58.92%
2025-04-10 00:09:32,374 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:09:32,374 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:09:36,022 - INFO - Token usage: prompt=1072, completion=854, total=1926
2025-04-10 00:09:36,025 - INFO - Agent workflow completed in 5.24s
2025-04-10 00:09:36,033 - INFO - Request processed in 5.24s (thinking: 3.65s)
2025-04-10 00:09:36,033 - INFO - 127.0.0.1 - - [10/Apr/2025 00:09:36] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:10:25,536 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:10:25,575 - INFO - Use pytorch device_name: cuda
2025-04-10 00:10:25,575 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:10:30,350 - INFO - Loading pre-built indexes...
2025-04-10 00:10:33,405 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:10:33,417 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:10:33,417 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:10:35,410 - INFO - 127.0.0.1 - - [10/Apr/2025 00:10:35] "GET / HTTP/1.1" 200 -
2025-04-10 00:10:35,493 - INFO - 127.0.0.1 - - [10/Apr/2025 00:10:35] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:10:35,643 - INFO - 127.0.0.1 - - [10/Apr/2025 00:10:35] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:10:43,796 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:10:44,314 - INFO - Token usage: prompt=102, completion=35, total=137
2025-04-10 00:10:44,323 - INFO - Processing query: 'Que dit la loi sur l'enrichissement sans cause ?' for conversation 5
2025-04-10 00:10:44,329 - INFO - Query received: Que dit la loi sur l'enrichissement sans cause ?
2025-04-10 00:10:45,285 - INFO - Search scores:
Document 66 (chunk: chunk_66): score=0.6333, confidence=100.00%
Document 1151 (chunk: chunk_1100): score=0.6046, confidence=95.46%
Document 81 (chunk: chunk_81): score=0.4715, confidence=74.45%
Document 70 (chunk: chunk_70): score=0.4336, confidence=68.46%
Document 1400 (chunk: chunk_1343): score=0.3731, confidence=58.92%
2025-04-10 00:10:45,288 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:10:45,288 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:10:48,628 - INFO - Token usage: prompt=1072, completion=822, total=1894
2025-04-10 00:10:48,631 - INFO - Agent workflow completed in 4.84s
2025-04-10 00:10:48,638 - INFO - Request processed in 4.84s (thinking: 3.34s)
2025-04-10 00:10:48,639 - INFO - 127.0.0.1 - - [10/Apr/2025 00:10:48] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:13:29,255 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:13:29,286 - INFO - Use pytorch device_name: cuda
2025-04-10 00:13:29,286 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:13:34,837 - INFO - Loading pre-built indexes...
2025-04-10 00:13:38,120 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:13:38,143 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:13:38,143 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:13:38,206 - INFO - 127.0.0.1 - - [10/Apr/2025 00:13:38] "GET / HTTP/1.1" 200 -
2025-04-10 00:13:38,353 - INFO - 127.0.0.1 - - [10/Apr/2025 00:13:38] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:13:38,602 - INFO - 127.0.0.1 - - [10/Apr/2025 00:13:38] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:13:44,433 - INFO - 127.0.0.1 - - [10/Apr/2025 00:13:44] "DELETE /delete_conversation/2 HTTP/1.1" 200 -
2025-04-10 00:13:47,735 - INFO - 127.0.0.1 - - [10/Apr/2025 00:13:47] "DELETE /delete_conversation/1 HTTP/1.1" 200 -
2025-04-10 00:14:09,797 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:14:10,286 - INFO - Token usage: prompt=110, completion=39, total=149
2025-04-10 00:14:10,296 - INFO - Processing query: 'Peut-on stipuler un contrat au profit d’un tiers ? Si oui, dans quel cadre ?' for conversation 6
2025-04-10 00:14:10,303 - INFO - Query received: Peut-on stipuler un contrat au profit d’un tiers ? Si oui, dans quel cadre ?
2025-04-10 00:14:11,355 - INFO - Search scores:
Document 37 (chunk: chunk_37): score=0.6958, confidence=100.00%
Document 39 (chunk: chunk_39): score=0.5000, confidence=71.86%
Document 1347 (chunk: chunk_1290): score=0.4187, confidence=60.17%
Document 1061 (chunk: chunk_1012): score=0.4118, confidence=59.19%
Document 1366 (chunk: chunk_1309): score=0.3566, confidence=51.25%
2025-04-10 00:14:11,358 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:14:11,358 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:14:14,169 - INFO - Token usage: prompt=1156, completion=683, total=1839
2025-04-10 00:14:14,173 - INFO - Agent workflow completed in 4.38s
2025-04-10 00:14:14,185 - INFO - Request processed in 4.39s (thinking: 2.82s)
2025-04-10 00:14:14,186 - INFO - 127.0.0.1 - - [10/Apr/2025 00:14:14] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:15:50,707 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:15:51,202 - INFO - Token usage: prompt=104, completion=50, total=154
2025-04-10 00:15:51,212 - INFO - Processing query: 'L'État est-il responsable des fautes de ses agents ?' for conversation 7
2025-04-10 00:15:51,213 - INFO - Query received: L'État est-il responsable des fautes de ses agents ?
2025-04-10 00:15:51,248 - INFO - Search scores:
Document 83 (chunk: chunk_83): score=0.6363, confidence=100.00%
Document 114 (chunk: chunk_105): score=0.3376, confidence=53.06%
Document 105 (chunk: chunk_97_sub_1): score=0.3244, confidence=50.98%
Document 104 (chunk: chunk_97): score=0.3226, confidence=50.70%
Document 902 (chunk: chunk_864): score=0.3196, confidence=50.23%
2025-04-10 00:15:51,252 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:15:51,252 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:15:54,229 - INFO - Token usage: prompt=1425, completion=725, total=2150
2025-04-10 00:15:54,231 - INFO - Agent workflow completed in 3.52s
2025-04-10 00:15:54,240 - INFO - Request processed in 3.53s (thinking: 2.98s)
2025-04-10 00:15:54,240 - INFO - 127.0.0.1 - - [10/Apr/2025 00:15:54] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:16:24,552 - INFO - 127.0.0.1 - - [10/Apr/2025 00:16:24] "GET / HTTP/1.1" 200 -
2025-04-10 00:16:24,856 - INFO - 127.0.0.1 - - [10/Apr/2025 00:16:24] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:16:25,201 - INFO - 127.0.0.1 - - [10/Apr/2025 00:16:25] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:16:27,255 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:16:27,771 - INFO - Token usage: prompt=103, completion=20, total=123
2025-04-10 00:16:27,780 - INFO - Processing query: 'What are my rights as an employee under Tunisian labor law?' for conversation 8
2025-04-10 00:16:27,781 - INFO - Query received: What are my rights as an employee under Tunisian labor law?
2025-04-10 00:16:28,344 - INFO - Search scores:
Document 230 (chunk: chunk_219): score=0.5000, confidence=100.00%
Document 206 (chunk: chunk_195): score=0.4609, confidence=92.17%
Document 1397 (chunk: chunk_1340): score=0.4461, confidence=89.21%
Document 872 (chunk: chunk_836): score=0.3726, confidence=74.53%
Document 907 (chunk: chunk_869): score=0.3622, confidence=72.43%
2025-04-10 00:16:28,348 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:16:28,348 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:16:30,462 - INFO - Token usage: prompt=933, completion=461, total=1394
2025-04-10 00:16:30,464 - INFO - Agent workflow completed in 3.21s
2025-04-10 00:16:30,473 - INFO - Request processed in 3.22s (thinking: 2.12s)
2025-04-10 00:16:30,474 - INFO - 127.0.0.1 - - [10/Apr/2025 00:16:30] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:17:25,233 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:17:25,267 - INFO - Use pytorch device_name: cuda
2025-04-10 00:17:25,267 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:17:33,047 - INFO - Loading pre-built indexes...
2025-04-10 00:17:36,268 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:17:36,282 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:17:36,282 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:17:43,686 - INFO - 127.0.0.1 - - [10/Apr/2025 00:17:43] "GET / HTTP/1.1" 200 -
2025-04-10 00:17:43,776 - INFO - 127.0.0.1 - - [10/Apr/2025 00:17:43] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:17:43,918 - INFO - 127.0.0.1 - - [10/Apr/2025 00:17:43] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:17:47,755 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:17:48,272 - INFO - Token usage: prompt=108, completion=36, total=144
2025-04-10 00:17:48,283 - INFO - Processing query: 'Peut-on imposer une condition qui empêche une personne de se marier ?' for conversation 9
2025-04-10 00:17:48,306 - INFO - Query received: Peut-on imposer une condition qui empêche une personne de se marier ?
2025-04-10 00:17:49,431 - INFO - Search scores:
Document 123 (chunk: chunk_114): score=0.6444, confidence=100.00%
Document 139 (chunk: chunk_130): score=0.3971, confidence=61.63%
Document 694 (chunk: chunk_662): score=0.3503, confidence=54.37%
Document 113 (chunk: chunk_104): score=0.3377, confidence=52.41%
Document 948 (chunk: chunk_903): score=0.3361, confidence=52.16%
2025-04-10 00:17:49,434 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:17:49,434 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:17:51,897 - INFO - Token usage: prompt=1187, completion=583, total=1770
2025-04-10 00:17:51,900 - INFO - Agent workflow completed in 4.14s
2025-04-10 00:17:51,908 - INFO - Request processed in 4.15s (thinking: 2.47s)
2025-04-10 00:17:51,910 - INFO - 127.0.0.1 - - [10/Apr/2025 00:17:51] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:19:51,007 - INFO - 127.0.0.1 - - [10/Apr/2025 00:19:51] "GET /get_conversation/7 HTTP/1.1" 200 -
2025-04-10 00:19:52,786 - INFO - 127.0.0.1 - - [10/Apr/2025 00:19:52] "GET /get_conversation/6 HTTP/1.1" 200 -
2025-04-10 00:19:54,122 - INFO - 127.0.0.1 - - [10/Apr/2025 00:19:54] "GET /get_conversation/5 HTTP/1.1" 200 -
2025-04-10 00:27:41,482 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:27:41,546 - INFO - Use pytorch device_name: cuda
2025-04-10 00:27:41,546 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:27:47,388 - INFO - Loading pre-built indexes...
2025-04-10 00:27:51,728 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:27:51,762 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:27:51,762 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:27:55,529 - INFO - 127.0.0.1 - - [10/Apr/2025 00:27:55] "GET / HTTP/1.1" 200 -
2025-04-10 00:27:55,771 - INFO - 127.0.0.1 - - [10/Apr/2025 00:27:55] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:27:55,796 - INFO - 127.0.0.1 - - [10/Apr/2025 00:27:55] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:27:58,596 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:27:59,143 - INFO - Token usage: prompt=103, completion=35, total=138
2025-04-10 00:27:59,165 - INFO - Processing query: 'La violence psychologique peut-elle invalider une obligation ?' for conversation 10
2025-04-10 00:27:59,173 - INFO - Query received: La violence psychologique peut-elle invalider une obligation ?
2025-04-10 00:28:00,333 - INFO - Search scores:
Document 52 (chunk: chunk_52): score=0.7049, confidence=100.00%
Document 50 (chunk: chunk_50): score=0.5970, confidence=84.70%
Document 53 (chunk: chunk_53): score=0.5870, confidence=83.28%
Document 49 (chunk: chunk_49): score=0.5767, confidence=81.81%
Document 448 (chunk: chunk_422): score=0.5126, confidence=72.72%
2025-04-10 00:28:00,336 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:28:00,336 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:28:03,738 - INFO - Token usage: prompt=960, completion=852, total=1812
2025-04-10 00:28:03,741 - INFO - Agent workflow completed in 5.15s
2025-04-10 00:28:03,763 - INFO - Request processed in 5.17s (thinking: 3.41s)
2025-04-10 00:28:03,764 - INFO - 127.0.0.1 - - [10/Apr/2025 00:28:03] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:29:17,577 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:29:17,612 - INFO - Use pytorch device_name: cuda
2025-04-10 00:29:17,612 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:29:22,972 - INFO - Loading pre-built indexes...
2025-04-10 00:29:26,326 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:29:26,338 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:29:26,339 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:29:38,036 - INFO - 127.0.0.1 - - [10/Apr/2025 00:29:38] "GET / HTTP/1.1" 200 -
2025-04-10 00:29:38,120 - INFO - 127.0.0.1 - - [10/Apr/2025 00:29:38] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:29:38,288 - INFO - 127.0.0.1 - - [10/Apr/2025 00:29:38] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:29:44,610 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:29:45,100 - INFO - Token usage: prompt=107, completion=34, total=141
2025-04-10 00:29:45,109 - INFO - Processing query: 'Une personne ivre peut-elle contester un contrat qu’elle a signé ?' for conversation 11
2025-04-10 00:29:45,116 - INFO - Query received: Une personne ivre peut-elle contester un contrat qu’elle a signé ?
2025-04-10 00:29:46,172 - INFO - Search scores:
Document 1399 (chunk: chunk_1342): score=0.5126, confidence=100.00%
Document 476 (chunk: chunk_448): score=0.5000, confidence=97.54%
Document 480 (chunk: chunk_452): score=0.4380, confidence=85.44%
Document 96 (chunk: chunk_92): score=0.4153, confidence=81.02%
Document 49 (chunk: chunk_49): score=0.3438, confidence=67.08%
2025-04-10 00:29:46,177 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:29:46,177 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:29:49,114 - INFO - Token usage: prompt=1032, completion=716, total=1748
2025-04-10 00:29:49,117 - INFO - Agent workflow completed in 4.51s
2025-04-10 00:29:49,126 - INFO - Request processed in 4.52s (thinking: 2.94s)
2025-04-10 00:29:49,127 - INFO - 127.0.0.1 - - [10/Apr/2025 00:29:49] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:33:08,120 - INFO - 127.0.0.1 - - [10/Apr/2025 00:33:08] "DELETE /delete_conversation/11 HTTP/1.1" 200 -
2025-04-10 00:37:59,987 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:38:00,030 - INFO - Use pytorch device_name: cuda
2025-04-10 00:38:00,030 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:38:06,263 - INFO - Loading pre-built indexes...
2025-04-10 00:38:09,582 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:38:09,596 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:38:09,596 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:38:11,136 - INFO - 127.0.0.1 - - [10/Apr/2025 00:38:11] "GET / HTTP/1.1" 200 -
2025-04-10 00:38:11,349 - INFO - 127.0.0.1 - - [10/Apr/2025 00:38:11] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:38:11,393 - INFO - 127.0.0.1 - - [10/Apr/2025 00:38:11] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:38:14,751 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:38:15,245 - INFO - Token usage: prompt=99, completion=12, total=111
2025-04-10 00:38:15,254 - INFO - Processing query: 'Un débiteur peut-il perdre le bénéfice du terme ? Si oui, dans quels cas ?' for conversation 12
2025-04-10 00:38:15,260 - INFO - Query received: Un débiteur peut-il perdre le bénéfice du terme ? Si oui, dans quels cas ?
2025-04-10 00:38:16,289 - INFO - Search scores:
Document 156 (chunk: chunk_145): score=0.5825, confidence=100.00%
Document 154 (chunk: chunk_143): score=0.5000, confidence=85.84%
Document 1431 (chunk: chunk_1374): score=0.3944, confidence=67.71%
Document 1447 (chunk: chunk_1390): score=0.3132, confidence=53.77%
Document 146 (chunk: chunk_135): score=0.2997, confidence=51.46%
2025-04-10 00:38:16,291 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:38:16,291 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:38:20,185 - INFO - Token usage: prompt=1371, completion=980, total=2351
2025-04-10 00:38:20,188 - INFO - Agent workflow completed in 5.44s
2025-04-10 00:38:20,197 - INFO - Request processed in 5.45s (thinking: 3.90s)
2025-04-10 00:38:20,198 - INFO - 127.0.0.1 - - [10/Apr/2025 00:38:20] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:40:43,288 - INFO - 127.0.0.1 - - [10/Apr/2025 00:40:43] "GET / HTTP/1.1" 200 -
2025-04-10 00:40:43,410 - INFO - 127.0.0.1 - - [10/Apr/2025 00:40:43] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:40:43,557 - INFO - 127.0.0.1 - - [10/Apr/2025 00:40:43] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:40:56,788 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:40:57,159 - INFO - Token usage: prompt=84, completion=7, total=91
2025-04-10 00:40:57,169 - INFO - Processing query: 'can i cancel my contract at anytime?' for conversation 13
2025-04-10 00:40:57,171 - INFO - Query received: can i cancel my contract at anytime?
2025-04-10 00:40:57,754 - INFO - Search scores:
Document 545 (chunk: chunk_517): score=0.5000, confidence=100.00%
Document 872 (chunk: chunk_836): score=0.4787, confidence=95.73%
Document 997 (chunk: chunk_950): score=0.4431, confidence=88.63%
Document 659 (chunk: chunk_631): score=0.4125, confidence=82.50%
Document 11 (chunk: chunk_11): score=0.4020, confidence=80.41%
2025-04-10 00:40:57,766 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:40:57,767 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:41:01,053 - INFO - Token usage: prompt=1038, completion=808, total=1846
2025-04-10 00:41:01,054 - INFO - Agent workflow completed in 4.27s
2025-04-10 00:41:01,067 - INFO - Request processed in 4.28s (thinking: 3.30s)
2025-04-10 00:41:01,068 - INFO - 127.0.0.1 - - [10/Apr/2025 00:41:01] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:43:29,766 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:43:29,799 - INFO - Use pytorch device_name: cuda
2025-04-10 00:43:29,799 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:43:35,069 - INFO - Loading pre-built indexes...
2025-04-10 00:43:38,559 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:43:38,583 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:43:38,584 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:43:43,612 - INFO - 127.0.0.1 - - [10/Apr/2025 00:43:43] "GET / HTTP/1.1" 200 -
2025-04-10 00:43:43,746 - INFO - 127.0.0.1 - - [10/Apr/2025 00:43:43] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:43:43,874 - INFO - 127.0.0.1 - - [10/Apr/2025 00:43:43] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:43:53,214 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:43:53,715 - INFO - Token usage: prompt=83, completion=17, total=100
2025-04-10 00:43:53,724 - INFO - Processing query: 'can i fire anyone at anytime?' for conversation 14
2025-04-10 00:43:53,731 - INFO - Query received: can i fire anyone at anytime?
2025-04-10 00:43:55,431 - INFO - Search scores:
Document 545 (chunk: chunk_517): score=0.5000, confidence=100.00%
Document 1414 (chunk: chunk_1357): score=0.4463, confidence=89.25%
Document 949 (chunk: chunk_904): score=0.4190, confidence=83.81%
Document 659 (chunk: chunk_631): score=0.4125, confidence=82.50%
Document 950 (chunk: chunk_905): score=0.4124, confidence=82.47%
2025-04-10 00:43:55,436 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:43:55,436 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:43:56,531 - INFO - Token usage: prompt=976, completion=194, total=1170
2025-04-10 00:43:56,531 - INFO - Agent workflow completed in 3.32s
2025-04-10 00:43:56,542 - INFO - Request processed in 3.33s (thinking: 1.10s)
2025-04-10 00:43:56,543 - INFO - 127.0.0.1 - - [10/Apr/2025 00:43:56] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:44:37,186 - INFO - 127.0.0.1 - - [10/Apr/2025 00:44:37] "GET / HTTP/1.1" 200 -
2025-04-10 00:44:37,499 - INFO - 127.0.0.1 - - [10/Apr/2025 00:44:37] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:44:37,859 - INFO - 127.0.0.1 - - [10/Apr/2025 00:44:37] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:44:41,103 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:44:41,599 - INFO - Token usage: prompt=84, completion=11, total=95
2025-04-10 00:44:41,609 - INFO - Processing query: 'can i cancel my contract at anytime?' for conversation 15
2025-04-10 00:44:41,610 - INFO - Query received: can i cancel my contract at anytime?
2025-04-10 00:44:42,071 - INFO - Search scores:
Document 545 (chunk: chunk_517): score=0.5000, confidence=100.00%
Document 872 (chunk: chunk_836): score=0.4787, confidence=95.73%
Document 997 (chunk: chunk_950): score=0.4431, confidence=88.63%
Document 659 (chunk: chunk_631): score=0.4125, confidence=82.50%
Document 11 (chunk: chunk_11): score=0.4020, confidence=80.41%
2025-04-10 00:44:42,080 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:44:42,080 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:44:45,456 - INFO - Token usage: prompt=1038, completion=715, total=1753
2025-04-10 00:44:45,457 - INFO - Agent workflow completed in 4.35s
2025-04-10 00:44:45,468 - INFO - Request processed in 4.36s (thinking: 3.39s)
2025-04-10 00:44:45,469 - INFO - 127.0.0.1 - - [10/Apr/2025 00:44:45] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:45:10,550 - INFO - 127.0.0.1 - - [10/Apr/2025 00:45:10] "GET / HTTP/1.1" 200 -
2025-04-10 00:45:10,676 - INFO - 127.0.0.1 - - [10/Apr/2025 00:45:10] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:45:10,823 - INFO - 127.0.0.1 - - [10/Apr/2025 00:45:10] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:45:12,954 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:45:13,464 - INFO - Token usage: prompt=84, completion=9, total=93
2025-04-10 00:45:13,473 - INFO - Processing query: 'can i cancel my contract at anytime?' for conversation 16
2025-04-10 00:45:13,474 - INFO - Query received: can i cancel my contract at anytime?
2025-04-10 00:45:13,925 - INFO - Search scores:
Document 545 (chunk: chunk_517): score=0.5000, confidence=100.00%
Document 872 (chunk: chunk_836): score=0.4787, confidence=95.73%
Document 997 (chunk: chunk_950): score=0.4431, confidence=88.63%
Document 659 (chunk: chunk_631): score=0.4125, confidence=82.50%
Document 11 (chunk: chunk_11): score=0.4020, confidence=80.41%
2025-04-10 00:45:13,937 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:45:13,937 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:45:15,799 - INFO - Token usage: prompt=1038, completion=390, total=1428
2025-04-10 00:45:15,800 - INFO - Agent workflow completed in 2.85s
2025-04-10 00:45:15,811 - INFO - Request processed in 2.86s (thinking: 1.87s)
2025-04-10 00:45:15,812 - INFO - 127.0.0.1 - - [10/Apr/2025 00:45:15] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:45:38,646 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:45:38,679 - INFO - Use pytorch device_name: cuda
2025-04-10 00:45:38,679 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:45:46,603 - INFO - Loading pre-built indexes...
2025-04-10 00:45:49,704 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:45:49,724 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:45:49,724 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:45:58,157 - INFO - 127.0.0.1 - - [10/Apr/2025 00:45:58] "GET / HTTP/1.1" 200 -
2025-04-10 00:45:58,317 - INFO - 127.0.0.1 - - [10/Apr/2025 00:45:58] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:45:58,414 - INFO - 127.0.0.1 - - [10/Apr/2025 00:45:58] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:46:00,537 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:46:01,029 - INFO - Token usage: prompt=84, completion=9, total=93
2025-04-10 00:46:01,038 - INFO - Processing query: 'can i cancel my contract at anytime?' for conversation 17
2025-04-10 00:46:01,045 - INFO - Query received: can i cancel my contract at anytime?
2025-04-10 00:46:02,609 - INFO - Search scores:
Document 545 (chunk: chunk_517): score=0.5000, confidence=100.00%
Document 872 (chunk: chunk_836): score=0.4787, confidence=95.73%
Document 997 (chunk: chunk_950): score=0.4431, confidence=88.63%
Document 659 (chunk: chunk_631): score=0.4125, confidence=82.50%
Document 11 (chunk: chunk_11): score=0.4020, confidence=80.41%
2025-04-10 00:46:02,619 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:46:02,619 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:46:06,082 - INFO - Token usage: prompt=1038, completion=866, total=1904
2025-04-10 00:46:06,083 - INFO - Agent workflow completed in 5.55s
2025-04-10 00:46:06,095 - INFO - Request processed in 5.56s (thinking: 3.47s)
2025-04-10 00:46:06,096 - INFO - 127.0.0.1 - - [10/Apr/2025 00:46:06] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:47:56,730 - INFO - 127.0.0.1 - - [10/Apr/2025 00:47:56] "GET / HTTP/1.1" 200 -
2025-04-10 00:47:56,851 - INFO - 127.0.0.1 - - [10/Apr/2025 00:47:56] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:47:56,985 - INFO - 127.0.0.1 - - [10/Apr/2025 00:47:56] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:47:59,508 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:48:00,020 - INFO - Token usage: prompt=84, completion=8, total=92
2025-04-10 00:48:00,029 - INFO - Processing query: 'can i cancel my contract at anytime?' for conversation 18
2025-04-10 00:48:00,030 - INFO - Query received: can i cancel my contract at anytime?
2025-04-10 00:48:00,521 - INFO - Search scores:
Document 545 (chunk: chunk_517): score=0.5000, confidence=100.00%
Document 872 (chunk: chunk_836): score=0.4787, confidence=95.73%
Document 997 (chunk: chunk_950): score=0.4431, confidence=88.63%
Document 659 (chunk: chunk_631): score=0.4125, confidence=82.50%
Document 11 (chunk: chunk_11): score=0.4020, confidence=80.41%
2025-04-10 00:48:00,529 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:48:00,530 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:48:03,329 - INFO - Token usage: prompt=1038, completion=671, total=1709
2025-04-10 00:48:03,330 - INFO - Agent workflow completed in 3.82s
2025-04-10 00:48:03,342 - INFO - Request processed in 3.83s (thinking: 2.81s)
2025-04-10 00:48:03,343 - INFO - 127.0.0.1 - - [10/Apr/2025 00:48:03] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:49:47,632 - INFO - 127.0.0.1 - - [10/Apr/2025 00:49:47] "GET / HTTP/1.1" 200 -
2025-04-10 00:49:47,936 - INFO - 127.0.0.1 - - [10/Apr/2025 00:49:47] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:49:48,278 - INFO - 127.0.0.1 - - [10/Apr/2025 00:49:48] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:49:50,346 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:49:50,840 - INFO - Token usage: prompt=84, completion=11, total=95
2025-04-10 00:49:50,849 - INFO - Processing query: 'can i cancel my contract at anytime?' for conversation 19
2025-04-10 00:49:50,850 - INFO - Query received: can i cancel my contract at anytime?
2025-04-10 00:49:51,283 - INFO - Search scores:
Document 545 (chunk: chunk_517): score=0.5000, confidence=100.00%
Document 872 (chunk: chunk_836): score=0.4787, confidence=95.73%
Document 997 (chunk: chunk_950): score=0.4431, confidence=88.63%
Document 659 (chunk: chunk_631): score=0.4125, confidence=82.50%
Document 11 (chunk: chunk_11): score=0.4020, confidence=80.41%
2025-04-10 00:49:51,290 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:49:51,291 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:49:53,859 - INFO - Token usage: prompt=1038, completion=616, total=1654
2025-04-10 00:49:53,859 - INFO - Agent workflow completed in 3.51s
2025-04-10 00:49:53,869 - INFO - Request processed in 3.52s (thinking: 2.58s)
2025-04-10 00:49:53,869 - INFO - 127.0.0.1 - - [10/Apr/2025 00:49:53] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:51:16,960 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:51:16,984 - INFO - Use pytorch device_name: cuda
2025-04-10 00:51:16,985 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:51:25,175 - INFO - Loading pre-built indexes...
2025-04-10 00:51:28,324 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:51:28,337 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:51:28,337 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:51:28,504 - INFO - 127.0.0.1 - - [10/Apr/2025 00:51:28] "GET / HTTP/1.1" 200 -
2025-04-10 00:51:28,754 - INFO - 127.0.0.1 - - [10/Apr/2025 00:51:28] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:51:28,929 - INFO - 127.0.0.1 - - [10/Apr/2025 00:51:28] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:51:33,209 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:51:33,866 - INFO - Token usage: prompt=84, completion=11, total=95
2025-04-10 00:51:33,875 - INFO - Processing query: 'can i cancel my contract at anytime?' for conversation 20
2025-04-10 00:51:33,881 - INFO - Query received: can i cancel my contract at anytime?
2025-04-10 00:51:35,411 - INFO - Search scores:
Document 545 (chunk: chunk_517): score=0.5000, confidence=100.00%
Document 872 (chunk: chunk_836): score=0.4787, confidence=95.73%
Document 997 (chunk: chunk_950): score=0.4431, confidence=88.63%
Document 659 (chunk: chunk_631): score=0.4125, confidence=82.50%
Document 11 (chunk: chunk_11): score=0.4020, confidence=80.41%
2025-04-10 00:51:35,423 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:51:35,423 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:51:38,496 - INFO - Token usage: prompt=1038, completion=679, total=1717
2025-04-10 00:51:38,497 - INFO - Agent workflow completed in 5.29s
2025-04-10 00:51:38,497 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chedl\AppData\Local\Programs\Python\Python312\Lib\site-packages\flask\app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\chedl\AppData\Local\Programs\Python\Python312\Lib\site-packages\flask\app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\chedl\AppData\Local\Programs\Python\Python312\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\chedl\AppData\Local\Programs\Python\Python312\Lib\site-packages\flask\app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\chedl\AppData\Local\Programs\Python\Python312\Lib\site-packages\flask\app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\chedl\Downloads\Jo-main\Jo-main\try\app.py", line 991, in ask
    <h4>{step['title']}</h4>
         ~~~~^^^^^^^^^
KeyError: 'title'
2025-04-10 00:51:38,527 - INFO - 127.0.0.1 - - [10/Apr/2025 00:51:38] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-04-10 00:52:50,193 - INFO - 127.0.0.1 - - [10/Apr/2025 00:52:50] "GET / HTTP/1.1" 200 -
2025-04-10 00:52:50,292 - INFO - 127.0.0.1 - - [10/Apr/2025 00:52:50] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:52:50,462 - INFO - 127.0.0.1 - - [10/Apr/2025 00:52:50] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:52:53,805 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:52:54,165 - INFO - Token usage: prompt=84, completion=8, total=92
2025-04-10 00:52:54,175 - INFO - Processing query: 'can i cancel my contract at anytime?' for conversation 21
2025-04-10 00:52:54,176 - INFO - Query received: can i cancel my contract at anytime?
2025-04-10 00:52:54,557 - INFO - Search scores:
Document 545 (chunk: chunk_517): score=0.5000, confidence=100.00%
Document 872 (chunk: chunk_836): score=0.4787, confidence=95.73%
Document 997 (chunk: chunk_950): score=0.4431, confidence=88.63%
Document 659 (chunk: chunk_631): score=0.4125, confidence=82.50%
Document 11 (chunk: chunk_11): score=0.4020, confidence=80.41%
2025-04-10 00:52:54,566 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:52:54,566 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:52:57,488 - INFO - Token usage: prompt=1038, completion=716, total=1754
2025-04-10 00:52:57,489 - INFO - Agent workflow completed in 3.68s
2025-04-10 00:52:57,489 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chedl\AppData\Local\Programs\Python\Python312\Lib\site-packages\flask\app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\chedl\AppData\Local\Programs\Python\Python312\Lib\site-packages\flask\app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\chedl\AppData\Local\Programs\Python\Python312\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\chedl\AppData\Local\Programs\Python\Python312\Lib\site-packages\flask\app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\chedl\AppData\Local\Programs\Python\Python312\Lib\site-packages\flask\app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\chedl\Downloads\Jo-main\Jo-main\try\app.py", line 991, in ask
    <h4>{step['title']}</h4>
         ~~~~^^^^^^^^^
KeyError: 'title'
2025-04-10 00:52:57,490 - INFO - 127.0.0.1 - - [10/Apr/2025 00:52:57] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-04-10 00:53:09,553 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:53:09,595 - INFO - Use pytorch device_name: cuda
2025-04-10 00:53:09,595 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:54:58,690 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 00:54:58,738 - INFO - Use pytorch device_name: cuda
2025-04-10 00:54:58,739 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 00:55:03,597 - INFO - Loading pre-built indexes...
2025-04-10 00:55:07,075 - INFO - Loaded 1460 legal document chunks
2025-04-10 00:55:07,096 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 00:55:07,097 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 00:55:13,752 - INFO - 127.0.0.1 - - [10/Apr/2025 00:55:13] "GET / HTTP/1.1" 200 -
2025-04-10 00:55:13,831 - INFO - 127.0.0.1 - - [10/Apr/2025 00:55:13] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 00:55:13,993 - INFO - 127.0.0.1 - - [10/Apr/2025 00:55:13] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 00:55:17,108 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:55:17,602 - INFO - Token usage: prompt=89, completion=12, total=101
2025-04-10 00:55:17,612 - INFO - Processing query: 'What are my rights as an employee under Tunisian labor law?' for conversation 22
2025-04-10 00:55:17,618 - INFO - Query received: What are my rights as an employee under Tunisian labor law?
2025-04-10 00:55:19,120 - INFO - Search scores:
Document 230 (chunk: chunk_219): score=0.5000, confidence=100.00%
Document 206 (chunk: chunk_195): score=0.4609, confidence=92.17%
Document 1397 (chunk: chunk_1340): score=0.4461, confidence=89.21%
Document 872 (chunk: chunk_836): score=0.3726, confidence=74.53%
Document 907 (chunk: chunk_869): score=0.3622, confidence=72.43%
2025-04-10 00:55:19,123 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:55:19,123 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:55:21,073 - INFO - Token usage: prompt=925, completion=447, total=1372
2025-04-10 00:55:21,074 - INFO - Agent workflow completed in 3.97s
2025-04-10 00:55:21,087 - INFO - Request processed in 3.98s (thinking: 1.95s)
2025-04-10 00:55:21,088 - INFO - 127.0.0.1 - - [10/Apr/2025 00:55:21] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:56:05,279 - INFO - 127.0.0.1 - - [10/Apr/2025 00:56:05] "GET /get_conversation/5 HTTP/1.1" 200 -
2025-04-10 00:56:06,429 - INFO - 127.0.0.1 - - [10/Apr/2025 00:56:06] "GET /get_conversation/6 HTTP/1.1" 200 -
2025-04-10 00:56:08,218 - INFO - 127.0.0.1 - - [10/Apr/2025 00:56:08] "GET /get_conversation/21 HTTP/1.1" 200 -
2025-04-10 00:56:10,429 - INFO - 127.0.0.1 - - [10/Apr/2025 00:56:10] "GET /get_conversation/12 HTTP/1.1" 200 -
2025-04-10 00:56:10,898 - INFO - 127.0.0.1 - - [10/Apr/2025 00:56:10] "GET /get_conversation/13 HTTP/1.1" 200 -
2025-04-10 00:56:13,795 - INFO - 127.0.0.1 - - [10/Apr/2025 00:56:13] "GET /get_conversation/14 HTTP/1.1" 200 -
2025-04-10 00:56:21,006 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 00:56:21,547 - INFO - Token usage: prompt=83, completion=9, total=92
2025-04-10 00:56:21,557 - INFO - Processing query: 'can i fire anyone at anytime?' for conversation 23
2025-04-10 00:56:21,558 - INFO - Query received: can i fire anyone at anytime?
2025-04-10 00:56:21,962 - INFO - Search scores:
Document 545 (chunk: chunk_517): score=0.5000, confidence=100.00%
Document 1414 (chunk: chunk_1357): score=0.4463, confidence=89.25%
Document 949 (chunk: chunk_904): score=0.4190, confidence=83.81%
Document 659 (chunk: chunk_631): score=0.4125, confidence=82.50%
Document 950 (chunk: chunk_905): score=0.4124, confidence=82.47%
2025-04-10 00:56:21,968 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 00:56:21,968 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 00:56:23,047 - INFO - Token usage: prompt=976, completion=211, total=1187
2025-04-10 00:56:23,048 - INFO - Agent workflow completed in 2.04s
2025-04-10 00:56:23,061 - INFO - Request processed in 2.05s (thinking: 1.09s)
2025-04-10 00:56:23,061 - INFO - 127.0.0.1 - - [10/Apr/2025 00:56:23] "POST /ask HTTP/1.1" 200 -
2025-04-10 00:57:01,592 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:01] "DELETE /delete_conversation/21 HTTP/1.1" 200 -
2025-04-10 00:57:03,053 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:03] "DELETE /delete_conversation/20 HTTP/1.1" 200 -
2025-04-10 00:57:04,627 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:04] "DELETE /delete_conversation/19 HTTP/1.1" 200 -
2025-04-10 00:57:05,317 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:05] "DELETE /delete_conversation/18 HTTP/1.1" 200 -
2025-04-10 00:57:06,492 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:06] "DELETE /delete_conversation/17 HTTP/1.1" 200 -
2025-04-10 00:57:10,389 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:10] "DELETE /delete_conversation/7 HTTP/1.1" 200 -
2025-04-10 00:57:14,521 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:14] "DELETE /delete_conversation/8 HTTP/1.1" 200 -
2025-04-10 00:57:15,532 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:15] "DELETE /delete_conversation/9 HTTP/1.1" 200 -
2025-04-10 00:57:17,069 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:17] "DELETE /delete_conversation/10 HTTP/1.1" 200 -
2025-04-10 00:57:17,896 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:17] "DELETE /delete_conversation/12 HTTP/1.1" 200 -
2025-04-10 00:57:19,328 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:19] "DELETE /delete_conversation/13 HTTP/1.1" 200 -
2025-04-10 00:57:24,443 - INFO - 127.0.0.1 - - [10/Apr/2025 00:57:24] "GET /get_conversation/6 HTTP/1.1" 200 -
2025-04-10 00:58:41,404 - INFO - 127.0.0.1 - - [10/Apr/2025 00:58:41] "GET /get_conversation/23 HTTP/1.1" 200 -
2025-04-10 00:58:45,079 - INFO - 127.0.0.1 - - [10/Apr/2025 00:58:45] "POST /search_conversations HTTP/1.1" 200 -
2025-04-10 00:58:45,795 - INFO - 127.0.0.1 - - [10/Apr/2025 00:58:45] "POST /search_conversations HTTP/1.1" 200 -
2025-04-10 00:58:47,191 - INFO - 127.0.0.1 - - [10/Apr/2025 00:58:47] "POST /search_conversations HTTP/1.1" 200 -
2025-04-10 00:58:48,887 - INFO - 127.0.0.1 - - [10/Apr/2025 00:58:48] "POST /search_conversations HTTP/1.1" 200 -
2025-04-10 00:58:50,116 - INFO - 127.0.0.1 - - [10/Apr/2025 00:58:50] "POST /search_conversations HTTP/1.1" 200 -
2025-04-10 00:58:55,126 - INFO - 127.0.0.1 - - [10/Apr/2025 00:58:55] "POST /search_conversations HTTP/1.1" 200 -
2025-04-10 00:58:55,391 - INFO - 127.0.0.1 - - [10/Apr/2025 00:58:55] "POST /search_conversations HTTP/1.1" 200 -
2025-04-10 01:02:34,810 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 01:02:34,839 - INFO - Use pytorch device_name: cuda
2025-04-10 01:02:34,839 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 01:02:42,865 - INFO - Loading pre-built indexes...
2025-04-10 01:02:46,286 - INFO - Loaded 1460 legal document chunks
2025-04-10 01:02:46,304 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 01:02:46,304 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 01:02:47,994 - INFO - 127.0.0.1 - - [10/Apr/2025 01:02:47] "GET / HTTP/1.1" 200 -
2025-04-10 01:02:48,087 - INFO - 127.0.0.1 - - [10/Apr/2025 01:02:48] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 01:02:48,238 - INFO - 127.0.0.1 - - [10/Apr/2025 01:02:48] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 01:03:01,645 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 01:03:02,360 - INFO - Token usage: prompt=83, completion=7, total=90
2025-04-10 01:03:02,370 - INFO - Processing query: 'how much money i can ask' for conversation 24
2025-04-10 01:03:02,377 - INFO - Query received: how much money i can ask
2025-04-10 01:03:03,693 - INFO - Search scores:
Document 1317 (chunk: chunk_1260): score=0.5000, confidence=100.00%
Document 545 (chunk: chunk_517): score=0.3474, confidence=69.48%
Document 767 (chunk: chunk_735): score=0.3104, confidence=62.07%
Document 945 (chunk: chunk_900): score=0.2899, confidence=57.98%
Document 1352 (chunk: chunk_1295): score=0.2816, confidence=56.32%
2025-04-10 01:03:03,696 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 01:03:03,696 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 01:03:05,649 - INFO - Token usage: prompt=909, completion=441, total=1350
2025-04-10 01:03:05,650 - INFO - Agent workflow completed in 4.01s
2025-04-10 01:03:05,663 - INFO - Request processed in 4.02s (thinking: 1.96s)
2025-04-10 01:03:05,664 - INFO - 127.0.0.1 - - [10/Apr/2025 01:03:05] "POST /ask HTTP/1.1" 200 -
2025-04-10 01:05:03,538 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 01:05:03,571 - INFO - Use pytorch device_name: cuda
2025-04-10 01:05:03,571 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 01:05:09,280 - INFO - Loading pre-built indexes...
2025-04-10 01:05:12,305 - INFO - Loaded 1460 legal document chunks
2025-04-10 01:05:12,318 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 01:05:12,318 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 01:05:20,480 - INFO - 127.0.0.1 - - [10/Apr/2025 01:05:20] "GET / HTTP/1.1" 200 -
2025-04-10 01:05:20,592 - INFO - 127.0.0.1 - - [10/Apr/2025 01:05:20] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 01:05:20,740 - INFO - 127.0.0.1 - - [10/Apr/2025 01:05:20] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 01:05:35,838 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 01:05:35,870 - INFO - Use pytorch device_name: cuda
2025-04-10 01:05:35,871 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 01:05:42,460 - INFO - Loading pre-built indexes...
2025-04-10 01:05:45,459 - INFO - Loaded 1460 legal document chunks
2025-04-10 01:05:45,475 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-10 01:05:45,475 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 01:05:48,342 - INFO - 127.0.0.1 - - [10/Apr/2025 01:05:48] "GET / HTTP/1.1" 200 -
2025-04-10 01:05:48,424 - INFO - 127.0.0.1 - - [10/Apr/2025 01:05:48] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 01:05:48,560 - INFO - 127.0.0.1 - - [10/Apr/2025 01:05:48] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 01:06:01,072 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 01:06:01,570 - INFO - Token usage: prompt=83, completion=7, total=90
2025-04-10 01:06:01,578 - INFO - Processing query: 'asalamou alaykom' for conversation 25
2025-04-10 01:06:01,585 - INFO - Query received: asalamou alaykom
2025-04-10 01:06:02,898 - INFO - Search scores:
Document 942 (chunk: chunk_897): score=0.2642, confidence=100.00%
Document 441 (chunk: chunk_415): score=0.2627, confidence=99.43%
Document 545 (chunk: chunk_517): score=0.2606, confidence=98.65%
Document 936 (chunk: chunk_891): score=0.2583, confidence=97.77%
Document 937 (chunk: chunk_892): score=0.2581, confidence=97.69%
2025-04-10 01:06:02,909 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 01:06:02,909 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 01:06:04,112 - INFO - Token usage: prompt=851, completion=238, total=1089
2025-04-10 01:06:04,113 - INFO - Agent workflow completed in 3.04s
2025-04-10 01:06:04,129 - INFO - Request processed in 3.06s (thinking: 1.21s)
2025-04-10 01:06:04,130 - INFO - 127.0.0.1 - - [10/Apr/2025 01:06:04] "POST /ask HTTP/1.1" 200 -
2025-04-10 01:07:22,205 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 01:07:22,699 - INFO - Token usage: prompt=111, completion=15, total=126
2025-04-10 01:07:22,719 - INFO - Processing query: '\u0671\u0644\u0633\u064e\u0651\u0644\u064e\u0627\u0645\u064f \u0639\u064e\u0644\u064e\u064a\u0652\u0643\u064f\u0645\u0652 \u0648\u064e\u0631\u064e\u062d\u0652\u0645\u064e\u0629\u064f \u0671\u0644\u0644\u0647\u0650 \u0648\u064e\u0628\u064e\u0631\u064e\u0643\u064e\u0627\u062a\u064f\u0647\u064f' for conversation 26
2025-04-10 01:07:22,721 - INFO - Query received: \u0671\u0644\u0633\u064e\u0651\u0644\u064e\u0627\u0645\u064f \u0639\u064e\u0644\u064e\u064a\u0652\u0643\u064f\u0645\u0652 \u0648\u064e\u0631\u064e\u062d\u0652\u0645\u064e\u0629\u064f \u0671\u0644\u0644\u0647\u0650 \u0648\u064e\u0628\u064e\u0631\u064e\u0643\u064e\u0627\u062a\u064f\u0647\u064f
2025-04-10 01:07:42,722 - INFO - Search scores:
Document 351 (chunk: chunk_332): score=0.5000, confidence=100.00%
Document 832 (chunk: chunk_798): score=0.4828, confidence=96.57%
Document 829 (chunk: chunk_795): score=0.4822, confidence=96.44%
Document 1265 (chunk: chunk_1208): score=0.4819, confidence=96.39%
Document 794 (chunk: chunk_762): score=0.4769, confidence=95.38%
2025-04-10 01:07:42,724 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 01:07:42,724 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 01:07:44,648 - INFO - Token usage: prompt=1355, completion=237, total=1592
2025-04-10 01:07:44,648 - INFO - Agent workflow completed in 22.44s
2025-04-10 01:07:44,656 - INFO - Request processed in 22.45s (thinking: 1.93s)
2025-04-10 01:07:44,657 - INFO - 127.0.0.1 - - [10/Apr/2025 01:07:44] "POST /ask HTTP/1.1" 200 -
2025-04-10 01:08:37,411 - INFO - Processing query: '\u0645\u0646 \u0623\u0646\u062a' for conversation 26
2025-04-10 01:08:37,413 - INFO - Query received: \u0645\u0646 \u0623\u0646\u062a
2025-04-10 01:08:54,526 - INFO - Search scores:
Document 95 (chunk: chunk_91_sub_2): score=0.2242, confidence=100.00%
Document 517 (chunk: chunk_489): score=0.2242, confidence=99.98%
Document 18 (chunk: chunk_18): score=0.2224, confidence=99.19%
Document 798 (chunk: chunk_764): score=0.2203, confidence=98.27%
Document 504 (chunk: chunk_476): score=0.2198, confidence=98.04%
2025-04-10 01:08:54,528 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 01:08:54,528 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 01:08:56,825 - INFO - Token usage: prompt=846, completion=537, total=1383
2025-04-10 01:08:56,826 - INFO - Agent workflow completed in 19.42s
2025-04-10 01:08:56,831 - INFO - Request processed in 19.43s (thinking: 2.30s)
2025-04-10 01:08:56,831 - INFO - 127.0.0.1 - - [10/Apr/2025 01:08:56] "POST /ask HTTP/1.1" 200 -
2025-04-10 09:01:13,231 - INFO - 127.0.0.1 - - [10/Apr/2025 09:01:13] "GET /get_conversation/23 HTTP/1.1" 200 -
2025-04-10 09:01:15,716 - INFO - 127.0.0.1 - - [10/Apr/2025 09:01:15] "GET /get_conversation/22 HTTP/1.1" 200 -
2025-04-10 09:01:56,860 - INFO - 127.0.0.1 - - [10/Apr/2025 09:01:56] "GET / HTTP/1.1" 200 -
2025-04-10 09:01:57,247 - INFO - 127.0.0.1 - - [10/Apr/2025 09:01:57] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 09:01:57,460 - INFO - 127.0.0.1 - - [10/Apr/2025 09:01:57] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 09:18:35,911 - WARNING - Config file config.yaml not found, using defaults.
2025-04-10 09:18:35,956 - INFO - Use pytorch device_name: cuda
2025-04-10 09:18:35,956 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-10 09:18:42,901 - INFO - Loading pre-built indexes...
2025-04-10 09:18:46,376 - INFO - Loaded 1460 legal document chunks
2025-04-10 09:18:47,654 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.17.1.59:5000
2025-04-10 09:18:47,654 - INFO - [33mPress CTRL+C to quit[0m
2025-04-10 09:18:48,625 - INFO - 127.0.0.1 - - [10/Apr/2025 09:18:48] "GET / HTTP/1.1" 200 -
2025-04-10 09:18:48,891 - INFO - 127.0.0.1 - - [10/Apr/2025 09:18:48] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 09:18:49,341 - INFO - 127.0.0.1 - - [10/Apr/2025 09:18:49] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 09:18:52,159 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 09:18:52,786 - INFO - Token usage: prompt=98, completion=22, total=120
2025-04-10 09:18:52,796 - INFO - Processing query: 'Quelles sont les exigences légales et réglementaires pour la création d’une entreprise en Tunisie ?' for conversation 27
2025-04-10 09:18:52,819 - INFO - Query received: Quelles sont les exigences légales et réglementaires pour la création d’une entreprise en Tunisie ?
2025-04-10 09:18:54,149 - INFO - Search scores:
Document 269 (chunk: chunk_256): score=0.5585, confidence=100.00%
Document 877 (chunk: chunk_841): score=0.5000, confidence=89.53%
Document 474 (chunk: chunk_446_sub_2): score=0.4821, confidence=86.33%
Document 472 (chunk: chunk_446): score=0.4612, confidence=82.59%
Document 1144 (chunk: chunk_1093): score=0.4329, confidence=77.51%
2025-04-10 09:18:54,152 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 09:18:54,152 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 09:19:04,502 - INFO - 127.0.0.1 - - [10/Apr/2025 09:19:04] "GET / HTTP/1.1" 200 -
2025-04-10 09:19:04,940 - INFO - 127.0.0.1 - - [10/Apr/2025 09:19:04] "GET / HTTP/1.1" 200 -
2025-04-10 09:19:05,128 - INFO - 127.0.0.1 - - [10/Apr/2025 09:19:05] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 09:19:05,595 - INFO - 127.0.0.1 - - [10/Apr/2025 09:19:05] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 09:19:20,069 - INFO - Token usage: prompt=1373, completion=818, total=2191
2025-04-10 09:19:20,072 - INFO - Agent workflow completed in 27.91s
2025-04-10 09:19:20,087 - INFO - Request processed in 27.93s (thinking: 25.92s)
2025-04-10 09:19:20,088 - INFO - 127.0.0.1 - - [10/Apr/2025 09:19:20] "POST /ask HTTP/1.1" 200 -
2025-04-10 09:19:31,344 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 09:19:31,999 - INFO - Token usage: prompt=87, completion=51, total=138
2025-04-10 09:19:32,011 - INFO - Processing query: 'What are the requirements for starting a business in Tunisia?' for conversation 28
2025-04-10 09:19:32,012 - INFO - Query received: What are the requirements for starting a business in Tunisia?
2025-04-10 09:19:32,387 - INFO - Search scores:
Document 473 (chunk: chunk_446_sub_1): score=0.6039, confidence=100.00%
Document 701 (chunk: chunk_669): score=0.5000, confidence=82.80%
Document 269 (chunk: chunk_256): score=0.4578, confidence=75.81%
Document 877 (chunk: chunk_841): score=0.4505, confidence=74.60%
Document 472 (chunk: chunk_446): score=0.4452, confidence=73.72%
2025-04-10 09:19:32,391 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 09:19:32,392 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 09:19:43,958 - INFO - Token usage: prompt=1162, completion=483, total=1645
2025-04-10 09:19:43,959 - INFO - Agent workflow completed in 12.62s
2025-04-10 09:19:43,968 - INFO - Request processed in 12.62s (thinking: 11.57s)
2025-04-10 09:19:43,969 - INFO - 127.0.0.1 - - [10/Apr/2025 09:19:43] "POST /ask HTTP/1.1" 200 -
2025-04-10 09:20:30,000 - INFO - 127.0.0.1 - - [10/Apr/2025 09:20:30] "GET / HTTP/1.1" 200 -
2025-04-10 09:20:30,305 - INFO - 127.0.0.1 - - [10/Apr/2025 09:20:30] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-10 09:20:30,648 - INFO - 127.0.0.1 - - [10/Apr/2025 09:20:30] "GET /get_conversations HTTP/1.1" 200 -
2025-04-10 09:20:32,779 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-10 09:20:33,301 - INFO - Token usage: prompt=92, completion=38, total=130
2025-04-10 09:20:33,311 - INFO - Processing query: 'Quelles sont les exigences pour démarrer une entreprise en Tunisie ?' for conversation 29
2025-04-10 09:20:33,312 - INFO - Query received: Quelles sont les exigences pour démarrer une entreprise en Tunisie ?
2025-04-10 09:20:33,344 - INFO - Search scores:
Document 269 (chunk: chunk_256): score=0.6655, confidence=100.00%
Document 877 (chunk: chunk_841): score=0.4920, confidence=73.94%
Document 472 (chunk: chunk_446): score=0.4863, confidence=73.07%
Document 473 (chunk: chunk_446_sub_1): score=0.4822, confidence=72.47%
Document 474 (chunk: chunk_446_sub_2): score=0.4791, confidence=71.99%
2025-04-10 09:20:33,347 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-10 09:20:33,347 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-10 09:20:43,732 - INFO - Token usage: prompt=1357, completion=528, total=1885
2025-04-10 09:20:43,735 - INFO - Agent workflow completed in 10.96s
2025-04-10 09:20:43,744 - INFO - Request processed in 10.96s (thinking: 10.39s)
2025-04-10 09:20:43,745 - INFO - 127.0.0.1 - - [10/Apr/2025 09:20:43] "POST /ask HTTP/1.1" 200 -
2025-04-14 21:12:40,037 - WARNING - Config file config.yaml not found, using defaults.
2025-04-14 21:12:40,075 - INFO - Use pytorch device_name: cuda
2025-04-14 21:12:40,075 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-14 21:12:46,438 - INFO - Loading pre-built indexes...
2025-04-14 21:12:50,116 - INFO - Loaded 1460 legal document chunks
2025-04-14 21:12:50,154 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-14 21:12:50,154 - INFO - [33mPress CTRL+C to quit[0m
2025-04-14 21:13:16,936 - INFO - 127.0.0.1 - - [14/Apr/2025 21:13:16] "GET / HTTP/1.1" 200 -
2025-04-14 21:13:17,212 - INFO - 127.0.0.1 - - [14/Apr/2025 21:13:17] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-14 21:13:17,642 - INFO - 127.0.0.1 - - [14/Apr/2025 21:13:17] "GET /get_conversations HTTP/1.1" 200 -
2025-04-14 21:13:20,734 - INFO - 127.0.0.1 - - [14/Apr/2025 21:13:20] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-04-14 21:15:41,603 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-14 21:15:41,819 - ERROR - HTTP error occurred: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions (Status code: 400)
2025-04-14 21:15:41,819 - ERROR - Error generating title: Bad request to Groq API: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions
2025-04-14 21:15:41,829 - INFO - Processing query: 'Est-ce qu’un adolescent de 17 ans peut signer un contrat sans ses parents ?' for conversation 30
2025-04-14 21:15:41,858 - INFO - Query received: Est-ce qu’un adolescent de 17 ans peut signer un contrat sans ses parents ?
2025-04-14 21:15:43,683 - INFO - Search scores:
Document 16 (chunk: chunk_16): score=0.5500, confidence=100.00%
Document 870 (chunk: chunk_834): score=0.5161, confidence=93.83%
Document 840 (chunk: chunk_806): score=0.5054, confidence=91.89%
Document 1409 (chunk: chunk_1352): score=0.5023, confidence=91.33%
Document 1076 (chunk: chunk_1027): score=0.4641, confidence=84.38%
2025-04-14 21:15:43,692 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-14 21:15:43,692 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-14 21:15:48,389 - INFO - Token usage: prompt=1141, completion=766, total=1907
2025-04-14 21:15:48,392 - INFO - Agent workflow completed in 6.79s
2025-04-14 21:15:48,410 - INFO - Request processed in 6.81s (thinking: 4.71s)
2025-04-14 21:15:48,411 - INFO - 127.0.0.1 - - [14/Apr/2025 21:15:48] "POST /ask HTTP/1.1" 200 -
2025-04-14 21:17:20,484 - INFO - Processing query: 'Quelle est la portée juridique de la capacité contractuelle d’un mineur de plus de treize ans mais de moins de vingt ans non assisté par son représentant légal, ?' for conversation 30
2025-04-14 21:17:20,485 - INFO - Query received: Quelle est la portée juridique de la capacité contractuelle d’un mineur de plus de treize ans mais de moins de vingt ans non assisté par son représentant légal, ?
2025-04-14 21:17:20,528 - INFO - Search scores:
Document 407 (chunk: chunk_388): score=0.5560, confidence=100.00%
Document 5 (chunk: chunk_5): score=0.4890, confidence=87.96%
Document 4 (chunk: chunk_4): score=0.4061, confidence=73.04%
Document 349 (chunk: chunk_330): score=0.4020, confidence=72.31%
Document 265 (chunk: chunk_252): score=0.3992, confidence=71.80%
2025-04-14 21:17:20,532 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-14 21:17:20,532 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-14 21:17:24,359 - INFO - Token usage: prompt=1023, completion=909, total=1932
2025-04-14 21:17:24,362 - INFO - Agent workflow completed in 3.89s
2025-04-14 21:17:24,383 - INFO - Request processed in 3.91s (thinking: 3.83s)
2025-04-14 21:17:24,383 - INFO - 127.0.0.1 - - [14/Apr/2025 21:17:24] "POST /ask HTTP/1.1" 200 -
2025-04-14 21:18:52,224 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-14 21:18:52,388 - ERROR - HTTP error occurred: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions (Status code: 400)
2025-04-14 21:18:52,388 - ERROR - Error generating title: Bad request to Groq API: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions
2025-04-14 21:18:52,397 - INFO - Processing query: 'Si je me suis trompé en signant, est-ce que je peux annuler le contrat ?' for conversation 31
2025-04-14 21:18:52,399 - INFO - Query received: Si je me suis trompé en signant, est-ce que je peux annuler le contrat ?
2025-04-14 21:18:52,432 - INFO - Search scores:
Document 545 (chunk: chunk_517): score=0.5000, confidence=100.00%
Document 1308 (chunk: chunk_1251): score=0.4785, confidence=95.70%
Document 872 (chunk: chunk_836): score=0.4417, confidence=88.33%
Document 997 (chunk: chunk_950): score=0.3825, confidence=76.51%
Document 1114 (chunk: chunk_1063): score=0.3802, confidence=76.05%
2025-04-14 21:18:52,436 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-14 21:18:52,436 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-14 21:18:55,625 - INFO - Token usage: prompt=1314, completion=779, total=2093
2025-04-14 21:18:55,627 - INFO - Agent workflow completed in 3.40s
2025-04-14 21:18:55,648 - INFO - Request processed in 3.42s (thinking: 3.19s)
2025-04-14 21:18:55,648 - INFO - 127.0.0.1 - - [14/Apr/2025 21:18:55] "POST /ask HTTP/1.1" 200 -
2025-04-14 21:19:23,215 - INFO - Processing query: 'Dans quelles hypothèses l’erreur constitue-t-elle un vice du consentement justifiant la nullité d’un contrat ?' for conversation 31
2025-04-14 21:19:23,216 - INFO - Query received: Dans quelles hypothèses l’erreur constitue-t-elle un vice du consentement justifiant la nullité d’un contrat ?
2025-04-14 21:19:23,254 - INFO - Search scores:
Document 44 (chunk: chunk_44): score=0.5000, confidence=100.00%
Document 342 (chunk: chunk_323): score=0.4749, confidence=94.97%
Document 692 (chunk: chunk_660): score=0.4468, confidence=89.36%
Document 411 (chunk: chunk_392): score=0.4266, confidence=85.32%
Document 45 (chunk: chunk_45): score=0.4117, confidence=82.35%
2025-04-14 21:19:23,258 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-14 21:19:23,258 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-14 21:19:26,394 - INFO - Token usage: prompt=1194, completion=730, total=1924
2025-04-14 21:19:26,396 - INFO - Agent workflow completed in 3.19s
2025-04-14 21:19:26,416 - INFO - Request processed in 3.21s (thinking: 3.14s)
2025-04-14 21:19:26,416 - INFO - 127.0.0.1 - - [14/Apr/2025 21:19:26] "POST /ask HTTP/1.1" 200 -
2025-04-14 21:23:39,663 - INFO - 127.0.0.1 - - [14/Apr/2025 21:23:39] "GET / HTTP/1.1" 200 -
2025-04-14 21:23:39,743 - INFO - 127.0.0.1 - - [14/Apr/2025 21:23:39] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-14 21:23:39,922 - INFO - 127.0.0.1 - - [14/Apr/2025 21:23:39] "GET /get_conversations HTTP/1.1" 200 -
2025-04-14 21:23:52,905 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-14 21:23:53,091 - ERROR - HTTP error occurred: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions (Status code: 400)
2025-04-14 21:23:53,091 - ERROR - Error generating title: Bad request to Groq API: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions
2025-04-14 21:23:53,100 - INFO - Processing query: 'Si quelqu’un me cause un dommage, il est obligé de me rembourser ?' for conversation 32
2025-04-14 21:23:53,101 - INFO - Query received: Si quelqu’un me cause un dommage, il est obligé de me rembourser ?
2025-04-14 21:23:53,134 - INFO - Search scores:
Document 81 (chunk: chunk_81): score=0.5000, confidence=100.00%
Document 792 (chunk: chunk_760): score=0.4617, confidence=92.34%
Document 103 (chunk: chunk_96): score=0.4454, confidence=89.08%
Document 82 (chunk: chunk_82): score=0.4364, confidence=87.29%
Document 184 (chunk: chunk_173): score=0.4345, confidence=86.90%
2025-04-14 21:23:53,137 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-14 21:23:53,137 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-14 21:23:56,819 - INFO - Token usage: prompt=1201, completion=911, total=2112
2025-04-14 21:23:56,821 - INFO - Agent workflow completed in 3.92s
2025-04-14 21:23:56,846 - INFO - Request processed in 3.94s (thinking: 3.69s)
2025-04-14 21:23:56,847 - INFO - 127.0.0.1 - - [14/Apr/2025 21:23:56] "POST /ask HTTP/1.1" 200 -
2025-04-14 21:26:20,836 - INFO - Processing query: 'Quels sont les fondements de la responsabilité civile extracontractuelle en cas de dommage causé volontairement ou par négligence ?' for conversation 32
2025-04-14 21:26:20,837 - INFO - Query received: Quels sont les fondements de la responsabilité civile extracontractuelle en cas de dommage causé volontairement ou par négligence ?
2025-04-14 21:26:20,874 - INFO - Search scores:
Document 113 (chunk: chunk_104): score=0.7340, confidence=100.00%
Document 112 (chunk: chunk_103): score=0.7141, confidence=97.30%
Document 111 (chunk: chunk_102): score=0.6840, confidence=93.20%
Document 104 (chunk: chunk_97): score=0.5791, confidence=78.90%
Document 99 (chunk: chunk_93_sub_2): score=0.5140, confidence=70.04%
2025-04-14 21:26:20,878 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-14 21:26:20,878 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-14 21:26:25,080 - INFO - Token usage: prompt=1408, completion=1051, total=2459
2025-04-14 21:26:25,082 - INFO - Agent workflow completed in 4.25s
2025-04-14 21:26:25,112 - INFO - Request processed in 4.28s (thinking: 4.21s)
2025-04-14 21:26:25,113 - INFO - 127.0.0.1 - - [14/Apr/2025 21:26:25] "POST /ask HTTP/1.1" 200 -
2025-04-14 21:36:25,042 - INFO - 127.0.0.1 - - [14/Apr/2025 21:36:25] "GET / HTTP/1.1" 200 -
2025-04-14 21:36:25,112 - INFO - 127.0.0.1 - - [14/Apr/2025 21:36:25] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-14 21:36:25,299 - INFO - 127.0.0.1 - - [14/Apr/2025 21:36:25] "GET /get_conversations HTTP/1.1" 200 -
2025-04-14 21:38:24,829 - INFO - 127.0.0.1 - - [14/Apr/2025 21:38:24] "GET / HTTP/1.1" 200 -
2025-04-14 21:38:24,907 - INFO - 127.0.0.1 - - [14/Apr/2025 21:38:24] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-14 21:38:25,080 - INFO - 127.0.0.1 - - [14/Apr/2025 21:38:25] "GET /get_conversations HTTP/1.1" 200 -
2025-04-14 21:38:51,655 - INFO - Sending request to Groq API: model=llama-3.2-1b-preview, temperature=0.7, max_tokens=1000
2025-04-14 21:38:51,840 - ERROR - HTTP error occurred: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions (Status code: 400)
2025-04-14 21:38:51,840 - ERROR - Error generating title: Bad request to Groq API: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions
2025-04-14 21:38:51,850 - INFO - Processing query: 'Est-ce qu’on peut faire un contrat sur n’importe quoi ?' for conversation 33
2025-04-14 21:38:51,852 - INFO - Query received: Est-ce qu’on peut faire un contrat sur n’importe quoi ?
2025-04-14 21:38:51,887 - INFO - Search scores:
Document 1294 (chunk: chunk_1237): score=0.5415, confidence=100.00%
Document 82 (chunk: chunk_82): score=0.5000, confidence=92.34%
Document 902 (chunk: chunk_864): score=0.4866, confidence=89.86%
Document 755 (chunk: chunk_723): score=0.4749, confidence=87.71%
Document 22 (chunk: chunk_22): score=0.4571, confidence=84.42%
2025-04-14 21:38:51,891 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-14 21:38:51,891 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-14 21:38:56,484 - INFO - Token usage: prompt=1293, completion=1088, total=2381
2025-04-14 21:38:56,486 - INFO - Agent workflow completed in 4.83s
2025-04-14 21:38:56,527 - INFO - Request processed in 4.87s (thinking: 4.60s)
2025-04-14 21:38:56,527 - INFO - 127.0.0.1 - - [14/Apr/2025 21:38:56] "POST /ask HTTP/1.1" 200 -
2025-04-14 21:39:06,664 - INFO - Processing query: 'L’objet et la cause d’une obligation doivent-ils répondre à des critères de licéité et de possibilité ? Quels sont les effets d’une cause illicite ?' for conversation 33
2025-04-14 21:39:06,665 - INFO - Query received: L’objet et la cause d’une obligation doivent-ils répondre à des critères de licéité et de possibilité ? Quels sont les effets d’une cause illicite ?
2025-04-14 21:39:06,704 - INFO - Search scores:
Document 66 (chunk: chunk_66): score=0.5545, confidence=100.00%
Document 1 (chunk: chunk_1): score=0.5243, confidence=94.54%
Document 250 (chunk: chunk_237): score=0.5159, confidence=93.03%
Document 654 (chunk: chunk_626): score=0.5082, confidence=91.64%
Document 506 (chunk: chunk_478): score=0.5000, confidence=90.16%
2025-04-14 21:39:06,707 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-14 21:39:06,708 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-14 21:39:10,223 - INFO - Token usage: prompt=1321, completion=867, total=2188
2025-04-14 21:39:10,225 - INFO - Agent workflow completed in 3.57s
2025-04-14 21:39:10,249 - INFO - Request processed in 3.59s (thinking: 3.52s)
2025-04-14 21:39:10,249 - INFO - 127.0.0.1 - - [14/Apr/2025 21:39:10] "POST /ask HTTP/1.1" 200 -
2025-04-15 10:45:10,924 - WARNING - Config file config.yaml not found, using defaults.
2025-04-15 10:45:10,966 - INFO - Use pytorch device_name: cuda
2025-04-15 10:45:10,966 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-15 10:45:51,439 - INFO - Loading pre-built indexes...
2025-04-15 10:45:56,239 - INFO - Loaded 1460 legal document chunks
2025-04-15 10:45:56,275 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.3:5000
2025-04-15 10:45:56,275 - INFO - [33mPress CTRL+C to quit[0m
2025-04-15 10:46:44,045 - INFO - 127.0.0.1 - - [15/Apr/2025 10:46:44] "[33mGET /chapters/document/4 HTTP/1.1[0m" 404 -
2025-04-15 10:46:45,584 - INFO - 127.0.0.1 - - [15/Apr/2025 10:46:45] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-04-15 10:46:46,182 - INFO - 127.0.0.1 - - [15/Apr/2025 10:46:46] "GET / HTTP/1.1" 200 -
2025-04-15 10:46:46,783 - INFO - 127.0.0.1 - - [15/Apr/2025 10:46:46] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-15 10:46:47,327 - INFO - 127.0.0.1 - - [15/Apr/2025 10:46:47] "GET /get_conversations HTTP/1.1" 200 -
2025-04-15 10:46:52,957 - INFO - 127.0.0.1 - - [15/Apr/2025 10:46:52] "DELETE /delete_conversation/33 HTTP/1.1" 200 -
2025-04-15 10:46:55,339 - INFO - 127.0.0.1 - - [15/Apr/2025 10:46:55] "DELETE /delete_conversation/32 HTTP/1.1" 200 -
2025-04-15 10:46:56,656 - INFO - 127.0.0.1 - - [15/Apr/2025 10:46:56] "GET /get_conversation/31 HTTP/1.1" 200 -
2025-04-15 10:47:03,014 - INFO - 127.0.0.1 - - [15/Apr/2025 10:47:03] "GET / HTTP/1.1" 200 -
2025-04-15 10:47:03,558 - INFO - 127.0.0.1 - - [15/Apr/2025 10:47:03] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-15 10:47:03,822 - INFO - 127.0.0.1 - - [15/Apr/2025 10:47:03] "GET /get_conversations HTTP/1.1" 200 -
2025-04-15 10:47:06,623 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-04-15 10:47:07,185 - INFO - Token usage: prompt=76, completion=10, total=86
2025-04-15 10:47:07,199 - INFO - Processing query: 'Dans quelles hypothèses l’erreur constitue-t-elle un vice du consentement justifiant la nullité d’un contrat ?' for conversation 34
2025-04-15 10:47:07,227 - INFO - Query received: Dans quelles hypothèses l’erreur constitue-t-elle un vice du consentement justifiant la nullité d’un contrat ?
2025-04-15 10:47:09,412 - INFO - Search scores:
Document 44 (chunk: chunk_44): score=0.5000, confidence=100.00%
Document 342 (chunk: chunk_323): score=0.4749, confidence=94.97%
Document 692 (chunk: chunk_660): score=0.4468, confidence=89.36%
Document 411 (chunk: chunk_392): score=0.4266, confidence=85.32%
Document 45 (chunk: chunk_45): score=0.4117, confidence=82.35%
2025-04-15 10:47:09,418 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-04-15 10:47:09,418 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-04-15 10:47:11,913 - INFO - Token usage: prompt=1194, completion=606, total=1800
2025-04-15 10:47:11,917 - INFO - Agent workflow completed in 5.29s
2025-04-15 10:47:11,937 - INFO - Request processed in 5.31s (thinking: 2.50s)
2025-04-15 10:47:11,938 - INFO - 127.0.0.1 - - [15/Apr/2025 10:47:11] "POST /ask HTTP/1.1" 200 -
2025-04-15 10:50:20,520 - INFO - 127.0.0.1 - - [15/Apr/2025 10:50:20] "GET / HTTP/1.1" 200 -
2025-04-15 10:50:20,598 - INFO - 127.0.0.1 - - [15/Apr/2025 10:50:20] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-15 10:50:20,776 - INFO - 127.0.0.1 - - [15/Apr/2025 10:50:20] "GET /get_conversations HTTP/1.1" 200 -
2025-04-21 16:43:27,030 - WARNING - Config file config.yaml not found, using defaults.
2025-04-21 16:43:27,060 - INFO - Use pytorch device_name: cuda
2025-04-21 16:43:27,060 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-21 16:43:45,680 - INFO - Loading pre-built indexes...
2025-04-21 16:43:49,212 - INFO - Loaded 1460 legal document chunks
2025-04-21 16:44:01,528 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.139.177:5000
2025-04-21 16:44:01,528 - INFO - [33mPress CTRL+C to quit[0m
2025-04-21 16:44:01,856 - INFO - 127.0.0.1 - - [21/Apr/2025 16:44:01] "GET / HTTP/1.1" 200 -
2025-04-21 16:44:02,088 - INFO - 127.0.0.1 - - [21/Apr/2025 16:44:02] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-21 16:44:08,812 - INFO - 127.0.0.1 - - [21/Apr/2025 16:44:08] "GET /get_conversations HTTP/1.1" 200 -
2025-04-22 09:45:07,686 - WARNING - Config file config.yaml not found, using defaults.
2025-04-22 09:45:07,702 - INFO - Use pytorch device_name: cuda
2025-04-22 09:45:07,702 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-04-22 09:45:15,267 - INFO - Loading pre-built indexes...
2025-04-22 09:45:18,498 - INFO - Loaded 1460 legal document chunks
2025-04-22 09:45:19,964 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.59.76:5000
2025-04-22 09:45:19,964 - INFO - [33mPress CTRL+C to quit[0m
2025-04-22 09:45:34,757 - INFO - 127.0.0.1 - - [22/Apr/2025 09:45:34] "GET / HTTP/1.1" 200 -
2025-04-22 09:45:34,766 - INFO - 127.0.0.1 - - [22/Apr/2025 09:45:34] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-22 09:45:35,195 - INFO - 127.0.0.1 - - [22/Apr/2025 09:45:35] "GET /get_conversations HTTP/1.1" 200 -
2025-04-22 09:45:42,258 - INFO - 127.0.0.1 - - [22/Apr/2025 09:45:42] "GET /get_conversation/34 HTTP/1.1" 200 -
2025-04-22 09:45:42,514 - INFO - 127.0.0.1 - - [22/Apr/2025 09:45:42] "GET /get_conversation/34 HTTP/1.1" 200 -
2025-04-22 09:45:54,035 - INFO - 127.0.0.1 - - [22/Apr/2025 09:45:54] "GET /get_conversation/31 HTTP/1.1" 200 -
2025-04-22 09:45:55,297 - INFO - 127.0.0.1 - - [22/Apr/2025 09:45:55] "GET /get_conversation/34 HTTP/1.1" 200 -
2025-04-22 09:54:13,154 - INFO - 127.0.0.1 - - [22/Apr/2025 09:54:13] "GET / HTTP/1.1" 200 -
2025-04-22 09:54:13,162 - INFO - 127.0.0.1 - - [22/Apr/2025 09:54:13] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-04-22 09:54:13,423 - INFO - 127.0.0.1 - - [22/Apr/2025 09:54:13] "GET /get_conversations HTTP/1.1" 200 -
2025-04-22 09:54:13,497 - INFO - 127.0.0.1 - - [22/Apr/2025 09:54:13] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-04-22 09:54:15,006 - INFO - 127.0.0.1 - - [22/Apr/2025 09:54:15] "GET /get_conversation/29 HTTP/1.1" 200 -
2025-04-22 09:54:16,026 - INFO - 127.0.0.1 - - [22/Apr/2025 09:54:16] "GET /get_conversation/30 HTTP/1.1" 200 -
2025-05-05 15:52:55,832 - INFO - Use pytorch device_name: cpu
2025-05-05 15:52:55,833 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 16:00:06,189 - INFO - Rebuilding indexes due to updated data...
2025-05-05 16:00:10,939 - INFO - Parsed 1460 legal document chunks
2025-05-05 16:00:10,939 - INFO - Processing batch 1/183: chunks 0 to 7
2025-05-05 16:00:11,989 - INFO - Processing batch 2/183: chunks 8 to 15
2025-05-05 16:00:12,649 - INFO - Processing batch 3/183: chunks 16 to 23
2025-05-05 16:00:13,319 - INFO - Processing batch 4/183: chunks 24 to 31
2025-05-05 16:00:13,682 - INFO - Processing batch 5/183: chunks 32 to 39
2025-05-05 16:00:15,198 - INFO - Processing batch 6/183: chunks 40 to 47
2025-05-05 16:00:15,821 - INFO - Processing batch 7/183: chunks 48 to 55
2025-05-05 16:00:16,626 - INFO - Processing batch 8/183: chunks 56 to 63
2025-05-05 16:00:17,143 - INFO - Processing batch 9/183: chunks 64 to 71
2025-05-05 16:00:17,779 - INFO - Processing batch 10/183: chunks 72 to 79
2025-05-05 16:00:18,423 - INFO - Processing batch 11/183: chunks 80 to 87
2025-05-05 16:00:19,049 - INFO - Processing batch 12/183: chunks 88 to 95
2025-05-05 16:00:19,698 - INFO - Processing batch 13/183: chunks 96 to 103
2025-05-05 16:00:20,361 - INFO - Processing batch 14/183: chunks 104 to 111
2025-05-05 16:00:21,414 - INFO - Processing batch 15/183: chunks 112 to 119
2025-05-05 16:00:22,070 - INFO - Processing batch 16/183: chunks 120 to 127
2025-05-05 16:00:22,894 - INFO - Processing batch 17/183: chunks 128 to 135
2025-05-05 16:00:23,976 - INFO - Processing batch 18/183: chunks 136 to 143
2025-05-05 16:00:24,909 - INFO - Processing batch 19/183: chunks 144 to 151
2025-05-05 16:00:25,604 - INFO - Processing batch 20/183: chunks 152 to 159
2025-05-05 16:00:26,633 - INFO - Processing batch 21/183: chunks 160 to 167
2025-05-05 16:00:27,369 - INFO - Processing batch 22/183: chunks 168 to 175
2025-05-05 16:00:28,059 - INFO - Processing batch 23/183: chunks 176 to 183
2025-05-05 16:00:28,876 - INFO - Processing batch 24/183: chunks 184 to 191
2025-05-05 16:00:29,384 - INFO - Processing batch 25/183: chunks 192 to 199
2025-05-05 16:00:30,165 - INFO - Processing batch 26/183: chunks 200 to 207
2025-05-05 16:00:30,933 - INFO - Processing batch 27/183: chunks 208 to 215
2025-05-05 16:00:31,631 - INFO - Processing batch 28/183: chunks 216 to 223
2025-05-05 16:00:32,410 - INFO - Processing batch 29/183: chunks 224 to 231
2025-05-05 16:00:33,146 - INFO - Processing batch 30/183: chunks 232 to 239
2025-05-05 16:00:33,937 - INFO - Processing batch 31/183: chunks 240 to 247
2025-05-05 16:00:34,787 - INFO - Processing batch 32/183: chunks 248 to 255
2025-05-05 16:00:35,609 - INFO - Processing batch 33/183: chunks 256 to 263
2025-05-05 16:00:36,489 - INFO - Processing batch 34/183: chunks 264 to 271
2025-05-05 16:00:37,404 - INFO - Processing batch 35/183: chunks 272 to 279
2025-05-05 16:00:38,262 - INFO - Processing batch 36/183: chunks 280 to 287
2025-05-05 16:00:39,059 - INFO - Processing batch 37/183: chunks 288 to 295
2025-05-05 16:00:40,039 - INFO - Processing batch 38/183: chunks 296 to 303
2025-05-05 16:00:41,028 - INFO - Processing batch 39/183: chunks 304 to 311
2025-05-05 16:00:41,723 - INFO - Processing batch 40/183: chunks 312 to 319
2025-05-05 16:00:42,346 - INFO - Processing batch 41/183: chunks 320 to 327
2025-05-05 16:00:43,170 - INFO - Processing batch 42/183: chunks 328 to 335
2025-05-05 16:00:44,154 - INFO - Processing batch 43/183: chunks 336 to 343
2025-05-05 16:00:45,169 - INFO - Processing batch 44/183: chunks 344 to 351
2025-05-05 16:00:46,067 - INFO - Processing batch 45/183: chunks 352 to 359
2025-05-05 16:00:46,852 - INFO - Processing batch 46/183: chunks 360 to 367
2025-05-05 16:00:47,499 - INFO - Processing batch 47/183: chunks 368 to 375
2025-05-05 16:00:48,235 - INFO - Processing batch 48/183: chunks 376 to 383
2025-05-05 16:00:48,975 - INFO - Processing batch 49/183: chunks 384 to 391
2025-05-05 16:00:49,437 - INFO - Processing batch 50/183: chunks 392 to 399
2025-05-05 16:00:50,167 - INFO - Processing batch 51/183: chunks 400 to 407
2025-05-05 16:00:50,534 - INFO - Processing batch 52/183: chunks 408 to 415
2025-05-05 16:00:51,319 - INFO - Processing batch 53/183: chunks 416 to 423
2025-05-05 16:00:52,046 - INFO - Processing batch 54/183: chunks 424 to 431
2025-05-05 16:00:52,733 - INFO - Processing batch 55/183: chunks 432 to 439
2025-05-05 16:00:53,414 - INFO - Processing batch 56/183: chunks 440 to 447
2025-05-05 16:00:53,942 - INFO - Processing batch 57/183: chunks 448 to 455
2025-05-05 16:00:54,814 - INFO - Processing batch 58/183: chunks 456 to 463
2025-05-05 16:00:55,522 - INFO - Processing batch 59/183: chunks 464 to 471
2025-05-05 16:00:56,298 - INFO - Processing batch 60/183: chunks 472 to 479
2025-05-05 16:00:56,940 - INFO - Processing batch 61/183: chunks 480 to 487
2025-05-05 16:00:57,611 - INFO - Processing batch 62/183: chunks 488 to 495
2025-05-05 16:00:58,302 - INFO - Processing batch 63/183: chunks 496 to 503
2025-05-05 16:00:58,928 - INFO - Processing batch 64/183: chunks 504 to 511
2025-05-05 16:00:59,805 - INFO - Processing batch 65/183: chunks 512 to 519
2025-05-05 16:01:00,580 - INFO - Processing batch 66/183: chunks 520 to 527
2025-05-05 16:01:01,283 - INFO - Processing batch 67/183: chunks 528 to 535
2025-05-05 16:01:01,864 - INFO - Processing batch 68/183: chunks 536 to 543
2025-05-05 16:01:02,428 - INFO - Processing batch 69/183: chunks 544 to 551
2025-05-05 16:01:03,072 - INFO - Processing batch 70/183: chunks 552 to 559
2025-05-05 16:01:03,444 - INFO - Processing batch 71/183: chunks 560 to 567
2025-05-05 16:01:03,784 - INFO - Processing batch 72/183: chunks 568 to 575
2025-05-05 16:01:04,075 - INFO - Processing batch 73/183: chunks 576 to 583
2025-05-05 16:01:04,339 - INFO - Processing batch 74/183: chunks 584 to 591
2025-05-05 16:01:05,211 - INFO - Processing batch 75/183: chunks 592 to 599
2025-05-05 16:01:05,914 - INFO - Processing batch 76/183: chunks 600 to 607
2025-05-05 16:01:06,724 - INFO - Processing batch 77/183: chunks 608 to 615
2025-05-05 16:01:07,362 - INFO - Processing batch 78/183: chunks 616 to 623
2025-05-05 16:01:08,103 - INFO - Processing batch 79/183: chunks 624 to 631
2025-05-05 16:01:08,822 - INFO - Processing batch 80/183: chunks 632 to 639
2025-05-05 16:01:09,518 - INFO - Processing batch 81/183: chunks 640 to 647
2025-05-05 16:01:10,414 - INFO - Processing batch 82/183: chunks 648 to 655
2025-05-05 16:01:11,059 - INFO - Processing batch 83/183: chunks 656 to 663
2025-05-05 16:01:11,699 - INFO - Processing batch 84/183: chunks 664 to 671
2025-05-05 16:01:12,425 - INFO - Processing batch 85/183: chunks 672 to 679
2025-05-05 16:01:13,144 - INFO - Processing batch 86/183: chunks 680 to 687
2025-05-05 16:01:13,919 - INFO - Processing batch 87/183: chunks 688 to 695
2025-05-05 16:01:14,579 - INFO - Processing batch 88/183: chunks 696 to 703
2025-05-05 16:01:15,216 - INFO - Processing batch 89/183: chunks 704 to 711
2025-05-05 16:01:15,919 - INFO - Processing batch 90/183: chunks 712 to 719
2025-05-05 16:01:16,599 - INFO - Processing batch 91/183: chunks 720 to 727
2025-05-05 16:01:17,361 - INFO - Processing batch 92/183: chunks 728 to 735
2025-05-05 16:01:17,860 - INFO - Processing batch 93/183: chunks 736 to 743
2025-05-05 16:01:18,627 - INFO - Processing batch 94/183: chunks 744 to 751
2025-05-05 16:01:19,359 - INFO - Processing batch 95/183: chunks 752 to 759
2025-05-05 16:01:20,135 - INFO - Processing batch 96/183: chunks 760 to 767
2025-05-05 16:01:20,828 - INFO - Processing batch 97/183: chunks 768 to 775
2025-05-05 16:01:21,556 - INFO - Processing batch 98/183: chunks 776 to 783
2025-05-05 16:01:22,232 - INFO - Processing batch 99/183: chunks 784 to 791
2025-05-05 16:01:22,811 - INFO - Processing batch 100/183: chunks 792 to 799
2025-05-05 16:01:23,545 - INFO - Processing batch 101/183: chunks 800 to 807
2025-05-05 16:01:24,135 - INFO - Processing batch 102/183: chunks 808 to 815
2025-05-05 16:01:24,660 - INFO - Processing batch 103/183: chunks 816 to 823
2025-05-05 16:01:25,513 - INFO - Processing batch 104/183: chunks 824 to 831
2025-05-05 16:01:26,310 - INFO - Processing batch 105/183: chunks 832 to 839
2025-05-05 16:01:27,117 - INFO - Processing batch 106/183: chunks 840 to 847
2025-05-05 16:01:27,746 - INFO - Processing batch 107/183: chunks 848 to 855
2025-05-05 16:01:28,532 - INFO - Processing batch 108/183: chunks 856 to 863
2025-05-05 16:01:29,375 - INFO - Processing batch 109/183: chunks 864 to 871
2025-05-05 16:01:30,045 - INFO - Processing batch 110/183: chunks 872 to 879
2025-05-05 16:01:30,799 - INFO - Processing batch 111/183: chunks 880 to 887
2025-05-05 16:01:31,501 - INFO - Processing batch 112/183: chunks 888 to 895
2025-05-05 16:01:32,319 - INFO - Processing batch 113/183: chunks 896 to 903
2025-05-05 16:01:33,056 - INFO - Processing batch 114/183: chunks 904 to 911
2025-05-05 16:01:33,838 - INFO - Processing batch 115/183: chunks 912 to 919
2025-05-05 16:01:34,527 - INFO - Processing batch 116/183: chunks 920 to 927
2025-05-05 16:01:35,144 - INFO - Processing batch 117/183: chunks 928 to 935
2025-05-05 16:01:35,769 - INFO - Processing batch 118/183: chunks 936 to 943
2025-05-05 16:01:36,448 - INFO - Processing batch 119/183: chunks 944 to 951
2025-05-05 16:01:37,021 - INFO - Processing batch 120/183: chunks 952 to 959
2025-05-05 16:01:37,651 - INFO - Processing batch 121/183: chunks 960 to 967
2025-05-05 16:01:38,326 - INFO - Processing batch 122/183: chunks 968 to 975
2025-05-05 16:01:39,048 - INFO - Processing batch 123/183: chunks 976 to 983
2025-05-05 16:01:39,742 - INFO - Processing batch 124/183: chunks 984 to 991
2025-05-05 16:01:40,464 - INFO - Processing batch 125/183: chunks 992 to 999
2025-05-05 16:01:41,157 - INFO - Processing batch 126/183: chunks 1000 to 1007
2025-05-05 16:01:41,507 - INFO - Processing batch 127/183: chunks 1008 to 1015
2025-05-05 16:01:42,056 - INFO - Processing batch 128/183: chunks 1016 to 1023
2025-05-05 16:01:42,559 - INFO - Processing batch 129/183: chunks 1024 to 1031
2025-05-05 16:01:43,321 - INFO - Processing batch 130/183: chunks 1032 to 1039
2025-05-05 16:01:44,007 - INFO - Processing batch 131/183: chunks 1040 to 1047
2025-05-05 16:01:44,655 - INFO - Processing batch 132/183: chunks 1048 to 1055
2025-05-05 16:01:45,407 - INFO - Processing batch 133/183: chunks 1056 to 1063
2025-05-05 16:01:46,093 - INFO - Processing batch 134/183: chunks 1064 to 1071
2025-05-05 16:01:46,788 - INFO - Processing batch 135/183: chunks 1072 to 1079
2025-05-05 16:01:47,507 - INFO - Processing batch 136/183: chunks 1080 to 1087
2025-05-05 16:01:48,154 - INFO - Processing batch 137/183: chunks 1088 to 1095
2025-05-05 16:01:48,917 - INFO - Processing batch 138/183: chunks 1096 to 1103
2025-05-05 16:01:49,551 - INFO - Processing batch 139/183: chunks 1104 to 1111
2025-05-05 16:01:49,897 - INFO - Processing batch 140/183: chunks 1112 to 1119
2025-05-05 16:01:50,622 - INFO - Processing batch 141/183: chunks 1120 to 1127
2025-05-05 16:01:51,299 - INFO - Processing batch 142/183: chunks 1128 to 1135
2025-05-05 16:01:51,984 - INFO - Processing batch 143/183: chunks 1136 to 1143
2025-05-05 16:01:52,642 - INFO - Processing batch 144/183: chunks 1144 to 1151
2025-05-05 16:01:53,303 - INFO - Processing batch 145/183: chunks 1152 to 1159
2025-05-05 16:01:54,104 - INFO - Processing batch 146/183: chunks 1160 to 1167
2025-05-05 16:01:54,974 - INFO - Processing batch 147/183: chunks 1168 to 1175
2025-05-05 16:01:55,809 - INFO - Processing batch 148/183: chunks 1176 to 1183
2025-05-05 16:01:56,747 - INFO - Processing batch 149/183: chunks 1184 to 1191
2025-05-05 16:01:57,585 - INFO - Processing batch 150/183: chunks 1192 to 1199
2025-05-05 16:01:58,434 - INFO - Processing batch 151/183: chunks 1200 to 1207
2025-05-05 16:01:59,247 - INFO - Processing batch 152/183: chunks 1208 to 1215
2025-05-05 16:02:00,213 - INFO - Processing batch 153/183: chunks 1216 to 1223
2025-05-05 16:02:01,104 - INFO - Processing batch 154/183: chunks 1224 to 1231
2025-05-05 16:02:01,849 - INFO - Processing batch 155/183: chunks 1232 to 1239
2025-05-05 16:02:02,610 - INFO - Processing batch 156/183: chunks 1240 to 1247
2025-05-05 16:02:03,308 - INFO - Processing batch 157/183: chunks 1248 to 1255
2025-05-05 16:02:04,106 - INFO - Processing batch 158/183: chunks 1256 to 1263
2025-05-05 16:02:05,080 - INFO - Processing batch 159/183: chunks 1264 to 1271
2025-05-05 16:02:05,924 - INFO - Processing batch 160/183: chunks 1272 to 1279
2025-05-05 16:02:06,559 - INFO - Processing batch 161/183: chunks 1280 to 1287
2025-05-05 16:02:07,217 - INFO - Processing batch 162/183: chunks 1288 to 1295
2025-05-05 16:02:07,987 - INFO - Processing batch 163/183: chunks 1296 to 1303
2025-05-05 16:02:08,655 - INFO - Processing batch 164/183: chunks 1304 to 1311
2025-05-05 16:02:09,428 - INFO - Processing batch 165/183: chunks 1312 to 1319
2025-05-05 16:02:10,244 - INFO - Processing batch 166/183: chunks 1320 to 1327
2025-05-05 16:02:11,118 - INFO - Processing batch 167/183: chunks 1328 to 1335
2025-05-05 16:02:11,752 - INFO - Processing batch 168/183: chunks 1336 to 1343
2025-05-05 16:02:12,494 - INFO - Processing batch 169/183: chunks 1344 to 1351
2025-05-05 16:02:13,176 - INFO - Processing batch 170/183: chunks 1352 to 1359
2025-05-05 16:02:13,959 - INFO - Processing batch 171/183: chunks 1360 to 1367
2025-05-05 16:02:14,549 - INFO - Processing batch 172/183: chunks 1368 to 1375
2025-05-05 16:02:15,322 - INFO - Processing batch 173/183: chunks 1376 to 1383
2025-05-05 16:02:16,135 - INFO - Processing batch 174/183: chunks 1384 to 1391
2025-05-05 16:02:16,898 - INFO - Processing batch 175/183: chunks 1392 to 1399
2025-05-05 16:02:17,913 - INFO - Processing batch 176/183: chunks 1400 to 1407
2025-05-05 16:02:18,627 - INFO - Processing batch 177/183: chunks 1408 to 1415
2025-05-05 16:02:19,212 - INFO - Processing batch 178/183: chunks 1416 to 1423
2025-05-05 16:02:19,971 - INFO - Processing batch 179/183: chunks 1424 to 1431
2025-05-05 16:02:20,778 - INFO - Processing batch 180/183: chunks 1432 to 1439
2025-05-05 16:02:21,812 - INFO - Processing batch 181/183: chunks 1440 to 1447
2025-05-05 16:02:22,753 - INFO - Processing batch 182/183: chunks 1448 to 1455
2025-05-05 16:02:23,185 - INFO - Processing batch 183/183: chunks 1456 to 1459
2025-05-05 16:02:23,508 - INFO - Saving indexes to disk...
2025-05-05 16:02:23,646 - INFO - Successfully built and saved all indexes
2025-05-05 16:02:23,673 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.213.235:5000
2025-05-05 16:02:23,674 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 16:33:37,230 - INFO - Use pytorch device_name: cpu
2025-05-05 16:33:37,230 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 16:33:43,722 - WARNING - Created empty data folder: legal_texts
2025-05-05 16:33:43,736 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.213.235:5000
2025-05-05 16:33:43,736 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 16:35:36,038 - INFO - Use pytorch device_name: cpu
2025-05-05 16:35:36,038 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 16:35:41,779 - WARNING - No text files found in legal_texts
2025-05-05 16:35:41,793 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.213.235:5000
2025-05-05 16:35:41,793 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 16:36:31,131 - INFO - 127.0.0.1 - - [05/May/2025 16:36:31] "GET / HTTP/1.1" 200 -
2025-05-05 16:36:31,162 - INFO - 127.0.0.1 - - [05/May/2025 16:36:31] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 16:36:31,620 - INFO - 127.0.0.1 - - [05/May/2025 16:36:31] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 16:36:32,148 - INFO - 127.0.0.1 - - [05/May/2025 16:36:32] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-05-05 16:36:34,744 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-05 16:36:35,180 - ERROR - HTTP error occurred: 401 Client Error: Unauthorized for url: https://api.groq.com/openai/v1/chat/completions (Status code: 401)
2025-05-05 16:36:35,180 - ERROR - Error generating title: Authentication error: Invalid API key
2025-05-05 16:36:35,210 - INFO - Processing query: 'g' for conversation 35
2025-05-05 16:36:35,231 - INFO - Query received: g
2025-05-05 16:36:35,231 - WARNING - No legal file summaries available for routing
2025-05-05 16:36:36,379 - ERROR - Search failed: 'NoneType' object has no attribute 'search'
2025-05-05 16:36:36,380 - INFO - Agent workflow completed in 1.64s
2025-05-05 16:36:36,399 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 920, in full_dispatch_request
    return self.finalize_request(rv)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 939, in finalize_request
    response = self.make_response(rv)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1212, in make_response
    raise TypeError(
TypeError: The view function for 'ask' did not return a valid response. The function either returned None or ended without a return statement.
2025-05-05 16:36:36,400 - INFO - 127.0.0.1 - - [05/May/2025 16:36:36] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-05 16:37:48,978 - INFO - Use pytorch device_name: cpu
2025-05-05 16:37:48,978 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 16:37:55,123 - WARNING - No text files found in legal_texts
2025-05-05 16:37:55,136 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.213.235:5000
2025-05-05 16:37:55,136 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 16:38:03,966 - INFO - 127.0.0.1 - - [05/May/2025 16:38:03] "GET / HTTP/1.1" 200 -
2025-05-05 16:38:03,996 - INFO - 127.0.0.1 - - [05/May/2025 16:38:03] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 16:38:04,019 - INFO - 127.0.0.1 - - [05/May/2025 16:38:04] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 16:38:07,203 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-05 16:38:07,662 - INFO - Token usage: prompt=51, completion=8, total=59
2025-05-05 16:38:07,703 - INFO - Processing query: 'hello' for conversation 36
2025-05-05 16:38:07,720 - INFO - Query received: hello
2025-05-05 16:38:07,721 - WARNING - No legal file summaries available for routing
2025-05-05 16:38:08,826 - ERROR - Search failed: 'NoneType' object has no attribute 'search'
2025-05-05 16:38:08,826 - INFO - Agent workflow completed in 1.62s
2025-05-05 16:38:08,885 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 920, in full_dispatch_request
    return self.finalize_request(rv)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 939, in finalize_request
    response = self.make_response(rv)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1212, in make_response
    raise TypeError(
TypeError: The view function for 'ask' did not return a valid response. The function either returned None or ended without a return statement.
2025-05-05 16:38:08,888 - INFO - 127.0.0.1 - - [05/May/2025 16:38:08] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-05 16:39:22,759 - INFO - Use pytorch device_name: cpu
2025-05-05 16:39:22,759 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 16:39:30,153 - INFO - Loading pre-built indexes...
2025-05-05 16:39:30,616 - ERROR - Failed to initialize data: 'SentenceTransformer' object has no attribute 'embed_query'
2025-05-05 16:41:09,193 - INFO - Use pytorch device_name: cpu
2025-05-05 16:41:09,193 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 16:41:16,839 - INFO - Loading pre-built indexes...
2025-05-05 16:41:19,260 - INFO - Loaded 862 legal document chunks from 6 files
2025-05-05 16:41:19,278 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.213.235:5000
2025-05-05 16:41:19,278 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 16:41:34,557 - INFO - 127.0.0.1 - - [05/May/2025 16:41:34] "GET / HTTP/1.1" 200 -
2025-05-05 16:41:34,577 - INFO - 127.0.0.1 - - [05/May/2025 16:41:34] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 16:41:34,606 - INFO - 127.0.0.1 - - [05/May/2025 16:41:34] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 16:41:57,756 - INFO - 127.0.0.1 - - [05/May/2025 16:41:57] "GET / HTTP/1.1" 200 -
2025-05-05 16:41:57,777 - INFO - 127.0.0.1 - - [05/May/2025 16:41:57] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 16:41:57,790 - INFO - 127.0.0.1 - - [05/May/2025 16:41:57] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 16:42:09,627 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-05 16:42:12,888 - INFO - Token usage: prompt=51, completion=8, total=59
2025-05-05 16:42:12,918 - INFO - Processing query: 'hello' for conversation 37
2025-05-05 16:42:12,929 - INFO - Query received: hello
2025-05-05 16:42:12,929 - ERROR - Agent workflow failed: 'SentenceTransformer' object has no attribute 'embed_query'
2025-05-05 16:42:12,977 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 920, in full_dispatch_request
    return self.finalize_request(rv)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 939, in finalize_request
    response = self.make_response(rv)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1212, in make_response
    raise TypeError(
TypeError: The view function for 'ask' did not return a valid response. The function either returned None or ended without a return statement.
2025-05-05 16:42:12,978 - INFO - 127.0.0.1 - - [05/May/2025 16:42:12] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-05 16:46:08,118 - INFO - Use pytorch device_name: cpu
2025-05-05 16:46:08,118 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 16:46:17,520 - INFO - Loading pre-built indexes...
2025-05-05 16:46:19,932 - INFO - Loaded 862 legal document chunks from 6 files
2025-05-05 16:46:19,947 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.213.235:5000
2025-05-05 16:46:19,947 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 16:46:25,527 - INFO - 127.0.0.1 - - [05/May/2025 16:46:25] "GET / HTTP/1.1" 200 -
2025-05-05 16:46:25,547 - INFO - 127.0.0.1 - - [05/May/2025 16:46:25] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 16:46:25,560 - INFO - 127.0.0.1 - - [05/May/2025 16:46:25] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 16:46:29,035 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-05 16:46:29,507 - INFO - Token usage: prompt=51, completion=8, total=59
2025-05-05 16:46:29,544 - INFO - Processing query: 'hello' for conversation 38
2025-05-05 16:46:29,558 - INFO - Query received: hello
2025-05-05 16:46:29,586 - INFO - Routing query to loi_relative_commerce_exterieur.txt with similarity score: 2.6602
2025-05-05 16:46:29,996 - ERROR - Search failed: list index out of range
2025-05-05 16:46:29,997 - INFO - Agent workflow completed in 0.96s
2025-05-05 16:46:30,030 - INFO - Request processed in 1.00s (thinking: 0.00s)
2025-05-05 16:46:30,032 - INFO - 127.0.0.1 - - [05/May/2025 16:46:30] "POST /ask HTTP/1.1" 200 -
2025-05-05 18:55:11,722 - INFO - Use pytorch device_name: cpu
2025-05-05 18:55:11,723 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 18:55:25,194 - INFO - Loading pre-built indexes...
2025-05-05 18:55:31,560 - INFO - Loaded 1460 legal document chunks
2025-05-05 18:55:31,619 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.239.235:5000
2025-05-05 18:55:31,619 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 18:55:46,332 - INFO - 127.0.0.1 - - [05/May/2025 18:55:46] "GET / HTTP/1.1" 200 -
2025-05-05 18:55:46,377 - INFO - 127.0.0.1 - - [05/May/2025 18:55:46] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 18:55:46,473 - INFO - 127.0.0.1 - - [05/May/2025 18:55:46] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 18:55:46,616 - INFO - 127.0.0.1 - - [05/May/2025 18:55:46] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-05-05 18:55:50,942 - INFO - 127.0.0.1 - - [05/May/2025 18:55:50] "GET /get_conversation/30 HTTP/1.1" 200 -
2025-05-05 18:55:55,903 - INFO - 127.0.0.1 - - [05/May/2025 18:55:55] "GET /get_conversation/5 HTTP/1.1" 200 -
2025-05-05 18:55:57,827 - INFO - 127.0.0.1 - - [05/May/2025 18:55:57] "GET /get_conversation/38 HTTP/1.1" 200 -
2025-05-05 18:56:01,220 - INFO - 127.0.0.1 - - [05/May/2025 18:56:01] "POST /search_conversations HTTP/1.1" 200 -
2025-05-05 18:56:02,353 - INFO - 127.0.0.1 - - [05/May/2025 18:56:02] "POST /search_conversations HTTP/1.1" 200 -
2025-05-05 18:56:05,353 - INFO - 127.0.0.1 - - [05/May/2025 18:56:05] "GET /get_conversation/38 HTTP/1.1" 200 -
2025-05-05 18:56:08,380 - INFO - 127.0.0.1 - - [05/May/2025 18:56:08] "GET /get_conversation/38 HTTP/1.1" 200 -
2025-05-05 18:56:11,245 - INFO - 127.0.0.1 - - [05/May/2025 18:56:11] "DELETE /delete_conversation/38 HTTP/1.1" 200 -
2025-05-05 18:56:14,394 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-05 18:56:25,839 - ERROR - Request exception: HTTPSConnectionPool(host='api.groq.com', port=443): Max retries exceeded with url: /openai/v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BFCA8545E0>: Failed to resolve 'api.groq.com' ([Errno 11001] getaddrinfo failed)"))
2025-05-05 18:56:39,324 - ERROR - Request exception: HTTPSConnectionPool(host='api.groq.com', port=443): Max retries exceeded with url: /openai/v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BFCA856590>: Failed to resolve 'api.groq.com' ([Errno 11001] getaddrinfo failed)"))
2025-05-05 18:56:49,829 - INFO - Token usage: prompt=52, completion=9, total=61
2025-05-05 18:56:49,869 - INFO - Processing query: 'heeloo' for conversation 39
2025-05-05 18:56:49,950 - INFO - Query received: heeloo
2025-05-05 18:56:50,916 - INFO - Search scores:
Document 812 (chunk: chunk_778): score=0.2697, confidence=100.00%
Document 640 (chunk: chunk_612): score=0.2643, confidence=98.01%
Document 839 (chunk: chunk_805): score=0.2623, confidence=97.25%
Document 786 (chunk: chunk_754): score=0.2607, confidence=96.66%
Document 1134 (chunk: chunk_1083): score=0.2562, confidence=94.98%
2025-05-05 18:56:50,922 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 18:56:50,922 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 18:56:52,203 - INFO - Token usage: prompt=864, completion=152, total=1016
2025-05-05 18:56:52,205 - INFO - Agent workflow completed in 37.81s
2025-05-05 18:56:52,229 - INFO - Request processed in 37.84s (thinking: 1.29s)
2025-05-05 18:56:52,230 - INFO - 127.0.0.1 - - [05/May/2025 18:56:52] "POST /ask HTTP/1.1" 200 -
2025-05-05 18:57:16,239 - INFO - 127.0.0.1 - - [05/May/2025 18:57:16] "DELETE /delete_conversation/37 HTTP/1.1" 200 -
2025-05-05 18:57:17,692 - INFO - 127.0.0.1 - - [05/May/2025 18:57:17] "GET /get_conversation/36 HTTP/1.1" 200 -
2025-05-05 18:57:20,181 - INFO - 127.0.0.1 - - [05/May/2025 18:57:20] "DELETE /delete_conversation/36 HTTP/1.1" 200 -
2025-05-05 18:57:21,541 - INFO - 127.0.0.1 - - [05/May/2025 18:57:21] "GET /get_conversation/35 HTTP/1.1" 200 -
2025-05-05 18:57:22,887 - INFO - 127.0.0.1 - - [05/May/2025 18:57:22] "GET /get_conversation/34 HTTP/1.1" 200 -
2025-05-05 18:57:32,194 - INFO - 127.0.0.1 - - [05/May/2025 18:57:32] "DELETE /delete_conversation/35 HTTP/1.1" 200 -
2025-05-05 18:57:33,151 - INFO - 127.0.0.1 - - [05/May/2025 18:57:33] "GET /get_conversation/31 HTTP/1.1" 200 -
2025-05-05 18:57:46,099 - INFO - 127.0.0.1 - - [05/May/2025 18:57:46] "GET /get_conversation/30 HTTP/1.1" 200 -
2025-05-05 18:57:51,880 - INFO - 127.0.0.1 - - [05/May/2025 18:57:51] "GET /get_conversation/29 HTTP/1.1" 200 -
2025-05-05 18:57:53,078 - INFO - 127.0.0.1 - - [05/May/2025 18:57:53] "GET /get_conversation/28 HTTP/1.1" 200 -
2025-05-05 18:57:57,141 - INFO - 127.0.0.1 - - [05/May/2025 18:57:57] "GET /get_conversation/24 HTTP/1.1" 200 -
2025-05-05 18:58:04,909 - INFO - 127.0.0.1 - - [05/May/2025 18:58:04] "GET /get_conversation/24 HTTP/1.1" 200 -
2025-05-05 18:58:12,398 - INFO - 127.0.0.1 - - [05/May/2025 18:58:12] "DELETE /delete_conversation/24 HTTP/1.1" 200 -
2025-05-05 18:58:13,589 - INFO - 127.0.0.1 - - [05/May/2025 18:58:13] "GET /get_conversation/23 HTTP/1.1" 200 -
2025-05-05 18:58:17,057 - INFO - 127.0.0.1 - - [05/May/2025 18:58:17] "GET /get_conversation/22 HTTP/1.1" 200 -
2025-05-05 18:58:22,034 - INFO - 127.0.0.1 - - [05/May/2025 18:58:22] "GET /get_conversation/14 HTTP/1.1" 200 -
2025-05-05 18:58:28,838 - INFO - 127.0.0.1 - - [05/May/2025 18:58:28] "GET /get_conversation/6 HTTP/1.1" 200 -
2025-05-05 18:58:34,307 - INFO - 127.0.0.1 - - [05/May/2025 18:58:34] "GET /get_conversation/14 HTTP/1.1" 200 -
2025-05-05 21:49:15,204 - INFO - Use pytorch device_name: cpu
2025-05-05 21:49:15,204 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 21:49:20,666 - INFO - Building code-specific vector stores...
2025-05-05 21:49:20,666 - INFO - Processing loi_defense_contre_pratiques_deloyales_importation...
2025-05-05 21:49:20,872 - INFO - Creating vector store for loi_defense_contre_pratiques_deloyales_importation with 52 documents
2025-05-05 21:49:20,873 - ERROR - Error building vector store for loi_defense_contre_pratiques_deloyales_importation: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:49:20,873 - INFO - Processing loi_relative_commerce_exterieur...
2025-05-05 21:49:20,882 - INFO - Creating vector store for loi_relative_commerce_exterieur with 17 documents
2025-05-05 21:49:20,883 - ERROR - Error building vector store for loi_relative_commerce_exterieur: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:49:20,883 - INFO - Processing loi_relative_Startups...
2025-05-05 21:49:20,894 - INFO - Creating vector store for loi_relative_Startups with 19 documents
2025-05-05 21:49:20,895 - ERROR - Error building vector store for loi_relative_Startups: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:49:20,895 - INFO - Processing loi_societes_commerce_international...
2025-05-05 21:49:20,905 - INFO - Creating vector store for loi_societes_commerce_international with 14 documents
2025-05-05 21:49:20,905 - ERROR - Error building vector store for loi_societes_commerce_international: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:49:20,905 - INFO - Processing loi_societes_ligne...
2025-05-05 21:49:20,915 - INFO - Creating vector store for loi_societes_ligne with 3 documents
2025-05-05 21:49:20,915 - ERROR - Error building vector store for loi_societes_ligne: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:49:20,915 - INFO - Processing texte_code_societes_commerciales...
2025-05-05 21:49:20,940 - INFO - Creating vector store for texte_code_societes_commerciales with 492 documents
2025-05-05 21:49:20,940 - ERROR - Error building vector store for texte_code_societes_commerciales: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:49:20,940 - INFO - Completed building code-specific vector stores
2025-05-05 21:49:20,941 - INFO - Loading code-specific vector stores from stores...
2025-05-05 21:49:20,941 - INFO - Loading pre-built indexes...
2025-05-05 21:49:24,865 - INFO - Loaded 1460 legal document chunks
2025-05-05 21:49:24,865 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-05 21:49:24,865 - INFO - Loaded 0 code-specific vector stores: None
2025-05-05 21:49:24,886 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-05 21:49:24,886 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 21:50:26,958 - INFO - 127.0.0.1 - - [05/May/2025 21:50:26] "GET / HTTP/1.1" 200 -
2025-05-05 21:50:26,994 - INFO - 127.0.0.1 - - [05/May/2025 21:50:26] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 21:50:27,011 - INFO - 127.0.0.1 - - [05/May/2025 21:50:27] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 21:50:31,234 - INFO - 127.0.0.1 - - [05/May/2025 21:50:31] "GET /get_conversation/34 HTTP/1.1" 200 -
2025-05-05 21:50:37,497 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-05 21:50:37,854 - INFO - Token usage: prompt=76, completion=10, total=86
2025-05-05 21:50:37,889 - INFO - Processing query: 'Dans quelles hypothèses l’erreur constitue-t-elle un vice du consentement justifiant la nullité d’un contrat ?' for conversation 40
2025-05-05 21:50:37,892 - INFO - Query received: Dans quelles hypothèses l’erreur constitue-t-elle un vice du consentement justifiant la nullité d’un contrat ?
2025-05-05 21:50:38,322 - INFO - Search scores:
Document 44 (chunk: chunk_44): score=0.5000, confidence=100.00%
Document 342 (chunk: chunk_323): score=0.4749, confidence=94.97%
Document 692 (chunk: chunk_660): score=0.4468, confidence=89.36%
Document 411 (chunk: chunk_392): score=0.4266, confidence=85.32%
Document 45 (chunk: chunk_45): score=0.4117, confidence=82.35%
2025-05-05 21:50:38,329 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 21:50:38,329 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 21:50:41,839 - INFO - Token usage: prompt=1194, completion=897, total=2091
2025-05-05 21:50:41,848 - INFO - Agent workflow completed in 4.35s
2025-05-05 21:50:41,914 - INFO - Request processed in 4.42s (thinking: 3.52s)
2025-05-05 21:50:41,914 - INFO - 127.0.0.1 - - [05/May/2025 21:50:41] "POST /ask HTTP/1.1" 200 -
2025-05-05 21:58:42,167 - INFO - Use pytorch device_name: cpu
2025-05-05 21:58:42,168 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 21:58:48,322 - INFO - Checking stores directory: stores
2025-05-05 21:58:48,323 - INFO - Directory exists: True
2025-05-05 21:58:48,323 - INFO - Directory content: []
2025-05-05 21:58:48,323 - INFO - Building code stores...
2025-05-05 21:58:48,323 - INFO - Building code-specific vector stores...
2025-05-05 21:58:48,323 - INFO - Processing loi_defense_contre_pratiques_deloyales_importation...
2025-05-05 21:58:48,469 - INFO - Creating vector store for loi_defense_contre_pratiques_deloyales_importation with 52 documents
2025-05-05 21:58:48,470 - ERROR - Error building vector store for loi_defense_contre_pratiques_deloyales_importation: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:58:48,470 - INFO - Processing loi_relative_commerce_exterieur...
2025-05-05 21:58:48,471 - INFO - Creating vector store for loi_relative_commerce_exterieur with 17 documents
2025-05-05 21:58:48,471 - ERROR - Error building vector store for loi_relative_commerce_exterieur: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:58:48,471 - INFO - Processing loi_relative_Startups...
2025-05-05 21:58:48,472 - INFO - Creating vector store for loi_relative_Startups with 19 documents
2025-05-05 21:58:48,472 - ERROR - Error building vector store for loi_relative_Startups: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:58:48,472 - INFO - Processing loi_societes_commerce_international...
2025-05-05 21:58:48,473 - INFO - Creating vector store for loi_societes_commerce_international with 14 documents
2025-05-05 21:58:48,473 - ERROR - Error building vector store for loi_societes_commerce_international: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:58:48,473 - INFO - Processing loi_societes_ligne...
2025-05-05 21:58:48,473 - INFO - Creating vector store for loi_societes_ligne with 3 documents
2025-05-05 21:58:48,473 - ERROR - Error building vector store for loi_societes_ligne: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:58:48,474 - INFO - Processing texte_code_societes_commerciales...
2025-05-05 21:58:48,485 - INFO - Creating vector store for texte_code_societes_commerciales with 492 documents
2025-05-05 21:58:48,486 - ERROR - Error building vector store for texte_code_societes_commerciales: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 21:58:48,486 - INFO - Completed building code-specific vector stores
2025-05-05 21:58:48,487 - INFO - Loading code-specific vector stores from stores...
2025-05-05 21:58:48,487 - INFO - Loading pre-built indexes...
2025-05-05 21:58:51,918 - INFO - Loaded 1460 legal document chunks
2025-05-05 21:58:51,918 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-05 21:58:51,918 - INFO - Loaded 0 code-specific vector stores: None
2025-05-05 21:58:51,937 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-05 21:58:51,937 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 22:03:10,561 - INFO - 127.0.0.1 - - [05/May/2025 22:03:10] "GET / HTTP/1.1" 200 -
2025-05-05 22:03:10,584 - INFO - 127.0.0.1 - - [05/May/2025 22:03:10] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 22:03:10,603 - INFO - 127.0.0.1 - - [05/May/2025 22:03:10] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 22:03:14,902 - INFO - 127.0.0.1 - - [05/May/2025 22:03:14] "GET /get_conversation/40 HTTP/1.1" 200 -
2025-05-05 22:03:28,264 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-05 22:03:28,691 - INFO - Token usage: prompt=54, completion=11, total=65
2025-05-05 22:03:28,728 - INFO - Processing query: 'comment lancer une startup?' for conversation 41
2025-05-05 22:03:28,733 - INFO - Query received: comment lancer une startup?
2025-05-05 22:03:29,145 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-05 22:03:29,153 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 22:03:29,153 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 22:03:34,921 - INFO - Token usage: prompt=1200, completion=1153, total=2353
2025-05-05 22:03:34,928 - INFO - Agent workflow completed in 6.66s
2025-05-05 22:03:35,017 - INFO - Request processed in 6.75s (thinking: 5.78s)
2025-05-05 22:03:35,018 - INFO - 127.0.0.1 - - [05/May/2025 22:03:35] "POST /ask HTTP/1.1" 200 -
2025-05-05 22:09:30,748 - INFO - Use pytorch device_name: cpu
2025-05-05 22:09:30,749 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:09:36,213 - INFO - Checking stores directory: stores
2025-05-05 22:09:36,213 - INFO - Directory exists: True
2025-05-05 22:09:36,214 - INFO - Directory content: []
2025-05-05 22:09:36,214 - INFO - Building code stores...
2025-05-05 22:09:36,214 - INFO - ============================================
2025-05-05 22:09:36,214 - INFO - Building code-specific vector stores...
2025-05-05 22:09:36,214 - INFO - Checking stores directory: C:\Users\chtar\Desktop\bouba\stores
2025-05-05 22:09:36,215 - INFO - Checking legal_codes directory: C:\Users\chtar\Desktop\bouba\legal_codes
2025-05-05 22:09:36,215 - INFO - Files in legal_codes directory: ['loi_defense_contre_pratiques_deloyales_importation.txt', 'loi_relative_commerce_exterieur.txt', 'loi_relative_Startups.txt', 'loi_societes_commerce_international.txt', 'loi_societes_ligne.txt', 'texte_code_societes_commerciales.txt']
2025-05-05 22:09:36,215 - INFO - Looking for file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt
2025-05-05 22:09:36,215 - INFO - Processing loi_defense_contre_pratiques_deloyales_importation...
2025-05-05 22:09:36,215 - INFO - File size: 30641 characters
2025-05-05 22:09:36,217 - INFO - Found 52 article matches in loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:09:36,378 - INFO - Creating vector store for loi_defense_contre_pratiques_deloyales_importation with 52 documents
2025-05-05 22:09:36,379 - ERROR - Error building vector store for loi_defense_contre_pratiques_deloyales_importation: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:09:36,381 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 618, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:09:36,381 - INFO - Looking for file: legal_codes\loi_relative_commerce_exterieur.txt
2025-05-05 22:09:36,381 - INFO - Processing loi_relative_commerce_exterieur...
2025-05-05 22:09:36,382 - INFO - File size: 6553 characters
2025-05-05 22:09:36,382 - INFO - Found 17 article matches in loi_relative_commerce_exterieur
2025-05-05 22:09:36,382 - INFO - Creating vector store for loi_relative_commerce_exterieur with 17 documents
2025-05-05 22:09:36,382 - ERROR - Error building vector store for loi_relative_commerce_exterieur: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:09:36,383 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 618, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:09:36,383 - INFO - Looking for file: legal_codes\loi_relative_Startups.txt
2025-05-05 22:09:36,383 - INFO - Processing loi_relative_Startups...
2025-05-05 22:09:36,383 - INFO - File size: 14677 characters
2025-05-05 22:09:36,383 - INFO - Found 19 article matches in loi_relative_Startups
2025-05-05 22:09:36,384 - INFO - Creating vector store for loi_relative_Startups with 19 documents
2025-05-05 22:09:36,384 - ERROR - Error building vector store for loi_relative_Startups: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:09:36,384 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 618, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:09:36,384 - INFO - Looking for file: legal_codes\loi_societes_commerce_international.txt
2025-05-05 22:09:36,384 - INFO - Processing loi_societes_commerce_international...
2025-05-05 22:09:36,384 - INFO - File size: 8543 characters
2025-05-05 22:09:36,385 - INFO - Found 14 article matches in loi_societes_commerce_international
2025-05-05 22:09:36,385 - INFO - Creating vector store for loi_societes_commerce_international with 14 documents
2025-05-05 22:09:36,385 - ERROR - Error building vector store for loi_societes_commerce_international: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:09:36,385 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 618, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:09:36,385 - INFO - Looking for file: legal_codes\loi_societes_ligne.txt
2025-05-05 22:09:36,385 - INFO - Processing loi_societes_ligne...
2025-05-05 22:09:36,385 - INFO - File size: 1678 characters
2025-05-05 22:09:36,386 - INFO - Found 3 article matches in loi_societes_ligne
2025-05-05 22:09:36,386 - INFO - Creating vector store for loi_societes_ligne with 3 documents
2025-05-05 22:09:36,386 - ERROR - Error building vector store for loi_societes_ligne: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:09:36,386 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 618, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:09:36,386 - INFO - Looking for file: legal_codes\texte_code_societes_commerciales.txt
2025-05-05 22:09:36,386 - INFO - Processing texte_code_societes_commerciales...
2025-05-05 22:09:36,387 - INFO - File size: 306679 characters
2025-05-05 22:09:36,398 - INFO - Found 492 article matches in texte_code_societes_commerciales
2025-05-05 22:09:36,401 - INFO - Creating vector store for texte_code_societes_commerciales with 492 documents
2025-05-05 22:09:36,402 - ERROR - Error building vector store for texte_code_societes_commerciales: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:09:36,403 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 618, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:09:36,403 - INFO - Final stores directory content: []
2025-05-05 22:09:36,403 - INFO - Completed building code-specific vector stores
2025-05-05 22:09:36,403 - INFO - ============================================
2025-05-05 22:09:36,405 - INFO - Loading code-specific vector stores from stores...
2025-05-05 22:09:36,406 - INFO - Loading pre-built indexes...
2025-05-05 22:09:39,809 - INFO - Loaded 1460 legal document chunks
2025-05-05 22:09:39,809 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-05 22:09:39,809 - INFO - Loaded 0 code-specific vector stores: None
2025-05-05 22:09:39,826 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-05 22:09:39,826 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 22:10:10,684 - INFO - 127.0.0.1 - - [05/May/2025 22:10:10] "GET / HTTP/1.1" 200 -
2025-05-05 22:10:10,702 - INFO - 127.0.0.1 - - [05/May/2025 22:10:10] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 22:10:10,718 - INFO - 127.0.0.1 - - [05/May/2025 22:10:10] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 22:10:12,862 - INFO - 127.0.0.1 - - [05/May/2025 22:10:12] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-05 22:10:19,900 - INFO - Processing query: 'comment lancer une startup?' for conversation 41
2025-05-05 22:10:19,905 - INFO - Query received: comment lancer une startup?
2025-05-05 22:10:20,235 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-05 22:10:20,242 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 22:10:20,242 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 22:10:41,581 - INFO - Token usage: prompt=1200, completion=719, total=1919
2025-05-05 22:10:41,585 - INFO - Agent workflow completed in 21.70s
2025-05-05 22:10:41,616 - INFO - Request processed in 21.73s (thinking: 21.35s)
2025-05-05 22:10:41,616 - INFO - 127.0.0.1 - - [05/May/2025 22:10:41] "POST /ask HTTP/1.1" 200 -
2025-05-05 22:23:51,099 - INFO - Use pytorch device_name: cpu
2025-05-05 22:23:51,099 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:23:56,284 - INFO - Checking stores directory: stores
2025-05-05 22:23:56,285 - INFO - Removed existing stores directory to force rebuild
2025-05-05 22:23:56,285 - INFO - ============================================
2025-05-05 22:23:56,285 - INFO - Building code-specific vector stores...
2025-05-05 22:23:56,289 - INFO - Use pytorch device_name: cpu
2025-05-05 22:23:56,289 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:23:59,581 - INFO - Files in legal_codes directory: ['loi_defense_contre_pratiques_deloyales_importation.txt', 'loi_relative_commerce_exterieur.txt', 'loi_relative_Startups.txt', 'loi_societes_commerce_international.txt', 'loi_societes_ligne.txt', 'texte_code_societes_commerciales.txt']
2025-05-05 22:23:59,582 - INFO - Looking for file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt
2025-05-05 22:23:59,582 - INFO - Processing loi_defense_contre_pratiques_deloyales_importation...
2025-05-05 22:23:59,582 - INFO - File size: 30641 characters
2025-05-05 22:23:59,583 - INFO - Found 52 article matches in loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:23:59,743 - INFO - Creating vector store for loi_defense_contre_pratiques_deloyales_importation with 52 documents
2025-05-05 22:23:59,744 - ERROR - Error creating FAISS store for loi_defense_contre_pratiques_deloyales_importation: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:23:59,746 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:23:59,746 - INFO - Looking for file: legal_codes\loi_relative_commerce_exterieur.txt
2025-05-05 22:23:59,746 - INFO - Processing loi_relative_commerce_exterieur...
2025-05-05 22:23:59,747 - INFO - File size: 6553 characters
2025-05-05 22:23:59,747 - INFO - Found 17 article matches in loi_relative_commerce_exterieur
2025-05-05 22:23:59,747 - INFO - Creating vector store for loi_relative_commerce_exterieur with 17 documents
2025-05-05 22:23:59,747 - ERROR - Error creating FAISS store for loi_relative_commerce_exterieur: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:23:59,748 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:23:59,748 - INFO - Looking for file: legal_codes\loi_relative_Startups.txt
2025-05-05 22:23:59,748 - INFO - Processing loi_relative_Startups...
2025-05-05 22:23:59,748 - INFO - File size: 14677 characters
2025-05-05 22:23:59,748 - INFO - Found 19 article matches in loi_relative_Startups
2025-05-05 22:23:59,748 - INFO - Creating vector store for loi_relative_Startups with 19 documents
2025-05-05 22:23:59,749 - ERROR - Error creating FAISS store for loi_relative_Startups: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:23:59,749 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:23:59,749 - INFO - Looking for file: legal_codes\loi_societes_commerce_international.txt
2025-05-05 22:23:59,749 - INFO - Processing loi_societes_commerce_international...
2025-05-05 22:23:59,749 - INFO - File size: 8543 characters
2025-05-05 22:23:59,749 - INFO - Found 14 article matches in loi_societes_commerce_international
2025-05-05 22:23:59,750 - INFO - Creating vector store for loi_societes_commerce_international with 14 documents
2025-05-05 22:23:59,750 - ERROR - Error creating FAISS store for loi_societes_commerce_international: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:23:59,750 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:23:59,750 - INFO - Looking for file: legal_codes\loi_societes_ligne.txt
2025-05-05 22:23:59,750 - INFO - Processing loi_societes_ligne...
2025-05-05 22:23:59,750 - INFO - File size: 1678 characters
2025-05-05 22:23:59,750 - INFO - Found 3 article matches in loi_societes_ligne
2025-05-05 22:23:59,750 - INFO - Creating vector store for loi_societes_ligne with 3 documents
2025-05-05 22:23:59,750 - ERROR - Error creating FAISS store for loi_societes_ligne: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:23:59,751 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:23:59,751 - INFO - Looking for file: legal_codes\texte_code_societes_commerciales.txt
2025-05-05 22:23:59,751 - INFO - Processing texte_code_societes_commerciales...
2025-05-05 22:23:59,752 - INFO - File size: 306679 characters
2025-05-05 22:23:59,762 - INFO - Found 492 article matches in texte_code_societes_commerciales
2025-05-05 22:23:59,766 - INFO - Creating vector store for texte_code_societes_commerciales with 492 documents
2025-05-05 22:23:59,767 - ERROR - Error creating FAISS store for texte_code_societes_commerciales: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:23:59,767 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:23:59,767 - INFO - Final stores directory content: []
2025-05-05 22:23:59,767 - INFO - Completed building code-specific vector stores
2025-05-05 22:23:59,768 - INFO - ============================================
2025-05-05 22:23:59,773 - INFO - Use pytorch device_name: cpu
2025-05-05 22:23:59,774 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:24:02,673 - INFO - Stores directory is empty or doesn't exist. Building code stores...
2025-05-05 22:24:02,674 - INFO - ============================================
2025-05-05 22:24:02,674 - INFO - Building code-specific vector stores...
2025-05-05 22:24:02,677 - INFO - Use pytorch device_name: cpu
2025-05-05 22:24:02,678 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:24:05,431 - INFO - Files in legal_codes directory: ['loi_defense_contre_pratiques_deloyales_importation.txt', 'loi_relative_commerce_exterieur.txt', 'loi_relative_Startups.txt', 'loi_societes_commerce_international.txt', 'loi_societes_ligne.txt', 'texte_code_societes_commerciales.txt']
2025-05-05 22:24:05,431 - INFO - Looking for file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt
2025-05-05 22:24:05,431 - INFO - Processing loi_defense_contre_pratiques_deloyales_importation...
2025-05-05 22:24:05,432 - INFO - File size: 30641 characters
2025-05-05 22:24:05,433 - INFO - Found 52 article matches in loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:24:05,433 - INFO - Creating vector store for loi_defense_contre_pratiques_deloyales_importation with 52 documents
2025-05-05 22:24:05,433 - ERROR - Error creating FAISS store for loi_defense_contre_pratiques_deloyales_importation: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:24:05,434 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:24:05,434 - INFO - Looking for file: legal_codes\loi_relative_commerce_exterieur.txt
2025-05-05 22:24:05,434 - INFO - Processing loi_relative_commerce_exterieur...
2025-05-05 22:24:05,434 - INFO - File size: 6553 characters
2025-05-05 22:24:05,434 - INFO - Found 17 article matches in loi_relative_commerce_exterieur
2025-05-05 22:24:05,434 - INFO - Creating vector store for loi_relative_commerce_exterieur with 17 documents
2025-05-05 22:24:05,434 - ERROR - Error creating FAISS store for loi_relative_commerce_exterieur: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:24:05,434 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:24:05,434 - INFO - Looking for file: legal_codes\loi_relative_Startups.txt
2025-05-05 22:24:05,434 - INFO - Processing loi_relative_Startups...
2025-05-05 22:24:05,435 - INFO - File size: 14677 characters
2025-05-05 22:24:05,435 - INFO - Found 19 article matches in loi_relative_Startups
2025-05-05 22:24:05,435 - INFO - Creating vector store for loi_relative_Startups with 19 documents
2025-05-05 22:24:05,435 - ERROR - Error creating FAISS store for loi_relative_Startups: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:24:05,436 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:24:05,436 - INFO - Looking for file: legal_codes\loi_societes_commerce_international.txt
2025-05-05 22:24:05,436 - INFO - Processing loi_societes_commerce_international...
2025-05-05 22:24:05,436 - INFO - File size: 8543 characters
2025-05-05 22:24:05,436 - INFO - Found 14 article matches in loi_societes_commerce_international
2025-05-05 22:24:05,436 - INFO - Creating vector store for loi_societes_commerce_international with 14 documents
2025-05-05 22:24:05,436 - ERROR - Error creating FAISS store for loi_societes_commerce_international: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:24:05,437 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:24:05,437 - INFO - Looking for file: legal_codes\loi_societes_ligne.txt
2025-05-05 22:24:05,437 - INFO - Processing loi_societes_ligne...
2025-05-05 22:24:05,437 - INFO - File size: 1678 characters
2025-05-05 22:24:05,437 - INFO - Found 3 article matches in loi_societes_ligne
2025-05-05 22:24:05,437 - INFO - Creating vector store for loi_societes_ligne with 3 documents
2025-05-05 22:24:05,437 - ERROR - Error creating FAISS store for loi_societes_ligne: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:24:05,437 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:24:05,437 - INFO - Looking for file: legal_codes\texte_code_societes_commerciales.txt
2025-05-05 22:24:05,438 - INFO - Processing texte_code_societes_commerciales...
2025-05-05 22:24:05,439 - INFO - File size: 306679 characters
2025-05-05 22:24:05,447 - INFO - Found 492 article matches in texte_code_societes_commerciales
2025-05-05 22:24:05,450 - INFO - Creating vector store for texte_code_societes_commerciales with 492 documents
2025-05-05 22:24:05,450 - ERROR - Error creating FAISS store for texte_code_societes_commerciales: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:24:05,450 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 635, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:24:05,451 - INFO - Final stores directory content: []
2025-05-05 22:24:05,451 - INFO - Completed building code-specific vector stores
2025-05-05 22:24:05,451 - INFO - ============================================
2025-05-05 22:24:05,451 - INFO - Loading code-specific vector stores from stores...
2025-05-05 22:24:05,451 - INFO - Loading pre-built indexes...
2025-05-05 22:24:09,129 - INFO - Loaded 1460 legal document chunks
2025-05-05 22:24:09,129 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-05 22:24:09,129 - INFO - Loaded 0 code-specific vector stores: None
2025-05-05 22:24:09,149 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-05 22:24:09,149 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 22:24:17,439 - INFO - 127.0.0.1 - - [05/May/2025 22:24:17] "GET / HTTP/1.1" 200 -
2025-05-05 22:24:17,466 - INFO - 127.0.0.1 - - [05/May/2025 22:24:17] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 22:24:17,484 - INFO - 127.0.0.1 - - [05/May/2025 22:24:17] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 22:24:19,393 - INFO - 127.0.0.1 - - [05/May/2025 22:24:19] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-05 22:24:24,038 - INFO - Processing query: 'comment lancer une startup?' for conversation 41
2025-05-05 22:24:24,041 - INFO - Query received: comment lancer une startup?
2025-05-05 22:24:24,451 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-05 22:24:24,462 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 22:24:24,462 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 22:24:28,469 - INFO - Token usage: prompt=1200, completion=1025, total=2225
2025-05-05 22:24:28,477 - INFO - Agent workflow completed in 4.46s
2025-05-05 22:24:28,554 - INFO - Request processed in 4.53s (thinking: 4.02s)
2025-05-05 22:24:28,556 - INFO - 127.0.0.1 - - [05/May/2025 22:24:28] "POST /ask HTTP/1.1" 200 -
2025-05-05 22:33:01,061 - INFO - Use pytorch device_name: cpu
2025-05-05 22:33:01,061 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:33:06,069 - INFO - ==== STARTING APPLICATION ====
2025-05-05 22:33:06,069 - INFO - Starting store rebuild process...
2025-05-05 22:33:06,069 - INFO - ============================================
2025-05-05 22:33:06,069 - INFO - STARTING CODE STORE CREATION PROCESS
2025-05-05 22:33:06,069 - INFO - ============================================
2025-05-05 22:33:06,069 - INFO - Removed existing stores directory to force clean rebuild
2025-05-05 22:33:06,070 - INFO - Created fresh stores directory at: C:\Users\chtar\Desktop\bouba\stores
2025-05-05 22:33:06,072 - INFO - Use pytorch device_name: cpu
2025-05-05 22:33:06,072 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:33:09,460 - INFO - Successfully initialized embedding model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:33:09,460 - INFO - Found 6 files in legal_codes directory: ['loi_defense_contre_pratiques_deloyales_importation.txt', 'loi_relative_commerce_exterieur.txt', 'loi_relative_Startups.txt', 'loi_societes_commerce_international.txt', 'loi_societes_ligne.txt', 'texte_code_societes_commerciales.txt']
2025-05-05 22:33:09,460 - INFO - Processing code file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt
2025-05-05 22:33:09,461 - INFO - Successfully read file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt - Size: 30641 characters
2025-05-05 22:33:09,462 - INFO - Found 52 article matches in loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:33:09,462 - INFO - Created 52 chunks for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:33:09,618 - INFO - Created 52 document objects for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:33:09,618 - INFO - Starting FAISS vectorstore creation for loi_defense_contre_pratiques_deloyales_importation...
2025-05-05 22:33:09,793 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:09,794 - ERROR - CRITICAL ERROR creating FAISS store for loi_defense_contre_pratiques_deloyales_importation: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:09,795 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:09,795 - INFO - Processing code file: legal_codes\loi_relative_commerce_exterieur.txt
2025-05-05 22:33:09,795 - INFO - Successfully read file: legal_codes\loi_relative_commerce_exterieur.txt - Size: 6553 characters
2025-05-05 22:33:09,796 - INFO - Found 17 article matches in loi_relative_commerce_exterieur
2025-05-05 22:33:09,796 - INFO - Created 17 chunks for loi_relative_commerce_exterieur
2025-05-05 22:33:09,796 - INFO - Created 17 document objects for loi_relative_commerce_exterieur
2025-05-05 22:33:09,796 - INFO - Starting FAISS vectorstore creation for loi_relative_commerce_exterieur...
2025-05-05 22:33:09,810 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:09,810 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_commerce_exterieur: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:09,811 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:09,811 - INFO - Processing code file: legal_codes\loi_relative_Startups.txt
2025-05-05 22:33:09,811 - INFO - Successfully read file: legal_codes\loi_relative_Startups.txt - Size: 14677 characters
2025-05-05 22:33:09,812 - INFO - Found 19 article matches in loi_relative_Startups
2025-05-05 22:33:09,812 - INFO - Created 19 chunks for loi_relative_Startups
2025-05-05 22:33:09,812 - INFO - Created 19 document objects for loi_relative_Startups
2025-05-05 22:33:09,812 - INFO - Starting FAISS vectorstore creation for loi_relative_Startups...
2025-05-05 22:33:09,831 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:09,831 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_Startups: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:09,832 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:09,832 - INFO - Processing code file: legal_codes\loi_societes_commerce_international.txt
2025-05-05 22:33:09,832 - INFO - Successfully read file: legal_codes\loi_societes_commerce_international.txt - Size: 8543 characters
2025-05-05 22:33:09,833 - INFO - Found 14 article matches in loi_societes_commerce_international
2025-05-05 22:33:09,833 - INFO - Created 14 chunks for loi_societes_commerce_international
2025-05-05 22:33:09,833 - INFO - Created 14 document objects for loi_societes_commerce_international
2025-05-05 22:33:09,833 - INFO - Starting FAISS vectorstore creation for loi_societes_commerce_international...
2025-05-05 22:33:09,851 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:09,851 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_commerce_international: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:09,851 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:09,851 - INFO - Processing code file: legal_codes\loi_societes_ligne.txt
2025-05-05 22:33:09,852 - INFO - Successfully read file: legal_codes\loi_societes_ligne.txt - Size: 1678 characters
2025-05-05 22:33:09,852 - INFO - Found 3 article matches in loi_societes_ligne
2025-05-05 22:33:09,852 - INFO - Created 3 chunks for loi_societes_ligne
2025-05-05 22:33:09,852 - INFO - Created 3 document objects for loi_societes_ligne
2025-05-05 22:33:09,852 - INFO - Starting FAISS vectorstore creation for loi_societes_ligne...
2025-05-05 22:33:09,871 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:09,872 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_ligne: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:09,873 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:09,873 - INFO - Processing code file: legal_codes\texte_code_societes_commerciales.txt
2025-05-05 22:33:09,874 - INFO - Successfully read file: legal_codes\texte_code_societes_commerciales.txt - Size: 306679 characters
2025-05-05 22:33:09,883 - INFO - Found 492 article matches in texte_code_societes_commerciales
2025-05-05 22:33:09,884 - INFO - Created 492 chunks for texte_code_societes_commerciales
2025-05-05 22:33:09,886 - INFO - Created 492 document objects for texte_code_societes_commerciales
2025-05-05 22:33:09,886 - INFO - Starting FAISS vectorstore creation for texte_code_societes_commerciales...
2025-05-05 22:33:09,904 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:09,904 - ERROR - CRITICAL ERROR creating FAISS store for texte_code_societes_commerciales: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:09,905 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:09,905 - INFO - Final stores directory content: []
2025-05-05 22:33:09,905 - INFO - Successfully created 0 out of 6 possible stores
2025-05-05 22:33:09,905 - INFO - ============================================
2025-05-05 22:33:09,905 - INFO - COMPLETED CODE STORE CREATION PROCESS
2025-05-05 22:33:09,905 - INFO - ============================================
2025-05-05 22:33:09,906 - ERROR - CRITICAL: Failed to build code stores
2025-05-05 22:33:09,911 - INFO - Use pytorch device_name: cpu
2025-05-05 22:33:09,911 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:33:12,663 - INFO - Stores directory is empty or doesn't exist. Building code stores...
2025-05-05 22:33:12,663 - INFO - ============================================
2025-05-05 22:33:12,663 - INFO - STARTING CODE STORE CREATION PROCESS
2025-05-05 22:33:12,663 - INFO - ============================================
2025-05-05 22:33:12,664 - INFO - Removed existing stores directory to force clean rebuild
2025-05-05 22:33:12,664 - INFO - Created fresh stores directory at: C:\Users\chtar\Desktop\bouba\stores
2025-05-05 22:33:12,667 - INFO - Use pytorch device_name: cpu
2025-05-05 22:33:12,667 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:33:15,333 - INFO - Successfully initialized embedding model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:33:15,334 - INFO - Found 6 files in legal_codes directory: ['loi_defense_contre_pratiques_deloyales_importation.txt', 'loi_relative_commerce_exterieur.txt', 'loi_relative_Startups.txt', 'loi_societes_commerce_international.txt', 'loi_societes_ligne.txt', 'texte_code_societes_commerciales.txt']
2025-05-05 22:33:15,334 - INFO - Processing code file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt
2025-05-05 22:33:15,335 - INFO - Successfully read file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt - Size: 30641 characters
2025-05-05 22:33:15,336 - INFO - Found 52 article matches in loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:33:15,336 - INFO - Created 52 chunks for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:33:15,337 - INFO - Created 52 document objects for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:33:15,337 - INFO - Starting FAISS vectorstore creation for loi_defense_contre_pratiques_deloyales_importation...
2025-05-05 22:33:15,356 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:15,356 - ERROR - CRITICAL ERROR creating FAISS store for loi_defense_contre_pratiques_deloyales_importation: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:15,356 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:15,357 - INFO - Processing code file: legal_codes\loi_relative_commerce_exterieur.txt
2025-05-05 22:33:15,357 - INFO - Successfully read file: legal_codes\loi_relative_commerce_exterieur.txt - Size: 6553 characters
2025-05-05 22:33:15,357 - INFO - Found 17 article matches in loi_relative_commerce_exterieur
2025-05-05 22:33:15,357 - INFO - Created 17 chunks for loi_relative_commerce_exterieur
2025-05-05 22:33:15,358 - INFO - Created 17 document objects for loi_relative_commerce_exterieur
2025-05-05 22:33:15,358 - INFO - Starting FAISS vectorstore creation for loi_relative_commerce_exterieur...
2025-05-05 22:33:15,378 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:15,378 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_commerce_exterieur: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:15,379 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:15,379 - INFO - Processing code file: legal_codes\loi_relative_Startups.txt
2025-05-05 22:33:15,379 - INFO - Successfully read file: legal_codes\loi_relative_Startups.txt - Size: 14677 characters
2025-05-05 22:33:15,380 - INFO - Found 19 article matches in loi_relative_Startups
2025-05-05 22:33:15,380 - INFO - Created 19 chunks for loi_relative_Startups
2025-05-05 22:33:15,380 - INFO - Created 19 document objects for loi_relative_Startups
2025-05-05 22:33:15,380 - INFO - Starting FAISS vectorstore creation for loi_relative_Startups...
2025-05-05 22:33:15,401 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:15,401 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_Startups: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:15,401 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:15,401 - INFO - Processing code file: legal_codes\loi_societes_commerce_international.txt
2025-05-05 22:33:15,401 - INFO - Successfully read file: legal_codes\loi_societes_commerce_international.txt - Size: 8543 characters
2025-05-05 22:33:15,402 - INFO - Found 14 article matches in loi_societes_commerce_international
2025-05-05 22:33:15,402 - INFO - Created 14 chunks for loi_societes_commerce_international
2025-05-05 22:33:15,402 - INFO - Created 14 document objects for loi_societes_commerce_international
2025-05-05 22:33:15,402 - INFO - Starting FAISS vectorstore creation for loi_societes_commerce_international...
2025-05-05 22:33:15,424 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:15,425 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_commerce_international: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:15,425 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:15,425 - INFO - Processing code file: legal_codes\loi_societes_ligne.txt
2025-05-05 22:33:15,425 - INFO - Successfully read file: legal_codes\loi_societes_ligne.txt - Size: 1678 characters
2025-05-05 22:33:15,426 - INFO - Found 3 article matches in loi_societes_ligne
2025-05-05 22:33:15,426 - INFO - Created 3 chunks for loi_societes_ligne
2025-05-05 22:33:15,426 - INFO - Created 3 document objects for loi_societes_ligne
2025-05-05 22:33:15,426 - INFO - Starting FAISS vectorstore creation for loi_societes_ligne...
2025-05-05 22:33:15,445 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:15,446 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_ligne: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:15,446 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:15,446 - INFO - Processing code file: legal_codes\texte_code_societes_commerciales.txt
2025-05-05 22:33:15,447 - INFO - Successfully read file: legal_codes\texte_code_societes_commerciales.txt - Size: 306679 characters
2025-05-05 22:33:15,458 - INFO - Found 492 article matches in texte_code_societes_commerciales
2025-05-05 22:33:15,460 - INFO - Created 492 chunks for texte_code_societes_commerciales
2025-05-05 22:33:15,462 - INFO - Created 492 document objects for texte_code_societes_commerciales
2025-05-05 22:33:15,462 - INFO - Starting FAISS vectorstore creation for texte_code_societes_commerciales...
2025-05-05 22:33:15,482 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:33:15,483 - ERROR - CRITICAL ERROR creating FAISS store for texte_code_societes_commerciales: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:33:15,483 - ERROR - Traceback (most recent call last):
  File "C:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:33:15,483 - INFO - Final stores directory content: []
2025-05-05 22:33:15,483 - INFO - Successfully created 0 out of 6 possible stores
2025-05-05 22:33:15,483 - INFO - ============================================
2025-05-05 22:33:15,483 - INFO - COMPLETED CODE STORE CREATION PROCESS
2025-05-05 22:33:15,483 - INFO - ============================================
2025-05-05 22:33:15,484 - INFO - Loading code-specific vector stores from stores...
2025-05-05 22:33:15,484 - INFO - Loading pre-built indexes...
2025-05-05 22:33:19,042 - INFO - Loaded 1460 legal document chunks
2025-05-05 22:33:19,042 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-05 22:33:19,042 - INFO - Loaded 0 code-specific vector stores: None
2025-05-05 22:33:19,043 - INFO - ==== APPLICATION READY ====
2025-05-05 22:33:19,062 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-05 22:33:19,062 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 22:33:49,023 - INFO - 127.0.0.1 - - [05/May/2025 22:33:49] "GET / HTTP/1.1" 200 -
2025-05-05 22:33:49,042 - INFO - 127.0.0.1 - - [05/May/2025 22:33:49] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 22:33:49,056 - INFO - 127.0.0.1 - - [05/May/2025 22:33:49] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 22:33:50,857 - INFO - 127.0.0.1 - - [05/May/2025 22:33:50] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-05 22:34:42,325 - INFO - Use pytorch device_name: cpu
2025-05-05 22:34:42,325 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:34:48,402 - INFO - ==== STARTING APPLICATION ====
2025-05-05 22:34:48,402 - INFO - Starting store rebuild process...
2025-05-05 22:34:48,402 - INFO - ============================================
2025-05-05 22:34:48,402 - INFO - STARTING CODE STORE CREATION PROCESS
2025-05-05 22:34:48,402 - INFO - ============================================
2025-05-05 22:34:48,403 - INFO - Removed existing stores directory to force clean rebuild
2025-05-05 22:34:48,404 - INFO - Created fresh stores directory at: C:\Users\chtar\Desktop\bouba\stores
2025-05-05 22:34:48,408 - INFO - Use pytorch device_name: cpu
2025-05-05 22:34:48,408 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:34:51,270 - INFO - Successfully initialized embedding model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:34:51,271 - INFO - Found 6 files in legal_codes directory: ['loi_defense_contre_pratiques_deloyales_importation.txt', 'loi_relative_commerce_exterieur.txt', 'loi_relative_Startups.txt', 'loi_societes_commerce_international.txt', 'loi_societes_ligne.txt', 'texte_code_societes_commerciales.txt']
2025-05-05 22:34:51,271 - INFO - Processing code file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt
2025-05-05 22:34:51,272 - INFO - Successfully read file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt - Size: 30641 characters
2025-05-05 22:34:51,273 - INFO - Found 52 article matches in loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:34:51,273 - INFO - Created 52 chunks for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:34:51,416 - INFO - Created 52 document objects for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:34:51,416 - INFO - Starting FAISS vectorstore creation for loi_defense_contre_pratiques_deloyales_importation...
2025-05-05 22:34:51,616 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:51,617 - ERROR - CRITICAL ERROR creating FAISS store for loi_defense_contre_pratiques_deloyales_importation: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:51,618 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:51,618 - INFO - Processing code file: legal_codes\loi_relative_commerce_exterieur.txt
2025-05-05 22:34:51,619 - INFO - Successfully read file: legal_codes\loi_relative_commerce_exterieur.txt - Size: 6553 characters
2025-05-05 22:34:51,619 - INFO - Found 17 article matches in loi_relative_commerce_exterieur
2025-05-05 22:34:51,619 - INFO - Created 17 chunks for loi_relative_commerce_exterieur
2025-05-05 22:34:51,619 - INFO - Created 17 document objects for loi_relative_commerce_exterieur
2025-05-05 22:34:51,619 - INFO - Starting FAISS vectorstore creation for loi_relative_commerce_exterieur...
2025-05-05 22:34:51,640 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:51,641 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_commerce_exterieur: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:51,641 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:51,641 - INFO - Processing code file: legal_codes\loi_relative_Startups.txt
2025-05-05 22:34:51,641 - INFO - Successfully read file: legal_codes\loi_relative_Startups.txt - Size: 14677 characters
2025-05-05 22:34:51,642 - INFO - Found 19 article matches in loi_relative_Startups
2025-05-05 22:34:51,642 - INFO - Created 19 chunks for loi_relative_Startups
2025-05-05 22:34:51,642 - INFO - Created 19 document objects for loi_relative_Startups
2025-05-05 22:34:51,642 - INFO - Starting FAISS vectorstore creation for loi_relative_Startups...
2025-05-05 22:34:51,658 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:51,658 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_Startups: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:51,659 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:51,659 - INFO - Processing code file: legal_codes\loi_societes_commerce_international.txt
2025-05-05 22:34:51,659 - INFO - Successfully read file: legal_codes\loi_societes_commerce_international.txt - Size: 8543 characters
2025-05-05 22:34:51,659 - INFO - Found 14 article matches in loi_societes_commerce_international
2025-05-05 22:34:51,661 - INFO - Created 14 chunks for loi_societes_commerce_international
2025-05-05 22:34:51,661 - INFO - Created 14 document objects for loi_societes_commerce_international
2025-05-05 22:34:51,661 - INFO - Starting FAISS vectorstore creation for loi_societes_commerce_international...
2025-05-05 22:34:51,680 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:51,680 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_commerce_international: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:51,681 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:51,681 - INFO - Processing code file: legal_codes\loi_societes_ligne.txt
2025-05-05 22:34:51,681 - INFO - Successfully read file: legal_codes\loi_societes_ligne.txt - Size: 1678 characters
2025-05-05 22:34:51,681 - INFO - Found 3 article matches in loi_societes_ligne
2025-05-05 22:34:51,681 - INFO - Created 3 chunks for loi_societes_ligne
2025-05-05 22:34:51,681 - INFO - Created 3 document objects for loi_societes_ligne
2025-05-05 22:34:51,681 - INFO - Starting FAISS vectorstore creation for loi_societes_ligne...
2025-05-05 22:34:51,707 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:51,707 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_ligne: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:51,707 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:51,707 - INFO - Processing code file: legal_codes\texte_code_societes_commerciales.txt
2025-05-05 22:34:51,709 - INFO - Successfully read file: legal_codes\texte_code_societes_commerciales.txt - Size: 306679 characters
2025-05-05 22:34:51,720 - INFO - Found 492 article matches in texte_code_societes_commerciales
2025-05-05 22:34:51,723 - INFO - Created 492 chunks for texte_code_societes_commerciales
2025-05-05 22:34:51,726 - INFO - Created 492 document objects for texte_code_societes_commerciales
2025-05-05 22:34:51,726 - INFO - Starting FAISS vectorstore creation for texte_code_societes_commerciales...
2025-05-05 22:34:51,749 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:51,749 - ERROR - CRITICAL ERROR creating FAISS store for texte_code_societes_commerciales: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:51,750 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:51,750 - INFO - Final stores directory content: []
2025-05-05 22:34:51,750 - INFO - Successfully created 0 out of 6 possible stores
2025-05-05 22:34:51,750 - INFO - ============================================
2025-05-05 22:34:51,750 - INFO - COMPLETED CODE STORE CREATION PROCESS
2025-05-05 22:34:51,750 - INFO - ============================================
2025-05-05 22:34:51,751 - ERROR - CRITICAL: Failed to build code stores
2025-05-05 22:34:51,757 - INFO - Use pytorch device_name: cpu
2025-05-05 22:34:51,757 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:34:54,663 - INFO - Stores directory is empty or doesn't exist. Building code stores...
2025-05-05 22:34:54,664 - INFO - ============================================
2025-05-05 22:34:54,664 - INFO - STARTING CODE STORE CREATION PROCESS
2025-05-05 22:34:54,664 - INFO - ============================================
2025-05-05 22:34:54,665 - INFO - Removed existing stores directory to force clean rebuild
2025-05-05 22:34:54,666 - INFO - Created fresh stores directory at: C:\Users\chtar\Desktop\bouba\stores
2025-05-05 22:34:54,669 - INFO - Use pytorch device_name: cpu
2025-05-05 22:34:54,669 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:34:57,499 - INFO - Successfully initialized embedding model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:34:57,499 - INFO - Found 6 files in legal_codes directory: ['loi_defense_contre_pratiques_deloyales_importation.txt', 'loi_relative_commerce_exterieur.txt', 'loi_relative_Startups.txt', 'loi_societes_commerce_international.txt', 'loi_societes_ligne.txt', 'texte_code_societes_commerciales.txt']
2025-05-05 22:34:57,499 - INFO - Processing code file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt
2025-05-05 22:34:57,500 - INFO - Successfully read file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt - Size: 30641 characters
2025-05-05 22:34:57,500 - INFO - Found 52 article matches in loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:34:57,501 - INFO - Created 52 chunks for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:34:57,501 - INFO - Created 52 document objects for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:34:57,501 - INFO - Starting FAISS vectorstore creation for loi_defense_contre_pratiques_deloyales_importation...
2025-05-05 22:34:57,515 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:57,515 - ERROR - CRITICAL ERROR creating FAISS store for loi_defense_contre_pratiques_deloyales_importation: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:57,515 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:57,515 - INFO - Processing code file: legal_codes\loi_relative_commerce_exterieur.txt
2025-05-05 22:34:57,516 - INFO - Successfully read file: legal_codes\loi_relative_commerce_exterieur.txt - Size: 6553 characters
2025-05-05 22:34:57,516 - INFO - Found 17 article matches in loi_relative_commerce_exterieur
2025-05-05 22:34:57,516 - INFO - Created 17 chunks for loi_relative_commerce_exterieur
2025-05-05 22:34:57,516 - INFO - Created 17 document objects for loi_relative_commerce_exterieur
2025-05-05 22:34:57,516 - INFO - Starting FAISS vectorstore creation for loi_relative_commerce_exterieur...
2025-05-05 22:34:57,535 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:57,536 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_commerce_exterieur: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:57,536 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:57,536 - INFO - Processing code file: legal_codes\loi_relative_Startups.txt
2025-05-05 22:34:57,538 - INFO - Successfully read file: legal_codes\loi_relative_Startups.txt - Size: 14677 characters
2025-05-05 22:34:57,538 - INFO - Found 19 article matches in loi_relative_Startups
2025-05-05 22:34:57,539 - INFO - Created 19 chunks for loi_relative_Startups
2025-05-05 22:34:57,539 - INFO - Created 19 document objects for loi_relative_Startups
2025-05-05 22:34:57,539 - INFO - Starting FAISS vectorstore creation for loi_relative_Startups...
2025-05-05 22:34:57,558 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:57,558 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_Startups: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:57,559 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:57,559 - INFO - Processing code file: legal_codes\loi_societes_commerce_international.txt
2025-05-05 22:34:57,559 - INFO - Successfully read file: legal_codes\loi_societes_commerce_international.txt - Size: 8543 characters
2025-05-05 22:34:57,560 - INFO - Found 14 article matches in loi_societes_commerce_international
2025-05-05 22:34:57,560 - INFO - Created 14 chunks for loi_societes_commerce_international
2025-05-05 22:34:57,560 - INFO - Created 14 document objects for loi_societes_commerce_international
2025-05-05 22:34:57,560 - INFO - Starting FAISS vectorstore creation for loi_societes_commerce_international...
2025-05-05 22:34:57,578 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:57,578 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_commerce_international: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:57,579 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:57,579 - INFO - Processing code file: legal_codes\loi_societes_ligne.txt
2025-05-05 22:34:57,579 - INFO - Successfully read file: legal_codes\loi_societes_ligne.txt - Size: 1678 characters
2025-05-05 22:34:57,579 - INFO - Found 3 article matches in loi_societes_ligne
2025-05-05 22:34:57,579 - INFO - Created 3 chunks for loi_societes_ligne
2025-05-05 22:34:57,579 - INFO - Created 3 document objects for loi_societes_ligne
2025-05-05 22:34:57,579 - INFO - Starting FAISS vectorstore creation for loi_societes_ligne...
2025-05-05 22:34:57,598 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:57,598 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_ligne: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:57,599 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:57,599 - INFO - Processing code file: legal_codes\texte_code_societes_commerciales.txt
2025-05-05 22:34:57,601 - INFO - Successfully read file: legal_codes\texte_code_societes_commerciales.txt - Size: 306679 characters
2025-05-05 22:34:57,612 - INFO - Found 492 article matches in texte_code_societes_commerciales
2025-05-05 22:34:57,614 - INFO - Created 492 chunks for texte_code_societes_commerciales
2025-05-05 22:34:57,616 - INFO - Created 492 document objects for texte_code_societes_commerciales
2025-05-05 22:34:57,616 - INFO - Starting FAISS vectorstore creation for texte_code_societes_commerciales...
2025-05-05 22:34:57,633 - INFO - Test encoding successful. Shape: (384,)
2025-05-05 22:34:57,634 - ERROR - CRITICAL ERROR creating FAISS store for texte_code_societes_commerciales: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:34:57,634 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 668, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:34:57,634 - INFO - Final stores directory content: []
2025-05-05 22:34:57,634 - INFO - Successfully created 0 out of 6 possible stores
2025-05-05 22:34:57,634 - INFO - ============================================
2025-05-05 22:34:57,635 - INFO - COMPLETED CODE STORE CREATION PROCESS
2025-05-05 22:34:57,635 - INFO - ============================================
2025-05-05 22:34:57,635 - INFO - Loading code-specific vector stores from stores...
2025-05-05 22:34:57,636 - INFO - Loading pre-built indexes...
2025-05-05 22:35:01,685 - INFO - Loaded 1460 legal document chunks
2025-05-05 22:35:01,685 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-05 22:35:01,685 - INFO - Loaded 0 code-specific vector stores: None
2025-05-05 22:35:01,686 - INFO - ==== APPLICATION READY ====
2025-05-05 22:35:01,704 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-05 22:35:01,704 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 22:42:51,706 - INFO - Use pytorch device_name: cpu
2025-05-05 22:42:51,707 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:43:09,963 - INFO - ============================================
2025-05-05 22:43:09,963 - INFO - STARTING CODE STORE CREATION PROCESS
2025-05-05 22:43:09,963 - INFO - ============================================
2025-05-05 22:43:09,965 - INFO - Removed existing stores directory to force clean rebuild
2025-05-05 22:43:09,968 - INFO - Created fresh stores directory at: C:\Users\chtar\Desktop\bouba\stores
2025-05-05 22:43:09,970 - INFO - Found 6 files in legal_codes directory: ['loi_defense_contre_pratiques_deloyales_importation.txt', 'loi_relative_commerce_exterieur.txt', 'loi_relative_Startups.txt', 'loi_societes_commerce_international.txt', 'loi_societes_ligne.txt', 'texte_code_societes_commerciales.txt']
2025-05-05 22:43:09,971 - INFO - Processing code file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt
2025-05-05 22:43:09,973 - INFO - Successfully read file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt - Size: 30641 characters
2025-05-05 22:43:09,978 - INFO - Found 52 article matches in loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:43:09,979 - INFO - Created 52 chunks for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:43:10,708 - INFO - Created 52 document objects for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:43:10,709 - INFO - Starting FAISS vectorstore creation for loi_defense_contre_pratiques_deloyales_importation...
2025-05-05 22:43:10,709 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:10,709 - ERROR - CRITICAL ERROR creating FAISS store for loi_defense_contre_pratiques_deloyales_importation: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:10,716 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:10,717 - INFO - Processing code file: legal_codes\loi_relative_commerce_exterieur.txt
2025-05-05 22:43:10,719 - INFO - Successfully read file: legal_codes\loi_relative_commerce_exterieur.txt - Size: 6553 characters
2025-05-05 22:43:10,720 - INFO - Found 17 article matches in loi_relative_commerce_exterieur
2025-05-05 22:43:10,721 - INFO - Created 17 chunks for loi_relative_commerce_exterieur
2025-05-05 22:43:10,721 - INFO - Created 17 document objects for loi_relative_commerce_exterieur
2025-05-05 22:43:10,722 - INFO - Starting FAISS vectorstore creation for loi_relative_commerce_exterieur...
2025-05-05 22:43:10,722 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:10,723 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_commerce_exterieur: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:10,725 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:10,725 - INFO - Processing code file: legal_codes\loi_relative_Startups.txt
2025-05-05 22:43:10,727 - INFO - Successfully read file: legal_codes\loi_relative_Startups.txt - Size: 14677 characters
2025-05-05 22:43:10,729 - INFO - Found 19 article matches in loi_relative_Startups
2025-05-05 22:43:10,730 - INFO - Created 19 chunks for loi_relative_Startups
2025-05-05 22:43:10,731 - INFO - Created 19 document objects for loi_relative_Startups
2025-05-05 22:43:10,731 - INFO - Starting FAISS vectorstore creation for loi_relative_Startups...
2025-05-05 22:43:10,731 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:10,732 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_Startups: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:10,734 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:10,734 - INFO - Processing code file: legal_codes\loi_societes_commerce_international.txt
2025-05-05 22:43:10,735 - INFO - Successfully read file: legal_codes\loi_societes_commerce_international.txt - Size: 8543 characters
2025-05-05 22:43:10,738 - INFO - Found 14 article matches in loi_societes_commerce_international
2025-05-05 22:43:10,738 - INFO - Created 14 chunks for loi_societes_commerce_international
2025-05-05 22:43:10,739 - INFO - Created 14 document objects for loi_societes_commerce_international
2025-05-05 22:43:10,739 - INFO - Starting FAISS vectorstore creation for loi_societes_commerce_international...
2025-05-05 22:43:10,739 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:10,740 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_commerce_international: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:10,741 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:10,742 - INFO - Processing code file: legal_codes\loi_societes_ligne.txt
2025-05-05 22:43:10,744 - INFO - Successfully read file: legal_codes\loi_societes_ligne.txt - Size: 1678 characters
2025-05-05 22:43:10,745 - INFO - Found 3 article matches in loi_societes_ligne
2025-05-05 22:43:10,745 - INFO - Created 3 chunks for loi_societes_ligne
2025-05-05 22:43:10,745 - INFO - Created 3 document objects for loi_societes_ligne
2025-05-05 22:43:10,745 - INFO - Starting FAISS vectorstore creation for loi_societes_ligne...
2025-05-05 22:43:10,747 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:10,747 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_ligne: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:10,748 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:10,749 - INFO - Processing code file: legal_codes\texte_code_societes_commerciales.txt
2025-05-05 22:43:10,758 - INFO - Successfully read file: legal_codes\texte_code_societes_commerciales.txt - Size: 306679 characters
2025-05-05 22:43:10,794 - INFO - Found 492 article matches in texte_code_societes_commerciales
2025-05-05 22:43:10,799 - INFO - Created 492 chunks for texte_code_societes_commerciales
2025-05-05 22:43:10,806 - INFO - Created 492 document objects for texte_code_societes_commerciales
2025-05-05 22:43:10,807 - INFO - Starting FAISS vectorstore creation for texte_code_societes_commerciales...
2025-05-05 22:43:10,807 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:10,808 - ERROR - CRITICAL ERROR creating FAISS store for texte_code_societes_commerciales: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:10,810 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:10,811 - INFO - Final stores directory content: []
2025-05-05 22:43:10,811 - INFO - Successfully created 0 out of 6 possible stores
2025-05-05 22:43:10,811 - INFO - ============================================
2025-05-05 22:43:10,812 - INFO - COMPLETED CODE STORE CREATION PROCESS
2025-05-05 22:43:10,812 - INFO - ============================================
2025-05-05 22:43:10,838 - INFO - Use pytorch device_name: cpu
2025-05-05 22:43:10,838 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:43:18,085 - INFO - Stores directory is empty or doesn't exist. Building code stores...
2025-05-05 22:43:18,085 - INFO - ============================================
2025-05-05 22:43:18,085 - INFO - STARTING CODE STORE CREATION PROCESS
2025-05-05 22:43:18,086 - INFO - ============================================
2025-05-05 22:43:18,089 - INFO - Removed existing stores directory to force clean rebuild
2025-05-05 22:43:18,090 - INFO - Created fresh stores directory at: C:\Users\chtar\Desktop\bouba\stores
2025-05-05 22:43:18,091 - INFO - Found 6 files in legal_codes directory: ['loi_defense_contre_pratiques_deloyales_importation.txt', 'loi_relative_commerce_exterieur.txt', 'loi_relative_Startups.txt', 'loi_societes_commerce_international.txt', 'loi_societes_ligne.txt', 'texte_code_societes_commerciales.txt']
2025-05-05 22:43:18,093 - INFO - Processing code file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt
2025-05-05 22:43:18,094 - INFO - Successfully read file: legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt - Size: 30641 characters
2025-05-05 22:43:18,098 - INFO - Found 52 article matches in loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:43:18,099 - INFO - Created 52 chunks for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:43:18,100 - INFO - Created 52 document objects for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 22:43:18,100 - INFO - Starting FAISS vectorstore creation for loi_defense_contre_pratiques_deloyales_importation...
2025-05-05 22:43:18,101 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:18,101 - ERROR - CRITICAL ERROR creating FAISS store for loi_defense_contre_pratiques_deloyales_importation: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:18,103 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:18,103 - INFO - Processing code file: legal_codes\loi_relative_commerce_exterieur.txt
2025-05-05 22:43:18,104 - INFO - Successfully read file: legal_codes\loi_relative_commerce_exterieur.txt - Size: 6553 characters
2025-05-05 22:43:18,106 - INFO - Found 17 article matches in loi_relative_commerce_exterieur
2025-05-05 22:43:18,106 - INFO - Created 17 chunks for loi_relative_commerce_exterieur
2025-05-05 22:43:18,107 - INFO - Created 17 document objects for loi_relative_commerce_exterieur
2025-05-05 22:43:18,107 - INFO - Starting FAISS vectorstore creation for loi_relative_commerce_exterieur...
2025-05-05 22:43:18,107 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:18,107 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_commerce_exterieur: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:18,110 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:18,110 - INFO - Processing code file: legal_codes\loi_relative_Startups.txt
2025-05-05 22:43:18,111 - INFO - Successfully read file: legal_codes\loi_relative_Startups.txt - Size: 14677 characters
2025-05-05 22:43:18,114 - INFO - Found 19 article matches in loi_relative_Startups
2025-05-05 22:43:18,114 - INFO - Created 19 chunks for loi_relative_Startups
2025-05-05 22:43:18,115 - INFO - Created 19 document objects for loi_relative_Startups
2025-05-05 22:43:18,115 - INFO - Starting FAISS vectorstore creation for loi_relative_Startups...
2025-05-05 22:43:18,116 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:18,116 - ERROR - CRITICAL ERROR creating FAISS store for loi_relative_Startups: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:18,118 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:18,118 - INFO - Processing code file: legal_codes\loi_societes_commerce_international.txt
2025-05-05 22:43:18,119 - INFO - Successfully read file: legal_codes\loi_societes_commerce_international.txt - Size: 8543 characters
2025-05-05 22:43:18,121 - INFO - Found 14 article matches in loi_societes_commerce_international
2025-05-05 22:43:18,121 - INFO - Created 14 chunks for loi_societes_commerce_international
2025-05-05 22:43:18,122 - INFO - Created 14 document objects for loi_societes_commerce_international
2025-05-05 22:43:18,122 - INFO - Starting FAISS vectorstore creation for loi_societes_commerce_international...
2025-05-05 22:43:18,123 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:18,123 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_commerce_international: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:18,124 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:18,124 - INFO - Processing code file: legal_codes\loi_societes_ligne.txt
2025-05-05 22:43:18,125 - INFO - Successfully read file: legal_codes\loi_societes_ligne.txt - Size: 1678 characters
2025-05-05 22:43:18,126 - INFO - Found 3 article matches in loi_societes_ligne
2025-05-05 22:43:18,126 - INFO - Created 3 chunks for loi_societes_ligne
2025-05-05 22:43:18,126 - INFO - Created 3 document objects for loi_societes_ligne
2025-05-05 22:43:18,126 - INFO - Starting FAISS vectorstore creation for loi_societes_ligne...
2025-05-05 22:43:18,126 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:18,126 - ERROR - CRITICAL ERROR creating FAISS store for loi_societes_ligne: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:18,128 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:18,128 - INFO - Processing code file: legal_codes\texte_code_societes_commerciales.txt
2025-05-05 22:43:18,135 - INFO - Successfully read file: legal_codes\texte_code_societes_commerciales.txt - Size: 306679 characters
2025-05-05 22:43:18,178 - INFO - Found 492 article matches in texte_code_societes_commerciales
2025-05-05 22:43:18,182 - INFO - Created 492 chunks for texte_code_societes_commerciales
2025-05-05 22:43:18,189 - INFO - Created 492 document objects for texte_code_societes_commerciales
2025-05-05 22:43:18,190 - INFO - Starting FAISS vectorstore creation for texte_code_societes_commerciales...
2025-05-05 22:43:18,190 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 22:43:18,191 - ERROR - CRITICAL ERROR creating FAISS store for texte_code_societes_commerciales: 'SentenceTransformer' object has no attribute 'embed_documents'
2025-05-05 22:43:18,192 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in build_code_stores
    store = FAISS.from_documents(documents, embedding_model)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\vectorstores\base.py", line 847, in from_documents
    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_community\vectorstores\faiss.py", line 1043, in from_texts
    embeddings = embedding.embed_documents(texts)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'SentenceTransformer' object has no attribute 'embed_documents'

2025-05-05 22:43:18,192 - INFO - Final stores directory content: []
2025-05-05 22:43:18,193 - INFO - Successfully created 0 out of 6 possible stores
2025-05-05 22:43:18,193 - INFO - ============================================
2025-05-05 22:43:18,193 - INFO - COMPLETED CODE STORE CREATION PROCESS
2025-05-05 22:43:18,193 - INFO - ============================================
2025-05-05 22:43:18,194 - INFO - Loading code-specific vector stores from stores...
2025-05-05 22:43:18,196 - INFO - Loading pre-built indexes...
2025-05-05 22:43:35,598 - INFO - Loaded 1460 legal document chunks
2025-05-05 22:43:35,598 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-05 22:43:35,598 - INFO - Loaded 0 code-specific vector stores: None
2025-05-05 22:43:35,668 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-05 22:43:35,668 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 22:48:09,505 - INFO - 127.0.0.1 - - [05/May/2025 22:48:09] "GET / HTTP/1.1" 200 -
2025-05-05 22:48:09,558 - INFO - 127.0.0.1 - - [05/May/2025 22:48:09] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 22:48:09,578 - INFO - 127.0.0.1 - - [05/May/2025 22:48:09] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 22:48:11,042 - INFO - 127.0.0.1 - - [05/May/2025 22:48:11] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-05 22:48:15,367 - INFO - Processing query: 'comment lancer une startup?' for conversation 41
2025-05-05 22:48:15,377 - INFO - Query received: comment lancer une startup?
2025-05-05 22:48:15,525 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-05 22:48:15,546 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 22:48:15,547 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 22:48:20,328 - INFO - Token usage: prompt=1200, completion=1228, total=2428
2025-05-05 22:48:20,339 - INFO - Agent workflow completed in 4.99s
2025-05-05 22:48:20,511 - INFO - Request processed in 5.17s (thinking: 4.81s)
2025-05-05 22:48:20,514 - INFO - 127.0.0.1 - - [05/May/2025 22:48:20] "POST /ask HTTP/1.1" 200 -
2025-05-05 22:54:53,722 - INFO - Use pytorch device_name: cpu
2025-05-05 22:54:53,722 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:55:01,908 - INFO - Use pytorch device_name: cpu
2025-05-05 22:55:01,909 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 22:55:07,558 - INFO - Stores directory is empty or doesn't exist. Building code stores...
2025-05-05 22:55:07,601 - INFO - Loading code-specific vector stores from stores...
2025-05-05 22:55:07,603 - INFO - Loading pre-built indexes...
2025-05-05 22:55:13,877 - INFO - Loaded 1460 legal document chunks
2025-05-05 22:55:13,877 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-05 22:55:13,877 - INFO - Loaded 0 code-specific vector stores: None
2025-05-05 22:55:13,907 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-05 22:55:13,908 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 23:01:30,362 - INFO - Use pytorch device_name: cpu
2025-05-05 23:01:30,362 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 23:01:43,259 - INFO - Use pytorch device_name: cpu
2025-05-05 23:01:43,260 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 23:03:11,690 - INFO - Use pytorch device_name: cpu
2025-05-05 23:03:11,691 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 23:03:17,959 - INFO - Loading code-specific vector stores from stores...
2025-05-05 23:03:17,959 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:03:18,016 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 23:03:18,017 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:03:18,065 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-05 23:03:18,066 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:03:18,113 - INFO - Loaded vector store for loi_relative_Startups
2025-05-05 23:03:18,114 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:03:18,161 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-05 23:03:18,162 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:03:18,209 - INFO - Loaded vector store for loi_societes_ligne
2025-05-05 23:03:18,209 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:03:18,291 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-05 23:03:18,293 - INFO - Loading pre-built indexes...
2025-05-05 23:03:34,403 - INFO - Loaded 1460 legal document chunks
2025-05-05 23:03:34,404 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-05 23:03:34,404 - INFO - Loaded 6 code-specific vector stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-05 23:03:34,472 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-05 23:03:34,472 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 23:03:56,551 - INFO - 127.0.0.1 - - [05/May/2025 23:03:56] "GET / HTTP/1.1" 200 -
2025-05-05 23:03:56,583 - INFO - 127.0.0.1 - - [05/May/2025 23:03:56] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 23:03:56,600 - INFO - 127.0.0.1 - - [05/May/2025 23:03:56] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 23:03:58,300 - INFO - 127.0.0.1 - - [05/May/2025 23:03:58] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-05 23:04:03,362 - INFO - Processing query: 'comment lancer une startup?' for conversation 41
2025-05-05 23:04:03,366 - INFO - Query received: comment lancer une startup?
2025-05-05 23:04:03,479 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-05 23:04:03,503 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 23:04:03,503 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 23:04:08,263 - INFO - Token usage: prompt=1200, completion=1160, total=2360
2025-05-05 23:04:08,273 - INFO - Agent workflow completed in 4.93s
2025-05-05 23:04:08,483 - INFO - Request processed in 5.14s (thinking: 4.79s)
2025-05-05 23:04:08,484 - INFO - 127.0.0.1 - - [05/May/2025 23:04:08] "POST /ask HTTP/1.1" 200 -
2025-05-05 23:10:30,866 - INFO - 127.0.0.1 - - [05/May/2025 23:10:30] "GET /get_conversation/40 HTTP/1.1" 200 -
2025-05-05 23:11:10,539 - INFO - Processing query: 'c'est quoi une startup?' for conversation 40
2025-05-05 23:11:10,543 - INFO - Query received: c'est quoi une startup?
2025-05-05 23:11:10,663 - INFO - Search scores:
Document 69 (chunk: chunk_69): score=0.5000, confidence=100.00%
Document 1419 (chunk: chunk_1362): score=0.4642, confidence=92.85%
Document 544 (chunk: chunk_516): score=0.4267, confidence=85.33%
Document 531 (chunk: chunk_503): score=0.4221, confidence=84.41%
Document 755 (chunk: chunk_723): score=0.4134, confidence=82.68%
2025-05-05 23:11:10,691 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 23:11:10,692 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 23:11:14,119 - INFO - Token usage: prompt=1055, completion=501, total=1556
2025-05-05 23:11:14,135 - INFO - Agent workflow completed in 3.62s
2025-05-05 23:11:14,206 - INFO - Request processed in 3.69s (thinking: 3.47s)
2025-05-05 23:11:14,209 - INFO - 127.0.0.1 - - [05/May/2025 23:11:14] "POST /ask HTTP/1.1" 200 -
2025-05-05 23:26:55,012 - INFO - Use pytorch device_name: cpu
2025-05-05 23:26:55,012 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 23:27:08,715 - INFO - Use pytorch device_name: cpu
2025-05-05 23:27:08,715 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 23:27:56,677 - INFO - Use pytorch device_name: cpu
2025-05-05 23:27:56,678 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 23:28:00,694 - INFO - Loading code-specific vector stores from stores...
2025-05-05 23:28:00,694 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:28:00,730 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 23:28:00,731 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:28:00,766 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-05 23:28:00,767 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:28:00,790 - INFO - Loaded vector store for loi_relative_Startups
2025-05-05 23:28:00,791 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:28:00,810 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-05 23:28:00,810 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:28:00,829 - INFO - Loaded vector store for loi_societes_ligne
2025-05-05 23:28:00,829 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:28:00,858 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-05 23:28:00,859 - INFO - Loading pre-built indexes...
2025-05-05 23:28:10,781 - INFO - Loaded 1460 legal document chunks
2025-05-05 23:28:10,781 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-05 23:28:10,781 - INFO - Loaded 6 code-specific vector stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-05 23:28:10,890 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-05 23:28:10,891 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 23:28:25,159 - INFO - 127.0.0.1 - - [05/May/2025 23:28:25] "GET / HTTP/1.1" 200 -
2025-05-05 23:28:25,190 - INFO - 127.0.0.1 - - [05/May/2025 23:28:25] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 23:28:25,214 - INFO - 127.0.0.1 - - [05/May/2025 23:28:25] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 23:28:27,018 - INFO - 127.0.0.1 - - [05/May/2025 23:28:27] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-05 23:28:38,235 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-05 23:28:39,027 - INFO - Token usage: prompt=54, completion=11, total=65
2025-05-05 23:28:39,056 - INFO - Processing query: 'comment lancer une startup?' for conversation 42
2025-05-05 23:28:39,057 - INFO - Query received: comment lancer une startup?
2025-05-05 23:28:39,098 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-05 23:28:39,107 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 23:28:39,107 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 23:28:44,543 - INFO - Token usage: prompt=1200, completion=1111, total=2311
2025-05-05 23:28:44,553 - INFO - Agent workflow completed in 6.32s
2025-05-05 23:28:44,637 - INFO - Request processed in 6.40s (thinking: 5.45s)
2025-05-05 23:28:44,638 - INFO - 127.0.0.1 - - [05/May/2025 23:28:44] "POST /ask HTTP/1.1" 200 -
2025-05-05 23:44:22,899 - INFO - Use pytorch device_name: cpu
2025-05-05 23:44:22,899 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 23:44:28,122 - INFO - Use pytorch device_name: cpu
2025-05-05 23:44:28,123 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 23:44:53,158 - INFO - 127.0.0.1 - - [05/May/2025 23:44:53] "GET / HTTP/1.1" 200 -
2025-05-05 23:44:53,189 - INFO - 127.0.0.1 - - [05/May/2025 23:44:53] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 23:44:53,214 - INFO - 127.0.0.1 - - [05/May/2025 23:44:53] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 23:44:55,861 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-05 23:44:56,224 - INFO - Token usage: prompt=57, completion=8, total=65
2025-05-05 23:44:56,260 - INFO - Processing query: 'How does inheritance law work in Tunisia?' for conversation 43
2025-05-05 23:44:56,262 - INFO - Query received: How does inheritance law work in Tunisia?
2025-05-05 23:44:58,267 - INFO - Search scores:
Document 473 (chunk: chunk_446_sub_1): score=0.5914, confidence=100.00%
Document 472 (chunk: chunk_446): score=0.5488, confidence=92.80%
Document 269 (chunk: chunk_256): score=0.5000, confidence=84.55%
Document 638 (chunk: chunk_610): score=0.4992, confidence=84.41%
Document 196 (chunk: chunk_185): score=0.4802, confidence=81.20%
2025-05-05 23:44:58,293 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 23:44:58,293 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 23:44:59,750 - INFO - Token usage: prompt=1206, completion=258, total=1464
2025-05-05 23:44:59,753 - INFO - Agent workflow completed in 3.89s
2025-05-05 23:44:59,796 - INFO - Request processed in 3.93s (thinking: 1.48s)
2025-05-05 23:44:59,798 - INFO - 127.0.0.1 - - [05/May/2025 23:44:59] "POST /ask HTTP/1.1" 200 -
2025-05-05 23:45:13,322 - INFO - Use pytorch device_name: cpu
2025-05-05 23:45:13,322 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-05 23:45:16,825 - INFO - Loading code-specific vector stores from stores...
2025-05-05 23:45:16,826 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:45:16,843 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-05 23:45:16,843 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:45:16,861 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-05 23:45:16,861 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:45:16,876 - INFO - Loaded vector store for loi_relative_Startups
2025-05-05 23:45:16,876 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:45:16,891 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-05 23:45:16,891 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:45:16,900 - INFO - Loaded vector store for loi_societes_ligne
2025-05-05 23:45:16,901 - INFO - Using langchain_community.vectorstores FAISS
2025-05-05 23:45:16,920 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-05 23:45:16,920 - INFO - Loading pre-built indexes...
2025-05-05 23:45:20,545 - INFO - Loaded 1460 legal document chunks
2025-05-05 23:45:20,545 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-05 23:45:20,545 - INFO - Loaded 6 code-specific vector stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-05 23:45:20,565 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-05 23:45:20,565 - INFO - [33mPress CTRL+C to quit[0m
2025-05-05 23:45:23,902 - INFO - 127.0.0.1 - - [05/May/2025 23:45:23] "GET / HTTP/1.1" 200 -
2025-05-05 23:45:23,933 - INFO - 127.0.0.1 - - [05/May/2025 23:45:23] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-05 23:45:23,948 - INFO - 127.0.0.1 - - [05/May/2025 23:45:23] "GET /get_conversations HTTP/1.1" 200 -
2025-05-05 23:45:32,306 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-05 23:45:32,631 - INFO - Token usage: prompt=54, completion=12, total=66
2025-05-05 23:45:32,662 - INFO - Processing query: 'comment lancer une startup?' for conversation 44
2025-05-05 23:45:32,663 - INFO - Query received: comment lancer une startup?
2025-05-05 23:45:32,692 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-05 23:45:32,700 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 23:45:32,700 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 23:45:35,356 - INFO - Token usage: prompt=1200, completion=526, total=1726
2025-05-05 23:45:35,362 - INFO - Agent workflow completed in 3.06s
2025-05-05 23:45:35,382 - INFO - Request processed in 3.08s (thinking: 2.67s)
2025-05-05 23:45:35,382 - INFO - 127.0.0.1 - - [05/May/2025 23:45:35] "POST /ask HTTP/1.1" 200 -
2025-05-05 23:45:53,252 - INFO - 127.0.0.1 - - [05/May/2025 23:45:53] "GET /get_conversation/42 HTTP/1.1" 200 -
2025-05-05 23:45:56,133 - INFO - Processing query: 'comment lancer une startup?' for conversation 42
2025-05-05 23:45:56,134 - INFO - Query received: comment lancer une startup?
2025-05-05 23:45:56,163 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-05 23:45:56,167 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 23:45:56,167 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 23:46:00,598 - INFO - Token usage: prompt=1200, completion=1124, total=2324
2025-05-05 23:46:00,601 - INFO - Agent workflow completed in 4.48s
2025-05-05 23:46:00,664 - INFO - Request processed in 4.55s (thinking: 4.44s)
2025-05-05 23:46:00,665 - INFO - 127.0.0.1 - - [05/May/2025 23:46:00] "POST /ask HTTP/1.1" 200 -
2025-05-05 23:48:02,970 - INFO - 127.0.0.1 - - [05/May/2025 23:48:02] "GET /get_conversation/43 HTTP/1.1" 200 -
2025-05-05 23:48:09,085 - INFO - 127.0.0.1 - - [05/May/2025 23:48:09] "DELETE /delete_conversation/43 HTTP/1.1" 200 -
2025-05-05 23:48:10,890 - INFO - 127.0.0.1 - - [05/May/2025 23:48:10] "GET /get_conversation/42 HTTP/1.1" 200 -
2025-05-05 23:48:23,878 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-05 23:48:24,371 - INFO - Token usage: prompt=54, completion=13, total=67
2025-05-05 23:48:24,405 - INFO - Processing query: 'comment lancer une startup?' for conversation 45
2025-05-05 23:48:24,407 - INFO - Query received: comment lancer une startup?
2025-05-05 23:48:24,459 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-05 23:48:24,469 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-05 23:48:24,469 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-05 23:48:30,832 - INFO - 127.0.0.1 - - [05/May/2025 23:48:30] "DELETE /delete_conversation/39 HTTP/1.1" 200 -
2025-05-05 23:48:30,861 - INFO - Token usage: prompt=1200, completion=1589, total=2789
2025-05-05 23:48:30,867 - INFO - Agent workflow completed in 6.99s
2025-05-05 23:48:31,040 - INFO - Request processed in 7.16s (thinking: 6.41s)
2025-05-05 23:48:31,042 - INFO - 127.0.0.1 - - [05/May/2025 23:48:31] "POST /ask HTTP/1.1" 200 -
2025-05-05 23:49:22,328 - INFO - 127.0.0.1 - - [05/May/2025 23:49:22] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-05 23:49:24,007 - INFO - 127.0.0.1 - - [05/May/2025 23:49:24] "GET /get_conversation/40 HTTP/1.1" 200 -
2025-05-05 23:49:31,499 - INFO - 127.0.0.1 - - [05/May/2025 23:49:31] "GET /get_conversation/42 HTTP/1.1" 200 -
2025-05-05 23:49:35,291 - INFO - 127.0.0.1 - - [05/May/2025 23:49:35] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-05 23:49:36,209 - INFO - 127.0.0.1 - - [05/May/2025 23:49:36] "GET /get_conversation/40 HTTP/1.1" 200 -
2025-05-06 00:27:09,284 - INFO - Use pytorch device_name: cpu
2025-05-06 00:27:09,284 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:27:14,385 - INFO - Use pytorch device_name: cpu
2025-05-06 00:27:14,385 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:27:54,168 - INFO - Use pytorch device_name: cpu
2025-05-06 00:27:54,168 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:27:57,108 - INFO - Loading code-specific vector stores from stores...
2025-05-06 00:27:57,108 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:27:57,128 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-06 00:27:57,128 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:27:57,142 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-06 00:27:57,143 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:27:57,160 - INFO - Loaded vector store for loi_relative_Startups
2025-05-06 00:27:57,160 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:27:57,175 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-06 00:27:57,175 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:27:57,184 - INFO - Loaded vector store for loi_societes_ligne
2025-05-06 00:27:57,185 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:27:57,203 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-06 00:27:57,203 - INFO - Loading pre-built indexes...
2025-05-06 00:28:00,790 - INFO - Loaded 1460 legal document chunks
2025-05-06 00:28:00,790 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-06 00:28:00,790 - INFO - Loaded 6 code-specific vector stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-06 00:28:00,912 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-06 00:28:00,912 - INFO - [33mPress CTRL+C to quit[0m
2025-05-06 00:28:48,505 - INFO - 127.0.0.1 - - [06/May/2025 00:28:48] "GET / HTTP/1.1" 200 -
2025-05-06 00:28:48,530 - INFO - 127.0.0.1 - - [06/May/2025 00:28:48] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 00:28:48,549 - INFO - 127.0.0.1 - - [06/May/2025 00:28:48] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 00:28:50,052 - INFO - 127.0.0.1 - - [06/May/2025 00:28:50] "GET /get_conversation/45 HTTP/1.1" 200 -
2025-05-06 00:28:55,168 - INFO - 127.0.0.1 - - [06/May/2025 00:28:55] "GET / HTTP/1.1" 200 -
2025-05-06 00:28:55,195 - INFO - 127.0.0.1 - - [06/May/2025 00:28:55] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 00:28:55,208 - INFO - 127.0.0.1 - - [06/May/2025 00:28:55] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 00:28:55,818 - INFO - 127.0.0.1 - - [06/May/2025 00:28:55] "GET / HTTP/1.1" 200 -
2025-05-06 00:28:55,835 - INFO - 127.0.0.1 - - [06/May/2025 00:28:55] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 00:28:55,847 - INFO - 127.0.0.1 - - [06/May/2025 00:28:55] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 00:28:55,990 - INFO - 127.0.0.1 - - [06/May/2025 00:28:55] "GET / HTTP/1.1" 200 -
2025-05-06 00:28:56,007 - INFO - 127.0.0.1 - - [06/May/2025 00:28:56] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 00:28:56,015 - INFO - 127.0.0.1 - - [06/May/2025 00:28:56] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 00:28:56,207 - INFO - 127.0.0.1 - - [06/May/2025 00:28:56] "GET / HTTP/1.1" 200 -
2025-05-06 00:28:56,224 - INFO - 127.0.0.1 - - [06/May/2025 00:28:56] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 00:28:56,237 - INFO - 127.0.0.1 - - [06/May/2025 00:28:56] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 00:28:58,143 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-06 00:28:58,517 - INFO - Token usage: prompt=54, completion=11, total=65
2025-05-06 00:28:58,563 - INFO - Processing query: 'comment lancer une startup?' for conversation 46
2025-05-06 00:28:58,569 - INFO - Query received: comment lancer une startup?
2025-05-06 00:28:58,691 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-06 00:28:58,698 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-06 00:28:58,698 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-06 00:29:01,034 - INFO - Token usage: prompt=1200, completion=511, total=1711
2025-05-06 00:29:01,042 - INFO - Agent workflow completed in 2.90s
2025-05-06 00:29:01,074 - INFO - Request processed in 2.93s (thinking: 2.35s)
2025-05-06 00:29:01,075 - INFO - 127.0.0.1 - - [06/May/2025 00:29:01] "POST /ask HTTP/1.1" 200 -
2025-05-06 00:31:26,983 - INFO - Use pytorch device_name: cpu
2025-05-06 00:31:26,983 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:31:33,519 - INFO - Use pytorch device_name: cpu
2025-05-06 00:31:33,519 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:32:14,318 - INFO - Use pytorch device_name: cpu
2025-05-06 00:32:14,318 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:32:17,572 - INFO - Loading code-specific vector stores from stores...
2025-05-06 00:32:17,572 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:32:17,590 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-06 00:32:17,590 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:32:17,604 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-06 00:32:17,605 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:32:17,621 - INFO - Loaded vector store for loi_relative_Startups
2025-05-06 00:32:17,622 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:32:17,637 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-06 00:32:17,637 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:32:17,645 - INFO - Loaded vector store for loi_societes_ligne
2025-05-06 00:32:17,646 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:32:17,666 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-06 00:32:17,666 - INFO - Loading pre-built indexes...
2025-05-06 00:32:17,689 - ERROR - Failed to initialize data: Expecting value: line 1 column 1 (char 0)
2025-05-06 00:32:17,711 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 781, in initialize_data
    bm25_corpus = json.load(f)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\json\__init__.py", line 293, in load
    return loads(fp.read(),
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

2025-05-06 00:34:43,165 - INFO - Use pytorch device_name: cpu
2025-05-06 00:34:43,165 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:34:48,857 - INFO - Use pytorch device_name: cpu
2025-05-06 00:34:48,857 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:35:29,094 - INFO - Use pytorch device_name: cpu
2025-05-06 00:35:29,094 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:35:31,922 - INFO - Loading code-specific vector stores from stores...
2025-05-06 00:35:31,923 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:35:31,942 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-06 00:35:31,943 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:35:31,962 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-06 00:35:31,962 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:35:31,977 - INFO - Loaded vector store for loi_relative_Startups
2025-05-06 00:35:31,977 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:35:31,992 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-06 00:35:31,992 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:35:32,008 - INFO - Loaded vector store for loi_societes_ligne
2025-05-06 00:35:32,008 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:35:32,026 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-06 00:35:32,026 - INFO - Rebuilding indexes due to updated data...
2025-05-06 00:35:35,380 - INFO - Parsed 1460 legal document chunks
2025-05-06 00:35:35,380 - INFO - Processing batch 1/183: chunks 0 to 7
2025-05-06 00:35:35,382 - INFO - Use pytorch device_name: cpu
2025-05-06 00:35:35,382 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:35:38,537 - INFO - Processing batch 2/183: chunks 8 to 15
2025-05-06 00:35:38,540 - INFO - Use pytorch device_name: cpu
2025-05-06 00:35:38,540 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:35:41,496 - INFO - Processing batch 3/183: chunks 16 to 23
2025-05-06 00:35:41,499 - INFO - Use pytorch device_name: cpu
2025-05-06 00:35:41,499 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:35:44,966 - INFO - Processing batch 4/183: chunks 24 to 31
2025-05-06 00:35:44,970 - INFO - Use pytorch device_name: cpu
2025-05-06 00:35:44,970 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:35:48,097 - INFO - Processing batch 5/183: chunks 32 to 39
2025-05-06 00:35:48,100 - INFO - Use pytorch device_name: cpu
2025-05-06 00:35:48,100 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:35:51,662 - INFO - Processing batch 6/183: chunks 40 to 47
2025-05-06 00:35:51,665 - INFO - Use pytorch device_name: cpu
2025-05-06 00:35:51,665 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:35:54,605 - INFO - Processing batch 7/183: chunks 48 to 55
2025-05-06 00:35:54,607 - INFO - Use pytorch device_name: cpu
2025-05-06 00:35:54,608 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:35:57,413 - INFO - Processing batch 8/183: chunks 56 to 63
2025-05-06 00:35:57,416 - INFO - Use pytorch device_name: cpu
2025-05-06 00:35:57,416 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:00,769 - INFO - Processing batch 9/183: chunks 64 to 71
2025-05-06 00:36:00,772 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:00,772 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:03,945 - INFO - Processing batch 10/183: chunks 72 to 79
2025-05-06 00:36:03,949 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:03,949 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:07,044 - INFO - Processing batch 11/183: chunks 80 to 87
2025-05-06 00:36:07,047 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:07,048 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:10,391 - INFO - Processing batch 12/183: chunks 88 to 95
2025-05-06 00:36:10,395 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:10,395 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:14,649 - INFO - Processing batch 13/183: chunks 96 to 103
2025-05-06 00:36:14,652 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:14,652 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:18,325 - INFO - Processing batch 14/183: chunks 104 to 111
2025-05-06 00:36:18,328 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:18,328 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:21,337 - INFO - Processing batch 15/183: chunks 112 to 119
2025-05-06 00:36:21,339 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:21,339 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:24,259 - INFO - Processing batch 16/183: chunks 120 to 127
2025-05-06 00:36:24,262 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:24,262 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:27,136 - INFO - Processing batch 17/183: chunks 128 to 135
2025-05-06 00:36:27,139 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:27,139 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:30,268 - INFO - Processing batch 18/183: chunks 136 to 143
2025-05-06 00:36:30,272 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:30,272 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:33,604 - INFO - Processing batch 19/183: chunks 144 to 151
2025-05-06 00:36:33,607 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:33,607 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:36,416 - INFO - Processing batch 20/183: chunks 152 to 159
2025-05-06 00:36:36,419 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:36,419 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:39,347 - INFO - Processing batch 21/183: chunks 160 to 167
2025-05-06 00:36:39,351 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:39,351 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:42,226 - INFO - Processing batch 22/183: chunks 168 to 175
2025-05-06 00:36:42,229 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:42,229 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:45,132 - INFO - Processing batch 23/183: chunks 176 to 183
2025-05-06 00:36:45,135 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:45,135 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:48,263 - INFO - Processing batch 24/183: chunks 184 to 191
2025-05-06 00:36:48,265 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:48,265 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:51,136 - INFO - Processing batch 25/183: chunks 192 to 199
2025-05-06 00:36:51,139 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:51,139 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:54,176 - INFO - Processing batch 26/183: chunks 200 to 207
2025-05-06 00:36:54,179 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:54,179 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:36:57,151 - INFO - Processing batch 27/183: chunks 208 to 215
2025-05-06 00:36:57,154 - INFO - Use pytorch device_name: cpu
2025-05-06 00:36:57,155 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:00,404 - INFO - Processing batch 28/183: chunks 216 to 223
2025-05-06 00:37:00,408 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:00,408 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:04,290 - INFO - Processing batch 29/183: chunks 224 to 231
2025-05-06 00:37:04,292 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:04,292 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:07,506 - INFO - Processing batch 30/183: chunks 232 to 239
2025-05-06 00:37:07,508 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:07,508 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:10,625 - INFO - Processing batch 31/183: chunks 240 to 247
2025-05-06 00:37:10,628 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:10,628 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:13,985 - INFO - Processing batch 32/183: chunks 248 to 255
2025-05-06 00:37:13,988 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:13,989 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:17,138 - INFO - Processing batch 33/183: chunks 256 to 263
2025-05-06 00:37:17,142 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:17,142 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:20,390 - INFO - Processing batch 34/183: chunks 264 to 271
2025-05-06 00:37:20,393 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:20,393 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:23,489 - INFO - Processing batch 35/183: chunks 272 to 279
2025-05-06 00:37:23,492 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:23,493 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:27,144 - INFO - Processing batch 36/183: chunks 280 to 287
2025-05-06 00:37:27,149 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:27,149 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:30,324 - INFO - Processing batch 37/183: chunks 288 to 295
2025-05-06 00:37:30,327 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:30,327 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:33,637 - INFO - Processing batch 38/183: chunks 296 to 303
2025-05-06 00:37:33,640 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:33,640 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:36,568 - INFO - Processing batch 39/183: chunks 304 to 311
2025-05-06 00:37:36,572 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:36,572 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:39,564 - INFO - Processing batch 40/183: chunks 312 to 319
2025-05-06 00:37:39,567 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:39,567 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:42,950 - INFO - Processing batch 41/183: chunks 320 to 327
2025-05-06 00:37:42,954 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:42,954 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:45,890 - INFO - Processing batch 42/183: chunks 328 to 335
2025-05-06 00:37:45,893 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:45,893 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:48,998 - INFO - Processing batch 43/183: chunks 336 to 343
2025-05-06 00:37:49,001 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:49,001 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:52,321 - INFO - Processing batch 44/183: chunks 344 to 351
2025-05-06 00:37:52,324 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:52,324 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:37:56,448 - INFO - Processing batch 45/183: chunks 352 to 359
2025-05-06 00:37:56,451 - INFO - Use pytorch device_name: cpu
2025-05-06 00:37:56,451 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:00,216 - INFO - Processing batch 46/183: chunks 360 to 367
2025-05-06 00:38:00,219 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:00,219 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:03,134 - INFO - Processing batch 47/183: chunks 368 to 375
2025-05-06 00:38:03,137 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:03,137 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:06,161 - INFO - Processing batch 48/183: chunks 376 to 383
2025-05-06 00:38:06,165 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:06,165 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:09,050 - INFO - Processing batch 49/183: chunks 384 to 391
2025-05-06 00:38:09,053 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:09,053 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:11,883 - INFO - Processing batch 50/183: chunks 392 to 399
2025-05-06 00:38:11,887 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:11,887 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:15,087 - INFO - Processing batch 51/183: chunks 400 to 407
2025-05-06 00:38:15,089 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:15,089 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:17,891 - INFO - Processing batch 52/183: chunks 408 to 415
2025-05-06 00:38:17,895 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:17,895 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:20,863 - INFO - Processing batch 53/183: chunks 416 to 423
2025-05-06 00:38:20,866 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:20,866 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:24,019 - INFO - Processing batch 54/183: chunks 424 to 431
2025-05-06 00:38:24,021 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:24,021 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:28,279 - INFO - Processing batch 55/183: chunks 432 to 439
2025-05-06 00:38:28,283 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:28,283 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:31,768 - INFO - Processing batch 56/183: chunks 440 to 447
2025-05-06 00:38:31,772 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:31,772 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:35,664 - INFO - Processing batch 57/183: chunks 448 to 455
2025-05-06 00:38:35,667 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:35,667 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:38,708 - INFO - Processing batch 58/183: chunks 456 to 463
2025-05-06 00:38:38,711 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:38,711 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:41,820 - INFO - Processing batch 59/183: chunks 464 to 471
2025-05-06 00:38:41,822 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:41,822 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:44,790 - INFO - Processing batch 60/183: chunks 472 to 479
2025-05-06 00:38:44,793 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:44,793 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:47,741 - INFO - Processing batch 61/183: chunks 480 to 487
2025-05-06 00:38:47,744 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:47,744 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:50,806 - INFO - Processing batch 62/183: chunks 488 to 495
2025-05-06 00:38:50,809 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:50,809 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:54,029 - INFO - Processing batch 63/183: chunks 496 to 503
2025-05-06 00:38:54,032 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:54,032 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:38:57,344 - INFO - Processing batch 64/183: chunks 504 to 511
2025-05-06 00:38:57,350 - INFO - Use pytorch device_name: cpu
2025-05-06 00:38:57,350 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:01,120 - INFO - Processing batch 65/183: chunks 512 to 519
2025-05-06 00:39:01,127 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:01,127 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:05,421 - INFO - Processing batch 66/183: chunks 520 to 527
2025-05-06 00:39:05,424 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:05,424 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:09,485 - INFO - Processing batch 67/183: chunks 528 to 535
2025-05-06 00:39:09,489 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:09,489 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:13,482 - INFO - Processing batch 68/183: chunks 536 to 543
2025-05-06 00:39:13,487 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:13,487 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:17,640 - INFO - Processing batch 69/183: chunks 544 to 551
2025-05-06 00:39:17,644 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:17,644 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:22,379 - INFO - Processing batch 70/183: chunks 552 to 559
2025-05-06 00:39:22,386 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:22,386 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:26,055 - INFO - Processing batch 71/183: chunks 560 to 567
2025-05-06 00:39:26,058 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:26,058 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:30,637 - INFO - Processing batch 72/183: chunks 568 to 575
2025-05-06 00:39:30,640 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:30,640 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:36,338 - INFO - Processing batch 73/183: chunks 576 to 583
2025-05-06 00:39:36,343 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:36,343 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:39,861 - INFO - Processing batch 74/183: chunks 584 to 591
2025-05-06 00:39:39,864 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:39,864 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:44,004 - INFO - Processing batch 75/183: chunks 592 to 599
2025-05-06 00:39:44,008 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:44,008 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:48,642 - INFO - Processing batch 76/183: chunks 600 to 607
2025-05-06 00:39:48,647 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:48,648 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:52,679 - INFO - Processing batch 77/183: chunks 608 to 615
2025-05-06 00:39:52,683 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:52,683 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:39:56,310 - INFO - Processing batch 78/183: chunks 616 to 623
2025-05-06 00:39:56,316 - INFO - Use pytorch device_name: cpu
2025-05-06 00:39:56,316 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:00,524 - INFO - Processing batch 79/183: chunks 624 to 631
2025-05-06 00:40:00,532 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:00,532 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:04,585 - INFO - Processing batch 80/183: chunks 632 to 639
2025-05-06 00:40:04,589 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:04,589 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:08,381 - INFO - Processing batch 81/183: chunks 640 to 647
2025-05-06 00:40:08,388 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:08,388 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:11,830 - INFO - Processing batch 82/183: chunks 648 to 655
2025-05-06 00:40:11,834 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:11,834 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:14,961 - INFO - Processing batch 83/183: chunks 656 to 663
2025-05-06 00:40:14,964 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:14,964 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:18,815 - INFO - Processing batch 84/183: chunks 664 to 671
2025-05-06 00:40:18,821 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:18,821 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:22,558 - INFO - Processing batch 85/183: chunks 672 to 679
2025-05-06 00:40:22,563 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:22,563 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:26,041 - INFO - Processing batch 86/183: chunks 680 to 687
2025-05-06 00:40:26,048 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:26,048 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:30,038 - INFO - Processing batch 87/183: chunks 688 to 695
2025-05-06 00:40:30,046 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:30,046 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:34,382 - INFO - Processing batch 88/183: chunks 696 to 703
2025-05-06 00:40:34,387 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:34,387 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:38,092 - INFO - Processing batch 89/183: chunks 704 to 711
2025-05-06 00:40:38,097 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:38,097 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:44,497 - INFO - Processing batch 90/183: chunks 712 to 719
2025-05-06 00:40:44,509 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:44,509 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:51,583 - INFO - Processing batch 91/183: chunks 720 to 727
2025-05-06 00:40:51,591 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:51,592 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:40:57,524 - INFO - Processing batch 92/183: chunks 728 to 735
2025-05-06 00:40:57,531 - INFO - Use pytorch device_name: cpu
2025-05-06 00:40:57,531 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:41:02,842 - INFO - Processing batch 93/183: chunks 736 to 743
2025-05-06 00:41:02,848 - INFO - Use pytorch device_name: cpu
2025-05-06 00:41:02,848 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:41:07,159 - INFO - Processing batch 94/183: chunks 744 to 751
2025-05-06 00:41:07,162 - INFO - Use pytorch device_name: cpu
2025-05-06 00:41:07,162 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:41:11,281 - INFO - Processing batch 95/183: chunks 752 to 759
2025-05-06 00:41:11,285 - INFO - Use pytorch device_name: cpu
2025-05-06 00:41:11,285 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:41:15,278 - INFO - Processing batch 96/183: chunks 760 to 767
2025-05-06 00:41:15,282 - INFO - Use pytorch device_name: cpu
2025-05-06 00:41:15,282 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:41:19,585 - INFO - Processing batch 97/183: chunks 768 to 775
2025-05-06 00:41:19,589 - INFO - Use pytorch device_name: cpu
2025-05-06 00:41:19,590 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:41:23,677 - INFO - Processing batch 98/183: chunks 776 to 783
2025-05-06 00:41:23,681 - INFO - Use pytorch device_name: cpu
2025-05-06 00:41:23,681 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:41:27,871 - INFO - Processing batch 99/183: chunks 784 to 791
2025-05-06 00:41:27,874 - INFO - Use pytorch device_name: cpu
2025-05-06 00:41:27,874 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:41:31,218 - INFO - Processing batch 100/183: chunks 792 to 799
2025-05-06 00:41:31,221 - INFO - Use pytorch device_name: cpu
2025-05-06 00:41:31,221 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:41:34,459 - INFO - Processing batch 101/183: chunks 800 to 807
2025-05-06 00:41:34,462 - INFO - Use pytorch device_name: cpu
2025-05-06 00:41:34,462 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:41:37,467 - INFO - Processing batch 102/183: chunks 808 to 815
2025-05-06 00:41:37,472 - INFO - Use pytorch device_name: cpu
2025-05-06 00:41:37,472 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:05,551 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:05,552 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:10,697 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:10,697 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:13,440 - INFO - Loading code-specific vector stores from stores...
2025-05-06 00:44:13,440 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:44:13,441 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-06 00:44:13,441 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:44:13,442 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-06 00:44:13,442 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:44:13,442 - INFO - Loaded vector store for loi_relative_Startups
2025-05-06 00:44:13,442 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:44:13,443 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-06 00:44:13,443 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:44:13,443 - INFO - Loaded vector store for loi_societes_ligne
2025-05-06 00:44:13,444 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 00:44:13,446 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-06 00:44:13,447 - INFO - Rebuilding indexes due to updated data...
2025-05-06 00:44:16,910 - INFO - Parsed 1460 legal document chunks
2025-05-06 00:44:16,910 - INFO - Processing batch 1/183: chunks 0 to 7
2025-05-06 00:44:16,913 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:16,913 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:20,165 - INFO - Processing batch 2/183: chunks 8 to 15
2025-05-06 00:44:20,168 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:20,168 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:22,999 - INFO - Processing batch 3/183: chunks 16 to 23
2025-05-06 00:44:23,002 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:23,002 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:26,046 - INFO - Processing batch 4/183: chunks 24 to 31
2025-05-06 00:44:26,049 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:26,049 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:28,942 - INFO - Processing batch 5/183: chunks 32 to 39
2025-05-06 00:44:28,945 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:28,945 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:31,881 - INFO - Processing batch 6/183: chunks 40 to 47
2025-05-06 00:44:31,884 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:31,884 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:34,799 - INFO - Processing batch 7/183: chunks 48 to 55
2025-05-06 00:44:34,802 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:34,802 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:37,743 - INFO - Processing batch 8/183: chunks 56 to 63
2025-05-06 00:44:37,746 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:37,746 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:40,649 - INFO - Processing batch 9/183: chunks 64 to 71
2025-05-06 00:44:40,652 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:40,653 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:43,777 - INFO - Processing batch 10/183: chunks 72 to 79
2025-05-06 00:44:43,780 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:43,780 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:46,768 - INFO - Processing batch 11/183: chunks 80 to 87
2025-05-06 00:44:46,772 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:46,772 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:50,564 - INFO - Processing batch 12/183: chunks 88 to 95
2025-05-06 00:44:50,567 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:50,567 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:53,733 - INFO - Processing batch 13/183: chunks 96 to 103
2025-05-06 00:44:53,735 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:53,735 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:44:57,853 - INFO - Processing batch 14/183: chunks 104 to 111
2025-05-06 00:44:57,856 - INFO - Use pytorch device_name: cpu
2025-05-06 00:44:57,856 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:01,074 - INFO - Processing batch 15/183: chunks 112 to 119
2025-05-06 00:45:01,076 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:01,076 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:04,617 - INFO - Processing batch 16/183: chunks 120 to 127
2025-05-06 00:45:04,620 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:04,620 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:07,519 - INFO - Processing batch 17/183: chunks 128 to 135
2025-05-06 00:45:07,522 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:07,522 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:10,438 - INFO - Processing batch 18/183: chunks 136 to 143
2025-05-06 00:45:10,440 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:10,440 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:13,586 - INFO - Processing batch 19/183: chunks 144 to 151
2025-05-06 00:45:13,589 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:13,589 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:16,956 - INFO - Processing batch 20/183: chunks 152 to 159
2025-05-06 00:45:16,959 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:16,959 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:20,092 - INFO - Processing batch 21/183: chunks 160 to 167
2025-05-06 00:45:20,095 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:20,095 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:22,944 - INFO - Processing batch 22/183: chunks 168 to 175
2025-05-06 00:45:22,947 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:22,948 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:26,512 - INFO - Processing batch 23/183: chunks 176 to 183
2025-05-06 00:45:26,514 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:26,514 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:29,896 - INFO - Processing batch 24/183: chunks 184 to 191
2025-05-06 00:45:29,899 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:29,899 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:32,814 - INFO - Processing batch 25/183: chunks 192 to 199
2025-05-06 00:45:32,817 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:32,817 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:35,819 - INFO - Processing batch 26/183: chunks 200 to 207
2025-05-06 00:45:35,822 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:35,822 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:38,798 - INFO - Processing batch 27/183: chunks 208 to 215
2025-05-06 00:45:38,800 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:38,800 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:41,825 - INFO - Processing batch 28/183: chunks 216 to 223
2025-05-06 00:45:41,828 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:41,828 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:45,134 - INFO - Processing batch 29/183: chunks 224 to 231
2025-05-06 00:45:45,137 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:45,137 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:48,099 - INFO - Processing batch 30/183: chunks 232 to 239
2025-05-06 00:45:48,102 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:48,102 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:51,211 - INFO - Processing batch 31/183: chunks 240 to 247
2025-05-06 00:45:51,213 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:51,214 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:54,130 - INFO - Processing batch 32/183: chunks 248 to 255
2025-05-06 00:45:54,134 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:54,134 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:45:57,116 - INFO - Processing batch 33/183: chunks 256 to 263
2025-05-06 00:45:57,118 - INFO - Use pytorch device_name: cpu
2025-05-06 00:45:57,118 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:00,158 - INFO - Processing batch 34/183: chunks 264 to 271
2025-05-06 00:46:00,160 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:00,160 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:03,113 - INFO - Processing batch 35/183: chunks 272 to 279
2025-05-06 00:46:03,116 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:03,116 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:06,759 - INFO - Processing batch 36/183: chunks 280 to 287
2025-05-06 00:46:06,761 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:06,761 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:10,038 - INFO - Processing batch 37/183: chunks 288 to 295
2025-05-06 00:46:10,041 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:10,041 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:14,043 - INFO - Processing batch 38/183: chunks 296 to 303
2025-05-06 00:46:14,046 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:14,046 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:18,079 - INFO - Processing batch 39/183: chunks 304 to 311
2025-05-06 00:46:18,082 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:18,082 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:21,842 - INFO - Processing batch 40/183: chunks 312 to 319
2025-05-06 00:46:21,845 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:21,845 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:24,788 - INFO - Processing batch 41/183: chunks 320 to 327
2025-05-06 00:46:24,791 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:24,792 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:27,774 - INFO - Processing batch 42/183: chunks 328 to 335
2025-05-06 00:46:27,777 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:27,777 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:30,827 - INFO - Processing batch 43/183: chunks 336 to 343
2025-05-06 00:46:30,830 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:30,830 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:33,929 - INFO - Processing batch 44/183: chunks 344 to 351
2025-05-06 00:46:33,932 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:33,932 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:37,039 - INFO - Processing batch 45/183: chunks 352 to 359
2025-05-06 00:46:37,042 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:37,042 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:40,042 - INFO - Processing batch 46/183: chunks 360 to 367
2025-05-06 00:46:40,045 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:40,045 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:43,132 - INFO - Processing batch 47/183: chunks 368 to 375
2025-05-06 00:46:43,134 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:43,134 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:46,092 - INFO - Processing batch 48/183: chunks 376 to 383
2025-05-06 00:46:46,095 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:46,095 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:48,974 - INFO - Processing batch 49/183: chunks 384 to 391
2025-05-06 00:46:48,976 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:48,977 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:51,980 - INFO - Processing batch 50/183: chunks 392 to 399
2025-05-06 00:46:51,982 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:51,983 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:55,155 - INFO - Processing batch 51/183: chunks 400 to 407
2025-05-06 00:46:55,158 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:55,158 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:46:58,217 - INFO - Processing batch 52/183: chunks 408 to 415
2025-05-06 00:46:58,219 - INFO - Use pytorch device_name: cpu
2025-05-06 00:46:58,219 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:47:01,155 - INFO - Processing batch 53/183: chunks 416 to 423
2025-05-06 00:47:01,158 - INFO - Use pytorch device_name: cpu
2025-05-06 00:47:01,158 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:47:04,177 - INFO - Processing batch 54/183: chunks 424 to 431
2025-05-06 00:47:04,180 - INFO - Use pytorch device_name: cpu
2025-05-06 00:47:04,180 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:47:07,158 - INFO - Processing batch 55/183: chunks 432 to 439
2025-05-06 00:47:07,161 - INFO - Use pytorch device_name: cpu
2025-05-06 00:47:07,161 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:47:10,654 - INFO - Processing batch 56/183: chunks 440 to 447
2025-05-06 00:47:10,658 - INFO - Use pytorch device_name: cpu
2025-05-06 00:47:10,659 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:47:13,675 - INFO - Processing batch 57/183: chunks 448 to 455
2025-05-06 00:47:13,678 - INFO - Use pytorch device_name: cpu
2025-05-06 00:47:13,678 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:49:12,677 - INFO - Use pytorch device_name: cpu
2025-05-06 00:49:12,677 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:49:17,763 - INFO - Use pytorch device_name: cpu
2025-05-06 00:49:17,763 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:49:20,339 - INFO - Use pytorch device_name: cpu
2025-05-06 00:49:20,339 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:49:23,224 - INFO - Stores directory is empty or doesn't exist. Building code stores...
2025-05-06 00:49:23,230 - INFO - Use pytorch device_name: cpu
2025-05-06 00:49:23,230 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:49:25,659 - INFO - Loading code-specific vector stores from stores...
2025-05-06 00:49:25,660 - INFO - Loading pre-built indexes...
2025-05-06 00:49:29,042 - INFO - Loaded 1460 legal document chunks
2025-05-06 00:49:29,042 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-06 00:49:29,042 - INFO - Loaded 0 code-specific vector stores: None
2025-05-06 00:49:29,056 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-06 00:49:29,056 - INFO - [33mPress CTRL+C to quit[0m
2025-05-06 00:50:08,639 - INFO - 127.0.0.1 - - [06/May/2025 00:50:08] "GET / HTTP/1.1" 200 -
2025-05-06 00:50:08,660 - INFO - 127.0.0.1 - - [06/May/2025 00:50:08] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 00:50:08,677 - INFO - 127.0.0.1 - - [06/May/2025 00:50:08] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 00:50:10,994 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-06 00:50:11,347 - INFO - Token usage: prompt=54, completion=11, total=65
2025-05-06 00:50:11,383 - INFO - Processing query: 'comment lancer une startup?' for conversation 47
2025-05-06 00:50:11,385 - INFO - Query received: comment lancer une startup?
2025-05-06 00:50:11,438 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-06 00:50:11,443 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-06 00:50:11,443 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-06 00:50:14,382 - INFO - Token usage: prompt=1200, completion=376, total=1576
2025-05-06 00:50:14,390 - INFO - Agent workflow completed in 3.40s
2025-05-06 00:50:14,416 - INFO - Request processed in 3.42s (thinking: 2.95s)
2025-05-06 00:50:14,417 - INFO - 127.0.0.1 - - [06/May/2025 00:50:14] "POST /ask HTTP/1.1" 200 -
2025-05-06 00:50:21,177 - INFO - 127.0.0.1 - - [06/May/2025 00:50:21] "GET / HTTP/1.1" 200 -
2025-05-06 00:50:21,200 - INFO - 127.0.0.1 - - [06/May/2025 00:50:21] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 00:50:21,217 - INFO - 127.0.0.1 - - [06/May/2025 00:50:21] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 00:50:22,007 - INFO - 127.0.0.1 - - [06/May/2025 00:50:22] "GET / HTTP/1.1" 200 -
2025-05-06 00:50:22,025 - INFO - 127.0.0.1 - - [06/May/2025 00:50:22] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 00:50:22,038 - INFO - 127.0.0.1 - - [06/May/2025 00:50:22] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 00:50:22,187 - INFO - 127.0.0.1 - - [06/May/2025 00:50:22] "GET / HTTP/1.1" 200 -
2025-05-06 00:50:22,238 - INFO - 127.0.0.1 - - [06/May/2025 00:50:22] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 00:50:22,248 - INFO - 127.0.0.1 - - [06/May/2025 00:50:22] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 00:50:22,401 - INFO - 127.0.0.1 - - [06/May/2025 00:50:22] "GET / HTTP/1.1" 200 -
2025-05-06 00:50:22,418 - INFO - 127.0.0.1 - - [06/May/2025 00:50:22] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 00:50:22,430 - INFO - 127.0.0.1 - - [06/May/2025 00:50:22] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 00:50:23,483 - INFO - 127.0.0.1 - - [06/May/2025 00:50:23] "GET /get_conversation/46 HTTP/1.1" 200 -
2025-05-06 00:50:24,612 - INFO - 127.0.0.1 - - [06/May/2025 00:50:24] "GET /get_conversation/47 HTTP/1.1" 200 -
2025-05-06 00:50:26,029 - INFO - 127.0.0.1 - - [06/May/2025 00:50:26] "GET /get_conversation/46 HTTP/1.1" 200 -
2025-05-06 00:50:28,790 - INFO - 127.0.0.1 - - [06/May/2025 00:50:28] "GET /get_conversation/47 HTTP/1.1" 200 -
2025-05-06 00:50:31,137 - INFO - 127.0.0.1 - - [06/May/2025 00:50:31] "DELETE /delete_conversation/47 HTTP/1.1" 200 -
2025-05-06 00:50:33,459 - INFO - 127.0.0.1 - - [06/May/2025 00:50:33] "DELETE /delete_conversation/46 HTTP/1.1" 200 -
2025-05-06 00:50:34,953 - INFO - 127.0.0.1 - - [06/May/2025 00:50:34] "GET /get_conversation/45 HTTP/1.1" 200 -
2025-05-06 00:51:39,901 - INFO - Use pytorch device_name: cpu
2025-05-06 00:51:39,901 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:51:44,883 - INFO - Use pytorch device_name: cpu
2025-05-06 00:51:44,883 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:51:47,391 - INFO - Use pytorch device_name: cpu
2025-05-06 00:51:47,391 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:51:50,253 - INFO - Stores directory is empty or doesn't exist. Building code stores...
2025-05-06 00:51:50,259 - INFO - Use pytorch device_name: cpu
2025-05-06 00:51:50,259 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 00:51:53,084 - INFO - Loading code-specific vector stores from stores...
2025-05-06 00:51:53,085 - INFO - Loading pre-built indexes...
2025-05-06 00:51:56,526 - INFO - Loaded 1460 legal document chunks
2025-05-06 00:51:56,526 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-06 00:51:56,526 - INFO - Loaded 0 code-specific vector stores: None
2025-05-06 00:51:56,544 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-06 00:51:56,544 - INFO - [33mPress CTRL+C to quit[0m
2025-05-06 00:53:08,334 - INFO - 127.0.0.1 - - [06/May/2025 00:53:08] "GET / HTTP/1.1" 200 -
2025-05-06 00:53:08,352 - INFO - 127.0.0.1 - - [06/May/2025 00:53:08] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 00:53:08,364 - INFO - 127.0.0.1 - - [06/May/2025 00:53:08] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 00:53:12,758 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-06 00:53:13,092 - INFO - Token usage: prompt=54, completion=12, total=66
2025-05-06 00:53:13,129 - INFO - Processing query: 'comment lancer une startup?' for conversation 48
2025-05-06 00:53:13,131 - INFO - Query received: comment lancer une startup?
2025-05-06 00:53:13,183 - INFO - Search scores:
Document 467 (chunk: chunk_441): score=0.5000, confidence=100.00%
Document 1324 (chunk: chunk_1267): score=0.4020, confidence=80.41%
Document 1354 (chunk: chunk_1297): score=0.3060, confidence=61.21%
Document 996 (chunk: chunk_949): score=0.3020, confidence=60.39%
Document 1139 (chunk: chunk_1088): score=0.3007, confidence=60.14%
2025-05-06 00:53:13,188 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-06 00:53:13,188 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-06 00:53:18,120 - INFO - Token usage: prompt=1200, completion=1226, total=2426
2025-05-06 00:53:18,126 - INFO - Agent workflow completed in 5.37s
2025-05-06 00:53:18,232 - INFO - Request processed in 5.47s (thinking: 4.94s)
2025-05-06 00:53:18,233 - INFO - 127.0.0.1 - - [06/May/2025 00:53:18] "POST /ask HTTP/1.1" 200 -
2025-05-06 11:55:55,764 - INFO - Use pytorch device_name: cpu
2025-05-06 11:55:55,764 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 11:56:51,906 - INFO - Use pytorch device_name: cpu
2025-05-06 11:56:51,906 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 11:56:57,180 - INFO - Use pytorch device_name: cpu
2025-05-06 11:56:57,181 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 11:57:04,170 - INFO - Stores directory is empty or doesn't exist. Building code stores...
2025-05-06 11:57:04,182 - INFO - Use pytorch device_name: cpu
2025-05-06 11:57:04,182 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 11:57:09,124 - INFO - Loading code-specific vector stores from stores...
2025-05-06 11:57:09,126 - INFO - Loading pre-built indexes...
2025-05-06 11:57:15,363 - INFO - Loaded 1460 legal document chunks
2025-05-06 11:57:15,363 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-06 11:57:15,363 - INFO - Loaded 0 code-specific vector stores: None
2025-05-06 11:57:15,390 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.213.235:5000
2025-05-06 11:57:15,390 - INFO - [33mPress CTRL+C to quit[0m
2025-05-06 11:57:40,184 - INFO - 127.0.0.1 - - [06/May/2025 11:57:40] "GET / HTTP/1.1" 200 -
2025-05-06 11:57:40,253 - INFO - 127.0.0.1 - - [06/May/2025 11:57:40] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-06 11:57:40,320 - INFO - 127.0.0.1 - - [06/May/2025 11:57:40] "GET /get_conversations HTTP/1.1" 200 -
2025-05-06 11:57:40,614 - INFO - 127.0.0.1 - - [06/May/2025 11:57:40] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-05-06 11:58:05,999 - INFO - Use pytorch device_name: cpu
2025-05-06 11:58:05,999 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 11:58:17,450 - INFO - Use pytorch device_name: cpu
2025-05-06 11:58:17,451 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 11:59:05,709 - INFO - Use pytorch device_name: cpu
2025-05-06 11:59:05,709 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 11:59:10,776 - INFO - Loading code-specific vector stores from stores...
2025-05-06 11:59:10,776 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 11:59:10,830 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-06 11:59:10,830 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 11:59:10,879 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-06 11:59:10,880 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 11:59:10,932 - INFO - Loaded vector store for loi_relative_Startups
2025-05-06 11:59:10,933 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 11:59:10,983 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-06 11:59:10,984 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 11:59:11,017 - INFO - Loaded vector store for loi_societes_ligne
2025-05-06 11:59:11,017 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 11:59:11,079 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-06 11:59:11,080 - INFO - Loading pre-built indexes...
2025-05-06 11:59:18,608 - INFO - Loaded 1460 legal document chunks
2025-05-06 11:59:18,608 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-06 11:59:18,608 - INFO - Loaded 6 code-specific vector stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-06 11:59:18,655 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.213.235:5000
2025-05-06 11:59:18,655 - INFO - [33mPress CTRL+C to quit[0m
2025-05-06 11:59:29,532 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-06 11:59:31,267 - INFO - Token usage: prompt=56, completion=10, total=66
2025-05-06 11:59:31,316 - INFO - Processing query: 'how can i open a startup' for conversation 49
2025-05-06 11:59:31,326 - INFO - Query received: how can i open a startup
2025-05-06 11:59:33,986 - INFO - Routing query to code: loi_relative_Startups (similarity: 0.5710)
2025-05-06 11:59:34,119 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-06 11:59:34,120 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-06 11:59:44,740 - INFO - Token usage: prompt=1589, completion=933, total=2522
2025-05-06 11:59:44,743 - INFO - Agent workflow completed in 15.21s
2025-05-06 11:59:44,839 - INFO - Request processed in 15.31s (thinking: 10.64s)
2025-05-06 11:59:44,840 - INFO - 127.0.0.1 - - [06/May/2025 11:59:44] "POST /ask HTTP/1.1" 200 -
2025-05-06 12:16:07,533 - INFO - 127.0.0.1 - - [06/May/2025 12:16:07] "GET /get_conversation/45 HTTP/1.1" 200 -
2025-05-06 12:16:08,664 - INFO - 127.0.0.1 - - [06/May/2025 12:16:08] "GET /get_conversation/42 HTTP/1.1" 200 -
2025-05-06 12:16:41,097 - INFO - 127.0.0.1 - - [06/May/2025 12:16:41] "GET /get_conversation/48 HTTP/1.1" 200 -
2025-05-06 12:16:49,577 - INFO - 127.0.0.1 - - [06/May/2025 12:16:49] "GET /get_conversation/45 HTTP/1.1" 200 -
2025-05-06 12:16:54,073 - INFO - 127.0.0.1 - - [06/May/2025 12:16:54] "GET /get_conversation/48 HTTP/1.1" 200 -
2025-05-06 12:16:58,817 - INFO - 127.0.0.1 - - [06/May/2025 12:16:58] "GET /get_conversation/45 HTTP/1.1" 200 -
2025-05-06 12:17:03,590 - INFO - 127.0.0.1 - - [06/May/2025 12:17:03] "GET /get_conversation/44 HTTP/1.1" 200 -
2025-05-06 12:17:04,891 - INFO - 127.0.0.1 - - [06/May/2025 12:17:04] "GET /get_conversation/42 HTTP/1.1" 200 -
2025-05-06 12:17:09,209 - INFO - 127.0.0.1 - - [06/May/2025 12:17:09] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-06 12:17:21,290 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-06 12:17:23,233 - INFO - Token usage: prompt=54, completion=13, total=67
2025-05-06 12:17:23,278 - INFO - Processing query: 'comment lancer une startup?' for conversation 50
2025-05-06 12:17:23,282 - INFO - Query received: comment lancer une startup?
2025-05-06 12:17:24,592 - INFO - Routing query to code: loi_relative_Startups (similarity: 0.5040)
2025-05-06 12:17:24,702 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-06 12:17:24,703 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-06 12:17:29,868 - INFO - Token usage: prompt=1775, completion=936, total=2711
2025-05-06 12:17:29,883 - INFO - Agent workflow completed in 8.59s
2025-05-06 12:17:30,055 - INFO - Request processed in 8.77s (thinking: 5.20s)
2025-05-06 12:17:30,058 - INFO - 127.0.0.1 - - [06/May/2025 12:17:30] "POST /ask HTTP/1.1" 200 -
2025-05-06 14:56:50,607 - INFO - Use pytorch device_name: cpu
2025-05-06 14:56:50,611 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 14:57:08,454 - INFO - Use pytorch device_name: cpu
2025-05-06 14:57:08,455 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 14:57:49,713 - ERROR - Failed to initialize data: Data file data.txt not found.
2025-05-06 14:57:49,714 - ERROR - Traceback (most recent call last):
  File "c:\Users\chtar\Desktop\bouba\app.py", line 660, in initialize_data
    raise FileNotFoundError(f"Data file {config['data_file']} not found.")
FileNotFoundError: Data file data.txt not found.

2025-05-06 14:59:10,617 - INFO - Use pytorch device_name: cpu
2025-05-06 14:59:10,617 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 14:59:25,866 - INFO - Use pytorch device_name: cpu
2025-05-06 14:59:25,867 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:00:46,911 - INFO - Use pytorch device_name: cpu
2025-05-06 15:00:46,911 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:00:56,046 - INFO - Loading code-specific vector stores from stores...
2025-05-06 15:00:56,047 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 15:00:56,105 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-06 15:00:56,106 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 15:00:56,159 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-06 15:00:56,161 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 15:00:56,211 - INFO - Loaded vector store for loi_relative_Startups
2025-05-06 15:00:56,213 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 15:00:56,274 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-06 15:00:56,275 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 15:00:56,319 - INFO - Loaded vector store for loi_societes_ligne
2025-05-06 15:00:56,320 - INFO - Using langchain_community.vectorstores FAISS
2025-05-06 15:00:56,389 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-06 15:00:56,391 - INFO - Rebuilding indexes due to updated data...
2025-05-06 15:01:16,231 - INFO - Parsed 1460 legal document chunks
2025-05-06 15:01:16,233 - INFO - Processing batch 1/183: chunks 0 to 7
2025-05-06 15:01:16,240 - INFO - Use pytorch device_name: cpu
2025-05-06 15:01:16,240 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:01:25,794 - INFO - Processing batch 2/183: chunks 8 to 15
2025-05-06 15:01:25,807 - INFO - Use pytorch device_name: cpu
2025-05-06 15:01:25,807 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:01:36,465 - INFO - Processing batch 3/183: chunks 16 to 23
2025-05-06 15:01:36,476 - INFO - Use pytorch device_name: cpu
2025-05-06 15:01:36,476 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:01:46,917 - INFO - Processing batch 4/183: chunks 24 to 31
2025-05-06 15:01:46,927 - INFO - Use pytorch device_name: cpu
2025-05-06 15:01:46,927 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:01:57,535 - INFO - Processing batch 5/183: chunks 32 to 39
2025-05-06 15:01:57,548 - INFO - Use pytorch device_name: cpu
2025-05-06 15:01:57,548 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:02:07,869 - INFO - Processing batch 6/183: chunks 40 to 47
2025-05-06 15:02:07,880 - INFO - Use pytorch device_name: cpu
2025-05-06 15:02:07,880 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:02:19,904 - INFO - Processing batch 7/183: chunks 48 to 55
2025-05-06 15:02:19,908 - INFO - Use pytorch device_name: cpu
2025-05-06 15:02:19,908 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:02:31,697 - INFO - Processing batch 8/183: chunks 56 to 63
2025-05-06 15:02:31,707 - INFO - Use pytorch device_name: cpu
2025-05-06 15:02:31,707 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:02:47,419 - INFO - Processing batch 9/183: chunks 64 to 71
2025-05-06 15:02:47,430 - INFO - Use pytorch device_name: cpu
2025-05-06 15:02:47,430 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:02:59,946 - INFO - Processing batch 10/183: chunks 72 to 79
2025-05-06 15:02:59,957 - INFO - Use pytorch device_name: cpu
2025-05-06 15:02:59,957 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:03:06,766 - INFO - Processing batch 11/183: chunks 80 to 87
2025-05-06 15:03:06,771 - INFO - Use pytorch device_name: cpu
2025-05-06 15:03:06,771 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:03:14,370 - INFO - Processing batch 12/183: chunks 88 to 95
2025-05-06 15:03:14,373 - INFO - Use pytorch device_name: cpu
2025-05-06 15:03:14,373 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:03:21,619 - INFO - Processing batch 13/183: chunks 96 to 103
2025-05-06 15:03:21,623 - INFO - Use pytorch device_name: cpu
2025-05-06 15:03:21,623 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:03:28,293 - INFO - Processing batch 14/183: chunks 104 to 111
2025-05-06 15:03:28,297 - INFO - Use pytorch device_name: cpu
2025-05-06 15:03:28,297 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:03:34,624 - INFO - Processing batch 15/183: chunks 112 to 119
2025-05-06 15:03:34,626 - INFO - Use pytorch device_name: cpu
2025-05-06 15:03:34,627 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:03:40,707 - INFO - Processing batch 16/183: chunks 120 to 127
2025-05-06 15:03:40,714 - INFO - Use pytorch device_name: cpu
2025-05-06 15:03:40,714 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:03:47,167 - INFO - Processing batch 17/183: chunks 128 to 135
2025-05-06 15:03:47,178 - INFO - Use pytorch device_name: cpu
2025-05-06 15:03:47,178 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:03:56,687 - INFO - Processing batch 18/183: chunks 136 to 143
2025-05-06 15:03:56,698 - INFO - Use pytorch device_name: cpu
2025-05-06 15:03:56,699 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:04:06,562 - INFO - Processing batch 19/183: chunks 144 to 151
2025-05-06 15:04:06,571 - INFO - Use pytorch device_name: cpu
2025-05-06 15:04:06,571 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:04:17,177 - INFO - Processing batch 20/183: chunks 152 to 159
2025-05-06 15:04:17,189 - INFO - Use pytorch device_name: cpu
2025-05-06 15:04:17,190 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:04:27,285 - INFO - Processing batch 21/183: chunks 160 to 167
2025-05-06 15:04:27,294 - INFO - Use pytorch device_name: cpu
2025-05-06 15:04:27,295 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:04:36,614 - INFO - Processing batch 22/183: chunks 168 to 175
2025-05-06 15:04:36,625 - INFO - Use pytorch device_name: cpu
2025-05-06 15:04:36,625 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:04:47,660 - INFO - Processing batch 23/183: chunks 176 to 183
2025-05-06 15:04:47,668 - INFO - Use pytorch device_name: cpu
2025-05-06 15:04:47,669 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:04:56,829 - INFO - Processing batch 24/183: chunks 184 to 191
2025-05-06 15:04:56,839 - INFO - Use pytorch device_name: cpu
2025-05-06 15:04:56,839 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:05:06,948 - INFO - Processing batch 25/183: chunks 192 to 199
2025-05-06 15:05:06,959 - INFO - Use pytorch device_name: cpu
2025-05-06 15:05:06,959 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:05:13,709 - INFO - Processing batch 26/183: chunks 200 to 207
2025-05-06 15:05:13,713 - INFO - Use pytorch device_name: cpu
2025-05-06 15:05:13,713 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:05:20,895 - INFO - Processing batch 27/183: chunks 208 to 215
2025-05-06 15:05:20,898 - INFO - Use pytorch device_name: cpu
2025-05-06 15:05:20,898 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:05:27,286 - INFO - Processing batch 28/183: chunks 216 to 223
2025-05-06 15:05:27,290 - INFO - Use pytorch device_name: cpu
2025-05-06 15:05:27,290 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:05:33,136 - INFO - Processing batch 29/183: chunks 224 to 231
2025-05-06 15:05:33,140 - INFO - Use pytorch device_name: cpu
2025-05-06 15:05:33,141 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:05:42,403 - INFO - Processing batch 30/183: chunks 232 to 239
2025-05-06 15:05:42,414 - INFO - Use pytorch device_name: cpu
2025-05-06 15:05:42,414 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:05:53,110 - INFO - Processing batch 31/183: chunks 240 to 247
2025-05-06 15:05:53,122 - INFO - Use pytorch device_name: cpu
2025-05-06 15:05:53,122 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:06:01,829 - INFO - Processing batch 32/183: chunks 248 to 255
2025-05-06 15:06:01,839 - INFO - Use pytorch device_name: cpu
2025-05-06 15:06:01,839 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:06:10,810 - INFO - Processing batch 33/183: chunks 256 to 263
2025-05-06 15:06:10,814 - INFO - Use pytorch device_name: cpu
2025-05-06 15:06:10,814 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:06:18,025 - INFO - Processing batch 34/183: chunks 264 to 271
2025-05-06 15:06:18,028 - INFO - Use pytorch device_name: cpu
2025-05-06 15:06:18,028 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:06:25,348 - INFO - Processing batch 35/183: chunks 272 to 279
2025-05-06 15:06:25,351 - INFO - Use pytorch device_name: cpu
2025-05-06 15:06:25,351 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:06:31,926 - INFO - Processing batch 36/183: chunks 280 to 287
2025-05-06 15:06:31,930 - INFO - Use pytorch device_name: cpu
2025-05-06 15:06:31,930 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:06:37,726 - INFO - Processing batch 37/183: chunks 288 to 295
2025-05-06 15:06:37,729 - INFO - Use pytorch device_name: cpu
2025-05-06 15:06:37,729 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:06:44,048 - INFO - Processing batch 38/183: chunks 296 to 303
2025-05-06 15:06:44,052 - INFO - Use pytorch device_name: cpu
2025-05-06 15:06:44,052 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:06:54,013 - INFO - Processing batch 39/183: chunks 304 to 311
2025-05-06 15:06:54,017 - INFO - Use pytorch device_name: cpu
2025-05-06 15:06:54,018 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:07:00,395 - INFO - Processing batch 40/183: chunks 312 to 319
2025-05-06 15:07:00,399 - INFO - Use pytorch device_name: cpu
2025-05-06 15:07:00,399 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:07:07,929 - INFO - Processing batch 41/183: chunks 320 to 327
2025-05-06 15:07:07,932 - INFO - Use pytorch device_name: cpu
2025-05-06 15:07:07,932 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:07:16,158 - INFO - Processing batch 42/183: chunks 328 to 335
2025-05-06 15:07:16,162 - INFO - Use pytorch device_name: cpu
2025-05-06 15:07:16,162 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:07:21,530 - INFO - Processing batch 43/183: chunks 336 to 343
2025-05-06 15:07:21,533 - INFO - Use pytorch device_name: cpu
2025-05-06 15:07:21,533 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:07:29,356 - INFO - Processing batch 44/183: chunks 344 to 351
2025-05-06 15:07:29,360 - INFO - Use pytorch device_name: cpu
2025-05-06 15:07:29,360 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:07:36,168 - INFO - Processing batch 45/183: chunks 352 to 359
2025-05-06 15:07:36,172 - INFO - Use pytorch device_name: cpu
2025-05-06 15:07:36,172 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:07:43,106 - INFO - Processing batch 46/183: chunks 360 to 367
2025-05-06 15:07:43,111 - INFO - Use pytorch device_name: cpu
2025-05-06 15:07:43,111 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:07:49,357 - INFO - Processing batch 47/183: chunks 368 to 375
2025-05-06 15:07:49,360 - INFO - Use pytorch device_name: cpu
2025-05-06 15:07:49,360 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:07:56,806 - INFO - Processing batch 48/183: chunks 376 to 383
2025-05-06 15:07:56,810 - INFO - Use pytorch device_name: cpu
2025-05-06 15:07:56,810 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:08:02,417 - INFO - Processing batch 49/183: chunks 384 to 391
2025-05-06 15:08:02,420 - INFO - Use pytorch device_name: cpu
2025-05-06 15:08:02,420 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:08:08,884 - INFO - Processing batch 50/183: chunks 392 to 399
2025-05-06 15:08:08,888 - INFO - Use pytorch device_name: cpu
2025-05-06 15:08:08,888 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:08:16,530 - INFO - Processing batch 51/183: chunks 400 to 407
2025-05-06 15:08:16,535 - INFO - Use pytorch device_name: cpu
2025-05-06 15:08:16,535 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:08:24,507 - INFO - Processing batch 52/183: chunks 408 to 415
2025-05-06 15:08:24,510 - INFO - Use pytorch device_name: cpu
2025-05-06 15:08:24,510 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:08:32,214 - INFO - Processing batch 53/183: chunks 416 to 423
2025-05-06 15:08:32,217 - INFO - Use pytorch device_name: cpu
2025-05-06 15:08:32,218 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:08:38,950 - INFO - Processing batch 54/183: chunks 424 to 431
2025-05-06 15:08:38,955 - INFO - Use pytorch device_name: cpu
2025-05-06 15:08:38,955 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:08:44,787 - INFO - Processing batch 55/183: chunks 432 to 439
2025-05-06 15:08:44,791 - INFO - Use pytorch device_name: cpu
2025-05-06 15:08:44,791 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:08:49,465 - INFO - Processing batch 56/183: chunks 440 to 447
2025-05-06 15:08:49,469 - INFO - Use pytorch device_name: cpu
2025-05-06 15:08:49,469 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:08:55,709 - INFO - Processing batch 57/183: chunks 448 to 455
2025-05-06 15:08:55,713 - INFO - Use pytorch device_name: cpu
2025-05-06 15:08:55,713 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:09:04,825 - INFO - Processing batch 58/183: chunks 456 to 463
2025-05-06 15:09:04,850 - INFO - Use pytorch device_name: cpu
2025-05-06 15:09:04,851 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:09:12,134 - INFO - Processing batch 59/183: chunks 464 to 471
2025-05-06 15:09:12,137 - INFO - Use pytorch device_name: cpu
2025-05-06 15:09:12,137 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:09:18,610 - INFO - Processing batch 60/183: chunks 472 to 479
2025-05-06 15:09:18,615 - INFO - Use pytorch device_name: cpu
2025-05-06 15:09:18,615 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:09:25,741 - INFO - Processing batch 61/183: chunks 480 to 487
2025-05-06 15:09:25,746 - INFO - Use pytorch device_name: cpu
2025-05-06 15:09:25,747 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:09:33,169 - INFO - Processing batch 62/183: chunks 488 to 495
2025-05-06 15:09:33,173 - INFO - Use pytorch device_name: cpu
2025-05-06 15:09:33,173 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:09:40,019 - INFO - Processing batch 63/183: chunks 496 to 503
2025-05-06 15:09:40,023 - INFO - Use pytorch device_name: cpu
2025-05-06 15:09:40,023 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:09:46,745 - INFO - Processing batch 64/183: chunks 504 to 511
2025-05-06 15:09:46,749 - INFO - Use pytorch device_name: cpu
2025-05-06 15:09:46,749 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:09:54,493 - INFO - Processing batch 65/183: chunks 512 to 519
2025-05-06 15:09:54,498 - INFO - Use pytorch device_name: cpu
2025-05-06 15:09:54,498 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:10:12,042 - INFO - Processing batch 66/183: chunks 520 to 527
2025-05-06 15:10:12,054 - INFO - Use pytorch device_name: cpu
2025-05-06 15:10:12,054 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:10:20,489 - INFO - Processing batch 67/183: chunks 528 to 535
2025-05-06 15:10:20,501 - INFO - Use pytorch device_name: cpu
2025-05-06 15:10:20,502 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:10:29,568 - INFO - Processing batch 68/183: chunks 536 to 543
2025-05-06 15:10:29,581 - INFO - Use pytorch device_name: cpu
2025-05-06 15:10:29,581 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:10:36,684 - INFO - Processing batch 69/183: chunks 544 to 551
2025-05-06 15:10:36,689 - INFO - Use pytorch device_name: cpu
2025-05-06 15:10:36,689 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:10:42,207 - INFO - Processing batch 70/183: chunks 552 to 559
2025-05-06 15:10:42,210 - INFO - Use pytorch device_name: cpu
2025-05-06 15:10:42,210 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:10:47,531 - INFO - Processing batch 71/183: chunks 560 to 567
2025-05-06 15:10:47,534 - INFO - Use pytorch device_name: cpu
2025-05-06 15:10:47,534 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:10:56,308 - INFO - Processing batch 72/183: chunks 568 to 575
2025-05-06 15:10:56,318 - INFO - Use pytorch device_name: cpu
2025-05-06 15:10:56,318 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:11:03,860 - INFO - Processing batch 73/183: chunks 576 to 583
2025-05-06 15:11:03,871 - INFO - Use pytorch device_name: cpu
2025-05-06 15:11:03,872 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:11:11,750 - INFO - Processing batch 74/183: chunks 584 to 591
2025-05-06 15:11:11,760 - INFO - Use pytorch device_name: cpu
2025-05-06 15:11:11,760 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:11:21,728 - INFO - Processing batch 75/183: chunks 592 to 599
2025-05-06 15:11:21,737 - INFO - Use pytorch device_name: cpu
2025-05-06 15:11:21,737 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:11:31,728 - INFO - Processing batch 76/183: chunks 600 to 607
2025-05-06 15:11:31,737 - INFO - Use pytorch device_name: cpu
2025-05-06 15:11:31,738 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:11:41,045 - INFO - Processing batch 77/183: chunks 608 to 615
2025-05-06 15:11:41,055 - INFO - Use pytorch device_name: cpu
2025-05-06 15:11:41,055 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:11:49,690 - INFO - Processing batch 78/183: chunks 616 to 623
2025-05-06 15:11:49,700 - INFO - Use pytorch device_name: cpu
2025-05-06 15:11:49,700 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:12:00,351 - INFO - Processing batch 79/183: chunks 624 to 631
2025-05-06 15:12:00,360 - INFO - Use pytorch device_name: cpu
2025-05-06 15:12:00,360 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:12:09,796 - INFO - Processing batch 80/183: chunks 632 to 639
2025-05-06 15:12:09,800 - INFO - Use pytorch device_name: cpu
2025-05-06 15:12:09,800 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:12:19,506 - INFO - Processing batch 81/183: chunks 640 to 647
2025-05-06 15:12:19,513 - INFO - Use pytorch device_name: cpu
2025-05-06 15:12:19,513 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:12:29,446 - INFO - Processing batch 82/183: chunks 648 to 655
2025-05-06 15:12:29,454 - INFO - Use pytorch device_name: cpu
2025-05-06 15:12:29,454 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:12:38,328 - INFO - Processing batch 83/183: chunks 656 to 663
2025-05-06 15:12:38,339 - INFO - Use pytorch device_name: cpu
2025-05-06 15:12:38,340 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-06 15:12:48,477 - INFO - Processing batch 84/183: chunks 664 to 671
2025-05-06 15:12:48,489 - INFO - Use pytorch device_name: cpu
2025-05-06 15:12:48,489 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:00:22,879 - INFO - Use pytorch device_name: cpu
2025-05-08 21:00:22,879 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:00:29,563 - INFO - Use pytorch device_name: cpu
2025-05-08 21:00:29,564 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:12,558 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:12,558 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:15,375 - INFO - Loading code-specific vector stores from stores...
2025-05-08 21:01:15,376 - INFO - Using langchain_community.vectorstores FAISS
2025-05-08 21:01:15,397 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-08 21:01:15,397 - INFO - Using langchain_community.vectorstores FAISS
2025-05-08 21:01:15,412 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-08 21:01:15,412 - INFO - Using langchain_community.vectorstores FAISS
2025-05-08 21:01:15,428 - INFO - Loaded vector store for loi_relative_Startups
2025-05-08 21:01:15,428 - INFO - Using langchain_community.vectorstores FAISS
2025-05-08 21:01:15,442 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-08 21:01:15,443 - INFO - Using langchain_community.vectorstores FAISS
2025-05-08 21:01:15,456 - INFO - Loaded vector store for loi_societes_ligne
2025-05-08 21:01:15,457 - INFO - Using langchain_community.vectorstores FAISS
2025-05-08 21:01:15,477 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-08 21:01:15,477 - INFO - Rebuilding indexes due to updated data...
2025-05-08 21:01:19,573 - INFO - Parsed 1460 legal document chunks
2025-05-08 21:01:19,573 - INFO - Processing batch 1/183: chunks 0 to 7
2025-05-08 21:01:19,576 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:19,576 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:22,490 - INFO - Processing batch 2/183: chunks 8 to 15
2025-05-08 21:01:22,492 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:22,492 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:25,660 - INFO - Processing batch 3/183: chunks 16 to 23
2025-05-08 21:01:25,664 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:25,664 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:28,882 - INFO - Processing batch 4/183: chunks 24 to 31
2025-05-08 21:01:28,885 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:28,886 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:31,733 - INFO - Processing batch 5/183: chunks 32 to 39
2025-05-08 21:01:31,736 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:31,736 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:35,291 - INFO - Processing batch 6/183: chunks 40 to 47
2025-05-08 21:01:35,294 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:35,294 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:38,226 - INFO - Processing batch 7/183: chunks 48 to 55
2025-05-08 21:01:38,229 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:38,229 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:41,239 - INFO - Processing batch 8/183: chunks 56 to 63
2025-05-08 21:01:41,242 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:41,242 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:44,229 - INFO - Processing batch 9/183: chunks 64 to 71
2025-05-08 21:01:44,231 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:44,231 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:47,192 - INFO - Processing batch 10/183: chunks 72 to 79
2025-05-08 21:01:47,195 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:47,195 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:50,178 - INFO - Processing batch 11/183: chunks 80 to 87
2025-05-08 21:01:50,181 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:50,181 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:53,291 - INFO - Processing batch 12/183: chunks 88 to 95
2025-05-08 21:01:53,295 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:53,296 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:56,181 - INFO - Processing batch 13/183: chunks 96 to 103
2025-05-08 21:01:56,183 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:56,184 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:01:59,158 - INFO - Processing batch 14/183: chunks 104 to 111
2025-05-08 21:01:59,161 - INFO - Use pytorch device_name: cpu
2025-05-08 21:01:59,161 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:02,143 - INFO - Processing batch 15/183: chunks 112 to 119
2025-05-08 21:02:02,146 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:02,146 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:05,081 - INFO - Processing batch 16/183: chunks 120 to 127
2025-05-08 21:02:05,084 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:05,084 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:07,935 - INFO - Processing batch 17/183: chunks 128 to 135
2025-05-08 21:02:07,938 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:07,938 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:10,957 - INFO - Processing batch 18/183: chunks 136 to 143
2025-05-08 21:02:10,960 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:10,960 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:13,847 - INFO - Processing batch 19/183: chunks 144 to 151
2025-05-08 21:02:13,849 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:13,849 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:16,678 - INFO - Processing batch 20/183: chunks 152 to 159
2025-05-08 21:02:16,681 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:16,681 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:19,724 - INFO - Processing batch 21/183: chunks 160 to 167
2025-05-08 21:02:19,728 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:19,728 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:22,606 - INFO - Processing batch 22/183: chunks 168 to 175
2025-05-08 21:02:22,610 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:22,610 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:25,677 - INFO - Processing batch 23/183: chunks 176 to 183
2025-05-08 21:02:25,680 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:25,680 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:28,670 - INFO - Processing batch 24/183: chunks 184 to 191
2025-05-08 21:02:28,672 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:28,672 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:31,635 - INFO - Processing batch 25/183: chunks 192 to 199
2025-05-08 21:02:31,638 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:31,638 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:35,106 - INFO - Processing batch 26/183: chunks 200 to 207
2025-05-08 21:02:35,110 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:35,110 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:38,628 - INFO - Processing batch 27/183: chunks 208 to 215
2025-05-08 21:02:38,632 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:38,632 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:41,726 - INFO - Processing batch 28/183: chunks 216 to 223
2025-05-08 21:02:41,730 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:41,730 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:46,839 - INFO - Processing batch 29/183: chunks 224 to 231
2025-05-08 21:02:46,845 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:46,845 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:50,884 - INFO - Processing batch 30/183: chunks 232 to 239
2025-05-08 21:02:50,888 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:50,888 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:55,161 - INFO - Processing batch 31/183: chunks 240 to 247
2025-05-08 21:02:55,164 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:55,164 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:02:59,250 - INFO - Processing batch 32/183: chunks 248 to 255
2025-05-08 21:02:59,254 - INFO - Use pytorch device_name: cpu
2025-05-08 21:02:59,254 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:03,397 - INFO - Processing batch 33/183: chunks 256 to 263
2025-05-08 21:03:03,400 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:03,400 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:07,422 - INFO - Processing batch 34/183: chunks 264 to 271
2025-05-08 21:03:07,425 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:07,425 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:11,186 - INFO - Processing batch 35/183: chunks 272 to 279
2025-05-08 21:03:11,189 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:11,190 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:15,010 - INFO - Processing batch 36/183: chunks 280 to 287
2025-05-08 21:03:15,014 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:15,014 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:18,899 - INFO - Processing batch 37/183: chunks 288 to 295
2025-05-08 21:03:18,906 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:18,906 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:22,857 - INFO - Processing batch 38/183: chunks 296 to 303
2025-05-08 21:03:22,861 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:22,861 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:26,894 - INFO - Processing batch 39/183: chunks 304 to 311
2025-05-08 21:03:26,898 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:26,898 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:31,015 - INFO - Processing batch 40/183: chunks 312 to 319
2025-05-08 21:03:31,018 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:31,018 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:35,436 - INFO - Processing batch 41/183: chunks 320 to 327
2025-05-08 21:03:35,441 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:35,441 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:39,756 - INFO - Processing batch 42/183: chunks 328 to 335
2025-05-08 21:03:39,762 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:39,762 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:43,752 - INFO - Processing batch 43/183: chunks 336 to 343
2025-05-08 21:03:43,755 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:43,755 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:47,943 - INFO - Processing batch 44/183: chunks 344 to 351
2025-05-08 21:03:47,952 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:47,953 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:52,051 - INFO - Processing batch 45/183: chunks 352 to 359
2025-05-08 21:03:52,057 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:52,057 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:03:56,162 - INFO - Processing batch 46/183: chunks 360 to 367
2025-05-08 21:03:56,165 - INFO - Use pytorch device_name: cpu
2025-05-08 21:03:56,166 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:00,383 - INFO - Processing batch 47/183: chunks 368 to 375
2025-05-08 21:04:00,388 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:00,388 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:04,840 - INFO - Processing batch 48/183: chunks 376 to 383
2025-05-08 21:04:04,843 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:04,843 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:09,428 - INFO - Processing batch 49/183: chunks 384 to 391
2025-05-08 21:04:09,431 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:09,431 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:12,340 - INFO - Processing batch 50/183: chunks 392 to 399
2025-05-08 21:04:12,343 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:12,343 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:15,644 - INFO - Processing batch 51/183: chunks 400 to 407
2025-05-08 21:04:15,651 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:15,651 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:19,419 - INFO - Processing batch 52/183: chunks 408 to 415
2025-05-08 21:04:19,424 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:19,424 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:22,753 - INFO - Processing batch 53/183: chunks 416 to 423
2025-05-08 21:04:22,761 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:22,762 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:26,633 - INFO - Processing batch 54/183: chunks 424 to 431
2025-05-08 21:04:26,640 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:26,640 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:31,065 - INFO - Processing batch 55/183: chunks 432 to 439
2025-05-08 21:04:31,069 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:31,069 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:34,329 - INFO - Processing batch 56/183: chunks 440 to 447
2025-05-08 21:04:34,332 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:34,332 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:37,161 - INFO - Processing batch 57/183: chunks 448 to 455
2025-05-08 21:04:37,163 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:37,163 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:40,236 - INFO - Processing batch 58/183: chunks 456 to 463
2025-05-08 21:04:40,239 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:40,239 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:43,139 - INFO - Processing batch 59/183: chunks 464 to 471
2025-05-08 21:04:43,142 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:43,142 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:46,177 - INFO - Processing batch 60/183: chunks 472 to 479
2025-05-08 21:04:46,179 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:46,179 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:49,367 - INFO - Processing batch 61/183: chunks 480 to 487
2025-05-08 21:04:49,370 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:49,371 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:52,266 - INFO - Processing batch 62/183: chunks 488 to 495
2025-05-08 21:04:52,269 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:52,269 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:55,340 - INFO - Processing batch 63/183: chunks 496 to 503
2025-05-08 21:04:55,344 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:55,344 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:04:58,693 - INFO - Processing batch 64/183: chunks 504 to 511
2025-05-08 21:04:58,696 - INFO - Use pytorch device_name: cpu
2025-05-08 21:04:58,697 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:02,487 - INFO - Processing batch 65/183: chunks 512 to 519
2025-05-08 21:05:02,491 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:02,491 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:06,768 - INFO - Processing batch 66/183: chunks 520 to 527
2025-05-08 21:05:06,774 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:06,774 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:10,820 - INFO - Processing batch 67/183: chunks 528 to 535
2025-05-08 21:05:10,825 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:10,825 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:15,214 - INFO - Processing batch 68/183: chunks 536 to 543
2025-05-08 21:05:15,220 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:15,220 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:18,905 - INFO - Processing batch 69/183: chunks 544 to 551
2025-05-08 21:05:18,910 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:18,910 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:23,192 - INFO - Processing batch 70/183: chunks 552 to 559
2025-05-08 21:05:23,197 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:23,197 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:26,125 - INFO - Processing batch 71/183: chunks 560 to 567
2025-05-08 21:05:26,127 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:26,127 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:29,175 - INFO - Processing batch 72/183: chunks 568 to 575
2025-05-08 21:05:29,177 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:29,177 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:31,895 - INFO - Processing batch 73/183: chunks 576 to 583
2025-05-08 21:05:31,898 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:31,898 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:34,819 - INFO - Processing batch 74/183: chunks 584 to 591
2025-05-08 21:05:34,822 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:34,822 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:37,951 - INFO - Processing batch 75/183: chunks 592 to 599
2025-05-08 21:05:37,954 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:37,954 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:41,155 - INFO - Processing batch 76/183: chunks 600 to 607
2025-05-08 21:05:41,158 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:41,159 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:44,176 - INFO - Processing batch 77/183: chunks 608 to 615
2025-05-08 21:05:44,180 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:44,180 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:47,533 - INFO - Processing batch 78/183: chunks 616 to 623
2025-05-08 21:05:47,537 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:47,537 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:51,391 - INFO - Processing batch 79/183: chunks 624 to 631
2025-05-08 21:05:51,395 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:51,395 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:55,424 - INFO - Processing batch 80/183: chunks 632 to 639
2025-05-08 21:05:55,429 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:55,429 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:05:59,621 - INFO - Processing batch 81/183: chunks 640 to 647
2025-05-08 21:05:59,626 - INFO - Use pytorch device_name: cpu
2025-05-08 21:05:59,626 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:03,699 - INFO - Processing batch 82/183: chunks 648 to 655
2025-05-08 21:06:03,703 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:03,704 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:07,900 - INFO - Processing batch 83/183: chunks 656 to 663
2025-05-08 21:06:07,904 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:07,904 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:11,996 - INFO - Processing batch 84/183: chunks 664 to 671
2025-05-08 21:06:12,000 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:12,000 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:15,286 - INFO - Processing batch 85/183: chunks 672 to 679
2025-05-08 21:06:15,289 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:15,289 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:18,357 - INFO - Processing batch 86/183: chunks 680 to 687
2025-05-08 21:06:18,359 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:18,359 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:21,612 - INFO - Processing batch 87/183: chunks 688 to 695
2025-05-08 21:06:21,614 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:21,615 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:25,606 - INFO - Processing batch 88/183: chunks 696 to 703
2025-05-08 21:06:25,611 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:25,611 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:30,414 - INFO - Processing batch 89/183: chunks 704 to 711
2025-05-08 21:06:30,417 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:30,418 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:34,523 - INFO - Processing batch 90/183: chunks 712 to 719
2025-05-08 21:06:34,527 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:34,527 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:38,286 - INFO - Processing batch 91/183: chunks 720 to 727
2025-05-08 21:06:38,290 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:38,291 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:41,994 - INFO - Processing batch 92/183: chunks 728 to 735
2025-05-08 21:06:41,998 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:41,998 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:45,673 - INFO - Processing batch 93/183: chunks 736 to 743
2025-05-08 21:06:45,678 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:45,679 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:49,808 - INFO - Processing batch 94/183: chunks 744 to 751
2025-05-08 21:06:49,814 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:49,814 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:53,563 - INFO - Processing batch 95/183: chunks 752 to 759
2025-05-08 21:06:53,566 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:53,566 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:06:57,527 - INFO - Processing batch 96/183: chunks 760 to 767
2025-05-08 21:06:57,530 - INFO - Use pytorch device_name: cpu
2025-05-08 21:06:57,530 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:01,413 - INFO - Processing batch 97/183: chunks 768 to 775
2025-05-08 21:07:01,416 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:01,416 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:05,332 - INFO - Processing batch 98/183: chunks 776 to 783
2025-05-08 21:07:05,335 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:05,335 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:09,381 - INFO - Processing batch 99/183: chunks 784 to 791
2025-05-08 21:07:09,385 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:09,385 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:13,675 - INFO - Processing batch 100/183: chunks 792 to 799
2025-05-08 21:07:13,682 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:13,683 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:17,800 - INFO - Processing batch 101/183: chunks 800 to 807
2025-05-08 21:07:17,807 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:17,807 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:21,428 - INFO - Processing batch 102/183: chunks 808 to 815
2025-05-08 21:07:21,432 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:21,432 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:25,011 - INFO - Processing batch 103/183: chunks 816 to 823
2025-05-08 21:07:25,017 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:25,017 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:28,991 - INFO - Processing batch 104/183: chunks 824 to 831
2025-05-08 21:07:28,997 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:28,997 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:33,066 - INFO - Processing batch 105/183: chunks 832 to 839
2025-05-08 21:07:33,069 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:33,069 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:36,828 - INFO - Processing batch 106/183: chunks 840 to 847
2025-05-08 21:07:36,832 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:36,832 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:40,936 - INFO - Processing batch 107/183: chunks 848 to 855
2025-05-08 21:07:40,940 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:40,940 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:45,128 - INFO - Processing batch 108/183: chunks 856 to 863
2025-05-08 21:07:45,131 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:45,131 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:49,018 - INFO - Processing batch 109/183: chunks 864 to 871
2025-05-08 21:07:49,025 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:49,025 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:52,735 - INFO - Processing batch 110/183: chunks 872 to 879
2025-05-08 21:07:52,738 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:52,738 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:07:56,663 - INFO - Processing batch 111/183: chunks 880 to 887
2025-05-08 21:07:56,670 - INFO - Use pytorch device_name: cpu
2025-05-08 21:07:56,671 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:00,801 - INFO - Processing batch 112/183: chunks 888 to 895
2025-05-08 21:08:00,805 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:00,805 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:04,584 - INFO - Processing batch 113/183: chunks 896 to 903
2025-05-08 21:08:04,588 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:04,588 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:08,379 - INFO - Processing batch 114/183: chunks 904 to 911
2025-05-08 21:08:08,382 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:08,382 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:12,258 - INFO - Processing batch 115/183: chunks 912 to 919
2025-05-08 21:08:12,261 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:12,262 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:16,271 - INFO - Processing batch 116/183: chunks 920 to 927
2025-05-08 21:08:16,276 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:16,276 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:20,609 - INFO - Processing batch 117/183: chunks 928 to 935
2025-05-08 21:08:20,614 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:20,615 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:24,748 - INFO - Processing batch 118/183: chunks 936 to 943
2025-05-08 21:08:24,752 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:24,752 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:28,866 - INFO - Processing batch 119/183: chunks 944 to 951
2025-05-08 21:08:28,870 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:28,870 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:32,999 - INFO - Processing batch 120/183: chunks 952 to 959
2025-05-08 21:08:33,003 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:33,003 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:37,204 - INFO - Processing batch 121/183: chunks 960 to 967
2025-05-08 21:08:37,208 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:37,208 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:41,409 - INFO - Processing batch 122/183: chunks 968 to 975
2025-05-08 21:08:41,415 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:41,416 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:45,657 - INFO - Processing batch 123/183: chunks 976 to 983
2025-05-08 21:08:45,661 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:45,661 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:49,571 - INFO - Processing batch 124/183: chunks 984 to 991
2025-05-08 21:08:49,574 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:49,574 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:53,491 - INFO - Processing batch 125/183: chunks 992 to 999
2025-05-08 21:08:53,494 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:53,495 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:08:57,833 - INFO - Processing batch 126/183: chunks 1000 to 1007
2025-05-08 21:08:57,836 - INFO - Use pytorch device_name: cpu
2025-05-08 21:08:57,836 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:01,823 - INFO - Processing batch 127/183: chunks 1008 to 1015
2025-05-08 21:09:01,827 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:01,827 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:05,415 - INFO - Processing batch 128/183: chunks 1016 to 1023
2025-05-08 21:09:05,418 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:05,418 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:09,161 - INFO - Processing batch 129/183: chunks 1024 to 1031
2025-05-08 21:09:09,164 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:09,164 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:13,210 - INFO - Processing batch 130/183: chunks 1032 to 1039
2025-05-08 21:09:13,215 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:13,215 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:17,106 - INFO - Processing batch 131/183: chunks 1040 to 1047
2025-05-08 21:09:17,109 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:17,109 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:20,785 - INFO - Processing batch 132/183: chunks 1048 to 1055
2025-05-08 21:09:20,788 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:20,788 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:24,729 - INFO - Processing batch 133/183: chunks 1056 to 1063
2025-05-08 21:09:24,733 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:24,734 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:28,848 - INFO - Processing batch 134/183: chunks 1064 to 1071
2025-05-08 21:09:28,854 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:28,854 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:32,610 - INFO - Processing batch 135/183: chunks 1072 to 1079
2025-05-08 21:09:32,616 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:32,616 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:36,465 - INFO - Processing batch 136/183: chunks 1080 to 1087
2025-05-08 21:09:36,468 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:36,469 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:40,617 - INFO - Processing batch 137/183: chunks 1088 to 1095
2025-05-08 21:09:40,625 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:40,625 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:44,572 - INFO - Processing batch 138/183: chunks 1096 to 1103
2025-05-08 21:09:44,577 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:44,577 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:48,244 - INFO - Processing batch 139/183: chunks 1104 to 1111
2025-05-08 21:09:48,247 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:48,248 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:51,682 - INFO - Processing batch 140/183: chunks 1112 to 1119
2025-05-08 21:09:51,686 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:51,686 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:55,451 - INFO - Processing batch 141/183: chunks 1120 to 1127
2025-05-08 21:09:55,455 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:55,455 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:09:59,161 - INFO - Processing batch 142/183: chunks 1128 to 1135
2025-05-08 21:09:59,164 - INFO - Use pytorch device_name: cpu
2025-05-08 21:09:59,165 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:03,182 - INFO - Processing batch 143/183: chunks 1136 to 1143
2025-05-08 21:10:03,185 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:03,185 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:06,904 - INFO - Processing batch 144/183: chunks 1144 to 1151
2025-05-08 21:10:06,907 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:06,907 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:10,689 - INFO - Processing batch 145/183: chunks 1152 to 1159
2025-05-08 21:10:10,692 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:10,692 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:14,663 - INFO - Processing batch 146/183: chunks 1160 to 1167
2025-05-08 21:10:14,667 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:14,667 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:20,142 - INFO - Processing batch 147/183: chunks 1168 to 1175
2025-05-08 21:10:20,145 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:20,145 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:24,901 - INFO - Processing batch 148/183: chunks 1176 to 1183
2025-05-08 21:10:24,904 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:24,904 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:28,680 - INFO - Processing batch 149/183: chunks 1184 to 1191
2025-05-08 21:10:28,684 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:28,684 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:32,509 - INFO - Processing batch 150/183: chunks 1192 to 1199
2025-05-08 21:10:32,512 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:32,512 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:36,266 - INFO - Processing batch 151/183: chunks 1200 to 1207
2025-05-08 21:10:36,269 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:36,269 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:40,076 - INFO - Processing batch 152/183: chunks 1208 to 1215
2025-05-08 21:10:40,080 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:40,080 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:43,617 - INFO - Processing batch 153/183: chunks 1216 to 1223
2025-05-08 21:10:43,621 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:43,621 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:48,311 - INFO - Processing batch 154/183: chunks 1224 to 1231
2025-05-08 21:10:48,315 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:48,315 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:52,082 - INFO - Processing batch 155/183: chunks 1232 to 1239
2025-05-08 21:10:52,085 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:52,085 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:10:56,009 - INFO - Processing batch 156/183: chunks 1240 to 1247
2025-05-08 21:10:56,013 - INFO - Use pytorch device_name: cpu
2025-05-08 21:10:56,013 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:00,109 - INFO - Processing batch 157/183: chunks 1248 to 1255
2025-05-08 21:11:00,112 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:00,112 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:04,032 - INFO - Processing batch 158/183: chunks 1256 to 1263
2025-05-08 21:11:04,036 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:04,036 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:08,305 - INFO - Processing batch 159/183: chunks 1264 to 1271
2025-05-08 21:11:08,308 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:08,309 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:12,246 - INFO - Processing batch 160/183: chunks 1272 to 1279
2025-05-08 21:11:12,250 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:12,250 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:16,216 - INFO - Processing batch 161/183: chunks 1280 to 1287
2025-05-08 21:11:16,220 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:16,220 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:20,123 - INFO - Processing batch 162/183: chunks 1288 to 1295
2025-05-08 21:11:20,126 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:20,126 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:23,944 - INFO - Processing batch 163/183: chunks 1296 to 1303
2025-05-08 21:11:23,951 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:23,951 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:27,678 - INFO - Processing batch 164/183: chunks 1304 to 1311
2025-05-08 21:11:27,682 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:27,682 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:31,611 - INFO - Processing batch 165/183: chunks 1312 to 1319
2025-05-08 21:11:31,614 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:31,615 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:35,279 - INFO - Processing batch 166/183: chunks 1320 to 1327
2025-05-08 21:11:35,283 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:35,283 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:39,264 - INFO - Processing batch 167/183: chunks 1328 to 1335
2025-05-08 21:11:39,267 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:39,267 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:43,351 - INFO - Processing batch 168/183: chunks 1336 to 1343
2025-05-08 21:11:43,355 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:43,355 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:47,192 - INFO - Processing batch 169/183: chunks 1344 to 1351
2025-05-08 21:11:47,195 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:47,195 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:52,131 - INFO - Processing batch 170/183: chunks 1352 to 1359
2025-05-08 21:11:52,134 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:52,134 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:11:56,558 - INFO - Processing batch 171/183: chunks 1360 to 1367
2025-05-08 21:11:56,561 - INFO - Use pytorch device_name: cpu
2025-05-08 21:11:56,561 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:00,212 - INFO - Processing batch 172/183: chunks 1368 to 1375
2025-05-08 21:12:00,216 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:00,216 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:05,011 - INFO - Processing batch 173/183: chunks 1376 to 1383
2025-05-08 21:12:05,017 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:05,017 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:09,231 - INFO - Processing batch 174/183: chunks 1384 to 1391
2025-05-08 21:12:09,235 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:09,235 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:12,932 - INFO - Processing batch 175/183: chunks 1392 to 1399
2025-05-08 21:12:12,936 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:12,936 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:16,815 - INFO - Processing batch 176/183: chunks 1400 to 1407
2025-05-08 21:12:16,817 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:16,817 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:20,714 - INFO - Processing batch 177/183: chunks 1408 to 1415
2025-05-08 21:12:20,721 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:20,721 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:24,324 - INFO - Processing batch 178/183: chunks 1416 to 1423
2025-05-08 21:12:24,327 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:24,327 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:28,546 - INFO - Processing batch 179/183: chunks 1424 to 1431
2025-05-08 21:12:28,552 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:28,552 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:33,072 - INFO - Processing batch 180/183: chunks 1432 to 1439
2025-05-08 21:12:33,076 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:33,076 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:36,545 - INFO - Processing batch 181/183: chunks 1440 to 1447
2025-05-08 21:12:36,547 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:36,548 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:39,743 - INFO - Processing batch 182/183: chunks 1448 to 1455
2025-05-08 21:12:39,746 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:39,746 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:42,529 - INFO - Processing batch 183/183: chunks 1456 to 1459
2025-05-08 21:12:42,532 - INFO - Use pytorch device_name: cpu
2025-05-08 21:12:42,532 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-08 21:12:45,538 - INFO - Saving indexes to disk...
2025-05-08 21:12:45,637 - INFO - Successfully built and saved all indexes
2025-05-08 21:12:45,637 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-08 21:12:45,637 - INFO - Loaded 6 code-specific vector stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-08 21:12:45,661 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-08 21:12:45,662 - INFO - [33mPress CTRL+C to quit[0m
2025-05-08 21:12:47,108 - INFO - 127.0.0.1 - - [08/May/2025 21:12:47] "GET / HTTP/1.1" 200 -
2025-05-08 21:12:47,132 - INFO - 127.0.0.1 - - [08/May/2025 21:12:47] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-08 21:12:47,154 - INFO - 127.0.0.1 - - [08/May/2025 21:12:47] "GET /get_conversations HTTP/1.1" 200 -
2025-05-08 21:12:47,231 - INFO - 127.0.0.1 - - [08/May/2025 21:12:47] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-05-08 21:12:59,312 - INFO - 127.0.0.1 - - [08/May/2025 21:12:59] "GET /get_conversation/50 HTTP/1.1" 200 -
2025-05-08 21:13:08,929 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-08 21:13:09,302 - INFO - Token usage: prompt=54, completion=12, total=66
2025-05-08 21:13:09,343 - INFO - Processing query: 'comment lancer une startup?' for conversation 51
2025-05-08 21:13:09,349 - INFO - Query received: comment lancer une startup?
2025-05-08 21:13:09,945 - INFO - Routing query to code: loi_relative_Startups (similarity: 0.5040)
2025-05-08 21:13:10,016 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-08 21:13:10,016 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-08 21:13:18,883 - INFO - Token usage: prompt=1775, completion=895, total=2670
2025-05-08 21:13:27,254 - INFO - Agent workflow completed in 18.32s
2025-05-08 21:13:27,326 - INFO - Request processed in 18.40s (thinking: 17.24s)
2025-05-08 21:13:27,327 - INFO - 127.0.0.1 - - [08/May/2025 21:13:27] "POST /ask HTTP/1.1" 200 -
2025-05-09 15:24:40,370 - INFO - Use pytorch device_name: cpu
2025-05-09 15:24:40,370 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 15:24:43,468 - INFO - Use pytorch device_name: cpu
2025-05-09 15:24:43,468 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 15:25:24,220 - INFO - Use pytorch device_name: cpu
2025-05-09 15:25:24,220 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 15:25:26,121 - INFO - Loading code-specific vector stores from stores...
2025-05-09 15:25:26,121 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:25:26,156 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 15:25:26,156 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:25:26,187 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-09 15:25:26,187 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:25:26,209 - INFO - Loaded vector store for loi_relative_Startups
2025-05-09 15:25:26,209 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:25:26,230 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-09 15:25:26,230 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:25:26,243 - INFO - Loaded vector store for loi_societes_ligne
2025-05-09 15:25:26,244 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:25:26,275 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-09 15:25:26,277 - INFO - Loading pre-built indexes...
2025-05-09 15:25:30,113 - INFO - Loaded 1460 legal document chunks
2025-05-09 15:25:30,114 - INFO - Initialization complete. General index has 1460 embeddings
2025-05-09 15:25:30,114 - INFO - Loaded 6 code-specific vector stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 15:25:30,131 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://127.0.0.1:5000
2025-05-09 15:25:30,131 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 15:25:33,630 - INFO - 127.0.0.1 - - [09/May/2025 15:25:33] "GET / HTTP/1.1" 200 -
2025-05-09 15:25:33,649 - INFO - 127.0.0.1 - - [09/May/2025 15:25:33] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-09 15:25:33,663 - INFO - 127.0.0.1 - - [09/May/2025 15:25:33] "GET /get_conversations HTTP/1.1" 200 -
2025-05-09 15:25:34,506 - INFO - 127.0.0.1 - - [09/May/2025 15:25:34] "GET / HTTP/1.1" 200 -
2025-05-09 15:25:34,528 - INFO - 127.0.0.1 - - [09/May/2025 15:25:34] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-09 15:25:34,544 - INFO - 127.0.0.1 - - [09/May/2025 15:25:34] "GET /get_conversations HTTP/1.1" 200 -
2025-05-09 15:25:35,690 - INFO - 127.0.0.1 - - [09/May/2025 15:25:35] "GET /get_conversation/51 HTTP/1.1" 200 -
2025-05-09 15:25:40,301 - INFO - 127.0.0.1 - - [09/May/2025 15:25:40] "GET /get_conversation/50 HTTP/1.1" 200 -
2025-05-09 15:25:43,297 - INFO - 127.0.0.1 - - [09/May/2025 15:25:43] "GET /get_conversation/51 HTTP/1.1" 200 -
2025-05-09 15:25:47,092 - INFO - 127.0.0.1 - - [09/May/2025 15:25:47] "DELETE /delete_conversation/51 HTTP/1.1" 200 -
2025-05-09 15:25:49,854 - INFO - 127.0.0.1 - - [09/May/2025 15:25:49] "DELETE /delete_conversation/50 HTTP/1.1" 200 -
2025-05-09 15:25:53,385 - INFO - 127.0.0.1 - - [09/May/2025 15:25:53] "DELETE /delete_conversation/48 HTTP/1.1" 200 -
2025-05-09 15:25:54,509 - INFO - 127.0.0.1 - - [09/May/2025 15:25:54] "GET /get_conversation/45 HTTP/1.1" 200 -
2025-05-09 15:26:04,764 - INFO - 127.0.0.1 - - [09/May/2025 15:26:04] "DELETE /delete_conversation/45 HTTP/1.1" 200 -
2025-05-09 15:26:05,925 - INFO - 127.0.0.1 - - [09/May/2025 15:26:05] "GET /get_conversation/49 HTTP/1.1" 200 -
2025-05-09 15:26:11,365 - INFO - 127.0.0.1 - - [09/May/2025 15:26:11] "DELETE /delete_conversation/44 HTTP/1.1" 200 -
2025-05-09 15:26:12,771 - INFO - 127.0.0.1 - - [09/May/2025 15:26:12] "GET /get_conversation/42 HTTP/1.1" 200 -
2025-05-09 15:26:15,947 - INFO - 127.0.0.1 - - [09/May/2025 15:26:15] "GET /get_conversation/42 HTTP/1.1" 200 -
2025-05-09 15:26:18,784 - INFO - 127.0.0.1 - - [09/May/2025 15:26:18] "DELETE /delete_conversation/42 HTTP/1.1" 200 -
2025-05-09 15:26:19,796 - INFO - 127.0.0.1 - - [09/May/2025 15:26:19] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-09 15:26:23,199 - INFO - 127.0.0.1 - - [09/May/2025 15:26:23] "GET /get_conversation/40 HTTP/1.1" 200 -
2025-05-09 15:26:26,412 - INFO - 127.0.0.1 - - [09/May/2025 15:26:26] "DELETE /delete_conversation/40 HTTP/1.1" 200 -
2025-05-09 15:26:29,227 - INFO - 127.0.0.1 - - [09/May/2025 15:26:29] "DELETE /delete_conversation/34 HTTP/1.1" 200 -
2025-05-09 15:26:32,326 - INFO - 127.0.0.1 - - [09/May/2025 15:26:32] "DELETE /delete_conversation/31 HTTP/1.1" 200 -
2025-05-09 15:26:35,134 - INFO - 127.0.0.1 - - [09/May/2025 15:26:35] "DELETE /delete_conversation/29 HTTP/1.1" 200 -
2025-05-09 15:26:36,482 - INFO - 127.0.0.1 - - [09/May/2025 15:26:36] "GET /get_conversation/28 HTTP/1.1" 200 -
2025-05-09 15:26:39,659 - INFO - 127.0.0.1 - - [09/May/2025 15:26:39] "GET /get_conversation/30 HTTP/1.1" 200 -
2025-05-09 15:26:41,136 - INFO - 127.0.0.1 - - [09/May/2025 15:26:41] "GET /get_conversation/30 HTTP/1.1" 200 -
2025-05-09 15:26:43,007 - INFO - 127.0.0.1 - - [09/May/2025 15:26:43] "DELETE /delete_conversation/30 HTTP/1.1" 200 -
2025-05-09 15:48:54,857 - INFO - Use pytorch device_name: cpu
2025-05-09 15:48:54,857 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 15:49:01,665 - INFO - Use pytorch device_name: cpu
2025-05-09 15:49:01,665 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 15:49:40,074 - INFO - Use pytorch device_name: cpu
2025-05-09 15:49:40,074 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 15:49:43,571 - INFO - Loading code-specific vector stores from stores...
2025-05-09 15:49:43,571 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:49:43,587 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 15:49:43,587 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:49:43,601 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-09 15:49:43,601 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:49:43,615 - INFO - Loaded vector store for loi_relative_Startups
2025-05-09 15:49:43,617 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:49:43,630 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-09 15:49:43,630 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:49:43,639 - INFO - Loaded vector store for loi_societes_ligne
2025-05-09 15:49:43,639 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 15:49:43,658 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-09 15:49:43,658 - INFO - Initialization complete. Loaded 6 code-specific vector stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 15:49:43,676 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.124.235:5000
2025-05-09 15:49:43,676 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 15:49:55,829 - INFO - 127.0.0.1 - - [09/May/2025 15:49:55] "GET / HTTP/1.1" 200 -
2025-05-09 15:49:55,849 - INFO - 127.0.0.1 - - [09/May/2025 15:49:55] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-09 15:49:55,862 - INFO - 127.0.0.1 - - [09/May/2025 15:49:55] "GET /get_conversations HTTP/1.1" 200 -
2025-05-09 15:51:56,128 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-09 15:51:56,572 - INFO - Token usage: prompt=64, completion=10, total=74
2025-05-09 15:51:56,611 - INFO - Processing query: 'qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?' for conversation 52
2025-05-09 15:51:56,617 - INFO - Query received: qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?
2025-05-09 15:51:57,459 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5990)
2025-05-09 15:51:57,520 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-09 15:51:57,520 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-09 15:52:01,042 - INFO - Token usage: prompt=2548, completion=817, total=3365
2025-05-09 15:52:01,049 - INFO - Agent workflow completed in 4.92s
2025-05-09 15:52:01,116 - INFO - Request processed in 4.99s (thinking: 3.53s)
2025-05-09 15:52:01,118 - INFO - 127.0.0.1 - - [09/May/2025 15:52:01] "POST /ask HTTP/1.1" 200 -
2025-05-09 16:07:37,852 - INFO - Use pytorch device_name: cpu
2025-05-09 16:07:37,852 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:07:44,388 - INFO - Use pytorch device_name: cpu
2025-05-09 16:07:44,388 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:08:25,589 - INFO - Use pytorch device_name: cpu
2025-05-09 16:08:25,589 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:08:28,863 - INFO - Loading code-specific vector stores from stores...
2025-05-09 16:08:28,864 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:08:28,881 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 16:08:28,881 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:08:28,896 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-09 16:08:28,897 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:08:28,911 - INFO - Loaded vector store for loi_relative_Startups
2025-05-09 16:08:28,911 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:08:28,925 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-09 16:08:28,926 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:08:28,934 - INFO - Loaded vector store for loi_societes_ligne
2025-05-09 16:08:28,934 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:08:28,952 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-09 16:08:28,952 - INFO - Initialization complete. Loaded 6 code-specific vector stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 16:08:28,966 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.124.235:5000
2025-05-09 16:08:28,966 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 16:09:12,285 - INFO - 127.0.0.1 - - [09/May/2025 16:09:12] "GET / HTTP/1.1" 200 -
2025-05-09 16:09:12,311 - INFO - 127.0.0.1 - - [09/May/2025 16:09:12] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-09 16:09:12,327 - INFO - 127.0.0.1 - - [09/May/2025 16:09:12] "GET /get_conversations HTTP/1.1" 200 -
2025-05-09 16:09:14,453 - INFO - 127.0.0.1 - - [09/May/2025 16:09:14] "GET /get_conversation/52 HTTP/1.1" 200 -
2025-05-09 16:09:25,983 - INFO - Processing query: 'qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?' for conversation 52
2025-05-09 16:09:25,987 - INFO - Query received: qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?
2025-05-09 16:09:26,941 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5990)
2025-05-09 16:09:27,022 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-09 16:09:27,022 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-09 16:09:30,930 - INFO - Token usage: prompt=2548, completion=866, total=3414
2025-05-09 16:09:30,936 - INFO - Agent workflow completed in 4.97s
2025-05-09 16:09:30,980 - INFO - Request processed in 5.01s (thinking: 3.92s)
2025-05-09 16:09:30,982 - INFO - 127.0.0.1 - - [09/May/2025 16:09:30] "POST /ask HTTP/1.1" 200 -
2025-05-09 16:27:19,584 - INFO - Use pytorch device_name: cpu
2025-05-09 16:27:19,584 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:27:25,595 - INFO - Use pytorch device_name: cpu
2025-05-09 16:27:25,595 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:27:28,956 - INFO - Use pytorch device_name: cpu
2025-05-09 16:27:28,956 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:27:32,974 - INFO - Loading code-specific vector stores from stores...
2025-05-09 16:27:32,974 - INFO - Initialization complete:
2025-05-09 16:27:32,974 - INFO - Loaded 0 FAISS stores: None
2025-05-09 16:27:32,974 - INFO - Loaded 0 BM25 indexes: None
2025-05-09 16:27:32,989 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.124.235:5000
2025-05-09 16:27:32,990 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 16:29:55,169 - INFO - Use pytorch device_name: cpu
2025-05-09 16:29:55,169 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:30:04,860 - INFO - Use pytorch device_name: cpu
2025-05-09 16:30:04,860 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:30:46,710 - INFO - Use pytorch device_name: cpu
2025-05-09 16:30:46,710 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:30:50,416 - INFO - Loading code-specific vector stores from stores...
2025-05-09 16:30:50,416 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:30:50,436 - INFO - Loaded vector store for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 16:30:50,436 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:30:50,452 - INFO - Loaded vector store for loi_relative_commerce_exterieur
2025-05-09 16:30:50,452 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:30:50,468 - INFO - Loaded vector store for loi_relative_Startups
2025-05-09 16:30:50,468 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:30:50,483 - INFO - Loaded vector store for loi_societes_commerce_international
2025-05-09 16:30:50,483 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:30:50,492 - INFO - Loaded vector store for loi_societes_ligne
2025-05-09 16:30:50,492 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:30:50,512 - INFO - Loaded vector store for texte_code_societes_commerciales
2025-05-09 16:30:50,513 - INFO - Initialization complete. Loaded 6 code-specific vector stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 16:30:50,526 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.124.235:5000
2025-05-09 16:30:50,526 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 16:32:31,755 - INFO - Use pytorch device_name: cpu
2025-05-09 16:32:31,755 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:32:37,874 - INFO - Use pytorch device_name: cpu
2025-05-09 16:32:37,874 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:33:16,690 - INFO - Use pytorch device_name: cpu
2025-05-09 16:33:16,690 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 16:33:20,057 - INFO - Loading code-specific vector stores from stores...
2025-05-09 16:33:20,058 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:33:20,076 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 16:33:20,087 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 16:33:20,087 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:33:20,103 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-09 16:33:20,112 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-09 16:33:20,112 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:33:20,127 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-09 16:33:20,137 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-09 16:33:20,137 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:33:20,153 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-09 16:33:20,162 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-09 16:33:20,162 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:33:20,172 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-09 16:33:20,181 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-09 16:33:20,181 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 16:33:20,198 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-09 16:33:20,224 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-09 16:33:20,224 - INFO - Initialization complete:
2025-05-09 16:33:20,224 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 16:33:20,224 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 16:33:20,242 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.124.235:5000
2025-05-09 16:33:20,242 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 17:32:48,085 - INFO - Use pytorch device_name: cpu
2025-05-09 17:32:48,086 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:33:04,508 - INFO - Use pytorch device_name: cpu
2025-05-09 17:33:04,508 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:33:56,714 - INFO - Use pytorch device_name: cpu
2025-05-09 17:33:56,714 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:34:06,056 - INFO - Loading code-specific vector stores from stores...
2025-05-09 17:34:06,057 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:34:06,100 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 17:34:06,121 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 17:34:06,121 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:34:06,148 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-09 17:34:06,166 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-09 17:34:06,166 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:34:06,198 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-09 17:34:06,221 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-09 17:34:06,221 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:34:06,243 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-09 17:34:06,254 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-09 17:34:06,254 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:34:06,280 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-09 17:34:06,283 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-09 17:34:06,284 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:34:06,336 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-09 17:34:06,390 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-09 17:34:06,390 - INFO - Initialization complete:
2025-05-09 17:34:06,390 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 17:34:06,390 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 17:34:06,409 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.31.210:5000
2025-05-09 17:34:06,410 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 17:36:30,226 - INFO - Use pytorch device_name: cpu
2025-05-09 17:36:30,227 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:36:42,999 - INFO - Use pytorch device_name: cpu
2025-05-09 17:36:42,999 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:37:23,494 - INFO - Use pytorch device_name: cpu
2025-05-09 17:37:23,494 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:37:29,330 - INFO - Loading code-specific vector stores from stores...
2025-05-09 17:37:29,331 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:37:29,369 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 17:37:29,392 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 17:37:29,392 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:37:29,416 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-09 17:37:29,429 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-09 17:37:29,430 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:37:29,465 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-09 17:37:29,479 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-09 17:37:29,479 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:37:29,508 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-09 17:37:29,533 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-09 17:37:29,534 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:37:29,561 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-09 17:37:29,565 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-09 17:37:29,566 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:37:29,620 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-09 17:37:29,695 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-09 17:37:29,695 - INFO - Initialization complete:
2025-05-09 17:37:29,695 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 17:37:29,695 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 17:37:29,715 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.31.210:5000
2025-05-09 17:37:29,716 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 17:40:22,358 - INFO - 127.0.0.1 - - [09/May/2025 17:40:22] "GET / HTTP/1.1" 200 -
2025-05-09 17:40:22,388 - INFO - 127.0.0.1 - - [09/May/2025 17:40:22] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-09 17:40:22,408 - INFO - 127.0.0.1 - - [09/May/2025 17:40:22] "GET /get_conversations HTTP/1.1" 200 -
2025-05-09 17:40:24,700 - INFO - 127.0.0.1 - - [09/May/2025 17:40:24] "GET /get_conversation/52 HTTP/1.1" 200 -
2025-05-09 17:40:29,518 - INFO - Processing query: 'qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?' for conversation 52
2025-05-09 17:40:29,522 - INFO - Query received: qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?
2025-05-09 17:40:30,379 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5990)
2025-05-09 17:40:30,424 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-09 17:40:30,425 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-09 17:40:34,352 - INFO - Token usage: prompt=2104, completion=836, total=2940
2025-05-09 17:40:34,360 - INFO - Agent workflow completed in 4.86s
2025-05-09 17:40:34,433 - INFO - Request processed in 4.93s (thinking: 3.94s)
2025-05-09 17:40:34,434 - INFO - 127.0.0.1 - - [09/May/2025 17:40:34] "POST /ask HTTP/1.1" 200 -
2025-05-09 17:50:46,647 - INFO - Use pytorch device_name: cpu
2025-05-09 17:50:46,647 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:50:58,509 - INFO - Use pytorch device_name: cpu
2025-05-09 17:50:58,509 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:51:38,401 - INFO - Use pytorch device_name: cpu
2025-05-09 17:51:38,401 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:51:45,602 - INFO - Loading code-specific vector stores from stores...
2025-05-09 17:51:45,603 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:51:45,650 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 17:51:45,681 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 17:51:45,682 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:51:45,718 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-09 17:51:45,744 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-09 17:51:45,745 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:51:45,786 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-09 17:51:45,812 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-09 17:51:45,812 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:51:45,860 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-09 17:51:45,891 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-09 17:51:45,891 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:51:45,923 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-09 17:51:45,926 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-09 17:51:45,927 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:51:45,986 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-09 17:51:46,041 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-09 17:51:46,042 - INFO - Initialization complete:
2025-05-09 17:51:46,042 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 17:51:46,042 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 17:51:46,063 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.31.210:5000
2025-05-09 17:51:46,063 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 17:51:55,502 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-09 17:51:56,321 - INFO - Token usage: prompt=64, completion=10, total=74
2025-05-09 17:51:56,365 - INFO - Processing query: 'qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?' for conversation 53
2025-05-09 17:51:56,373 - INFO - Query received: qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?
2025-05-09 17:51:58,267 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5990)
2025-05-09 17:51:58,400 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-09 17:51:58,400 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-09 17:52:02,359 - INFO - Token usage: prompt=2104, completion=797, total=2901
2025-05-09 17:52:02,362 - INFO - Agent workflow completed in 6.86s
2025-05-09 17:52:02,433 - INFO - Request processed in 6.93s (thinking: 3.97s)
2025-05-09 17:52:02,434 - INFO - 127.0.0.1 - - [09/May/2025 17:52:02] "POST /ask HTTP/1.1" 200 -
2025-05-09 17:55:06,627 - INFO - Use pytorch device_name: cpu
2025-05-09 17:55:06,628 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:55:17,510 - INFO - Use pytorch device_name: cpu
2025-05-09 17:55:17,510 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:56:02,657 - INFO - Use pytorch device_name: cpu
2025-05-09 17:56:02,659 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 17:56:10,400 - INFO - Loading code-specific vector stores from stores...
2025-05-09 17:56:10,401 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:56:10,447 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 17:56:10,482 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 17:56:10,483 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:56:10,536 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-09 17:56:10,566 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-09 17:56:10,567 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:56:10,621 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-09 17:56:10,651 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-09 17:56:10,651 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:56:10,702 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-09 17:56:10,737 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-09 17:56:10,738 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:56:10,774 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-09 17:56:10,777 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-09 17:56:10,778 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 17:56:10,834 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-09 17:56:10,882 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-09 17:56:10,882 - INFO - Initialization complete:
2025-05-09 17:56:10,882 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 17:56:10,882 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 17:56:10,901 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.31.210:5000
2025-05-09 17:56:10,901 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 17:56:13,183 - INFO - 127.0.0.1 - - [09/May/2025 17:56:13] "GET / HTTP/1.1" 200 -
2025-05-09 17:56:13,229 - INFO - 127.0.0.1 - - [09/May/2025 17:56:13] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-09 17:56:13,282 - INFO - 127.0.0.1 - - [09/May/2025 17:56:13] "GET /get_conversations HTTP/1.1" 200 -
2025-05-09 17:56:15,122 - INFO - 127.0.0.1 - - [09/May/2025 17:56:15] "GET /get_conversation/53 HTTP/1.1" 200 -
2025-05-09 17:56:21,298 - INFO - Processing query: 'qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?' for conversation 53
2025-05-09 17:56:21,301 - INFO - Query received: qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?
2025-05-09 17:56:22,099 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5990)
2025-05-09 17:56:22,165 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-09 17:56:22,165 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-09 17:56:25,686 - INFO - Token usage: prompt=2104, completion=663, total=2767
2025-05-09 17:56:25,693 - INFO - Agent workflow completed in 4.42s
2025-05-09 17:56:25,739 - INFO - Request processed in 4.46s (thinking: 3.53s)
2025-05-09 17:56:25,739 - INFO - 127.0.0.1 - - [09/May/2025 17:56:25] "POST /ask HTTP/1.1" 200 -
2025-05-09 18:05:36,821 - INFO - Use pytorch device_name: cpu
2025-05-09 18:05:36,821 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 18:05:50,466 - INFO - Use pytorch device_name: cpu
2025-05-09 18:05:50,466 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 18:06:30,211 - INFO - Use pytorch device_name: cpu
2025-05-09 18:06:30,211 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 18:06:35,238 - INFO - Loading code-specific vector stores from stores...
2025-05-09 18:06:35,238 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:06:35,282 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 18:06:35,296 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 18:06:35,297 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:06:35,320 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-09 18:06:35,340 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-09 18:06:35,341 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:06:35,365 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-09 18:06:35,376 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-09 18:06:35,377 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:06:35,397 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-09 18:06:35,421 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-09 18:06:35,422 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:06:35,457 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-09 18:06:35,462 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-09 18:06:35,463 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:06:35,541 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-09 18:06:35,618 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-09 18:06:35,618 - INFO - Initialization complete:
2025-05-09 18:06:35,618 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 18:06:35,618 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 18:06:35,670 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.31.210:5000
2025-05-09 18:06:35,670 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 18:07:22,137 - INFO - 127.0.0.1 - - [09/May/2025 18:07:22] "GET / HTTP/1.1" 200 -
2025-05-09 18:07:22,179 - INFO - 127.0.0.1 - - [09/May/2025 18:07:22] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-09 18:07:22,197 - INFO - 127.0.0.1 - - [09/May/2025 18:07:22] "GET /get_conversations HTTP/1.1" 200 -
2025-05-09 18:07:24,609 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-09 18:07:26,530 - INFO - Token usage: prompt=64, completion=10, total=74
2025-05-09 18:07:26,569 - INFO - Processing query: 'qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?' for conversation 54
2025-05-09 18:07:26,576 - INFO - Query received: qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?
2025-05-09 18:07:28,825 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5990)
2025-05-09 18:07:28,967 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-09 18:07:28,967 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-09 18:07:32,879 - INFO - Token usage: prompt=1196, completion=677, total=1873
2025-05-09 18:07:32,893 - INFO - Agent workflow completed in 8.28s
2025-05-09 18:07:32,974 - INFO - Request processed in 8.37s (thinking: 3.94s)
2025-05-09 18:07:32,975 - INFO - 127.0.0.1 - - [09/May/2025 18:07:32] "POST /ask HTTP/1.1" 200 -
2025-05-09 18:12:29,670 - INFO - Use pytorch device_name: cpu
2025-05-09 18:12:29,670 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 18:12:39,339 - INFO - Use pytorch device_name: cpu
2025-05-09 18:12:39,339 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 18:13:18,228 - INFO - Use pytorch device_name: cpu
2025-05-09 18:13:18,228 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-09 18:13:24,546 - INFO - Loading code-specific vector stores from stores...
2025-05-09 18:13:24,547 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:13:24,593 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 18:13:24,620 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-09 18:13:24,620 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:13:24,663 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-09 18:13:24,688 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-09 18:13:24,689 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:13:24,733 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-09 18:13:24,762 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-09 18:13:24,763 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:13:24,806 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-09 18:13:24,837 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-09 18:13:24,837 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:13:24,865 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-09 18:13:24,869 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-09 18:13:24,869 - INFO - Using langchain_community.vectorstores FAISS
2025-05-09 18:13:24,924 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-09 18:13:25,001 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-09 18:13:25,001 - INFO - Initialization complete:
2025-05-09 18:13:25,002 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 18:13:25,002 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-09 18:13:25,027 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.31.210:5000
2025-05-09 18:13:25,027 - INFO - [33mPress CTRL+C to quit[0m
2025-05-09 18:14:12,769 - INFO - Processing query: 'qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?' for conversation 54
2025-05-09 18:14:12,778 - INFO - Query received: qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?
2025-05-09 18:14:14,937 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5990)
2025-05-09 18:14:15,081 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-09 18:14:15,082 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-09 18:14:19,612 - INFO - Token usage: prompt=2104, completion=736, total=2840
2025-05-09 18:14:19,620 - INFO - Agent workflow completed in 6.87s
2025-05-09 18:14:19,691 - INFO - Request processed in 6.94s (thinking: 4.55s)
2025-05-09 18:14:19,694 - INFO - 127.0.0.1 - - [09/May/2025 18:14:19] "POST /ask HTTP/1.1" 200 -
2025-05-10 12:54:49,445 - INFO - Use pytorch device_name: cpu
2025-05-10 12:54:49,446 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 12:55:02,637 - INFO - Use pytorch device_name: cpu
2025-05-10 12:55:02,637 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 12:56:13,337 - INFO - Use pytorch device_name: cpu
2025-05-10 12:56:13,337 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 12:56:17,862 - INFO - Loading code-specific vector stores from stores...
2025-05-10 12:56:17,862 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 12:56:17,895 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 12:56:17,914 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 12:56:17,915 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 12:56:17,941 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 12:56:17,954 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 12:56:17,954 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 12:56:17,981 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 12:56:17,999 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 12:56:17,999 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 12:56:18,025 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 12:56:18,042 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 12:56:18,043 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 12:56:18,071 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 12:56:18,075 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 12:56:18,076 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 12:56:18,129 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 12:56:18,267 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 12:56:18,268 - INFO - Initialization complete:
2025-05-10 12:56:18,268 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 12:56:18,268 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 12:56:18,753 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 12:56:18,753 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 13:04:16,602 - INFO - Use pytorch device_name: cpu
2025-05-10 13:04:16,603 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:04:23,629 - INFO - Build metadata file doesn't exist. Rebuild needed.
2025-05-10 13:04:23,644 - INFO - Use pytorch device_name: cpu
2025-05-10 13:04:23,644 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:05:20,050 - INFO - Saved build metadata to C:\Users\chtar\Desktop\bouba\stores\build_metadata.json
2025-05-10 13:05:20,067 - INFO - Use pytorch device_name: cpu
2025-05-10 13:05:20,068 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:05:23,872 - INFO - Loading code-specific vector stores from stores...
2025-05-10 13:05:23,872 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:05:23,893 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 13:05:23,906 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 13:05:23,906 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:05:23,924 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 13:05:23,936 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 13:05:23,936 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:05:23,957 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 13:05:23,969 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 13:05:23,970 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:05:23,988 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 13:05:23,999 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 13:05:23,999 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:05:24,020 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 13:05:24,028 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 13:05:24,028 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:05:24,051 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 13:05:24,082 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 13:05:24,083 - INFO - Initialization complete:
2025-05-10 13:05:24,083 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 13:05:24,083 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 13:05:24,125 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 13:05:24,125 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 13:06:20,743 - INFO - Use pytorch device_name: cpu
2025-05-10 13:06:20,744 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:06:27,890 - INFO - No rebuild needed. Using existing stores.
2025-05-10 13:06:27,899 - INFO - Use pytorch device_name: cpu
2025-05-10 13:06:27,899 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:06:31,278 - INFO - Loading code-specific vector stores from stores...
2025-05-10 13:06:31,278 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:06:31,280 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 13:06:31,289 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 13:06:31,290 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:06:31,291 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 13:06:31,293 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 13:06:31,293 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:06:31,295 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 13:06:31,299 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 13:06:31,300 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:06:31,301 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 13:06:31,304 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 13:06:31,304 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:06:31,305 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 13:06:31,306 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 13:06:31,306 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:06:31,313 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 13:06:31,360 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 13:06:31,360 - INFO - Initialization complete:
2025-05-10 13:06:31,360 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 13:06:31,360 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 13:06:31,387 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 13:06:31,387 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 13:07:12,560 - INFO - Use pytorch device_name: cpu
2025-05-10 13:07:12,560 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:07:18,316 - INFO - Source file C:\Users\chtar\Desktop\bouba\legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt modified. Rebuild needed.
2025-05-10 13:07:18,333 - INFO - Use pytorch device_name: cpu
2025-05-10 13:07:18,333 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:08:28,125 - INFO - Saved build metadata to C:\Users\chtar\Desktop\bouba\stores\build_metadata.json
2025-05-10 13:08:28,144 - INFO - Use pytorch device_name: cpu
2025-05-10 13:08:28,144 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:08:35,050 - INFO - Loading code-specific vector stores from stores...
2025-05-10 13:08:35,051 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:08:35,095 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 13:08:35,129 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 13:08:35,130 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:08:35,180 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 13:08:35,210 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 13:08:35,211 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:08:35,258 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 13:08:35,290 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 13:08:35,291 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:08:35,334 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 13:08:35,355 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 13:08:35,356 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:08:35,380 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 13:08:35,383 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 13:08:35,383 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:08:35,435 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 13:08:35,532 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 13:08:35,533 - INFO - Initialization complete:
2025-05-10 13:08:35,533 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 13:08:35,533 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 13:08:35,562 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 13:08:35,562 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 13:12:32,696 - INFO - Use pytorch device_name: cpu
2025-05-10 13:12:32,696 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:12:39,134 - INFO - Code structure has changed. Full rebuild needed.
2025-05-10 13:12:39,139 - INFO - Use pytorch device_name: cpu
2025-05-10 13:12:39,139 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:12:41,824 - INFO - Saved metadata for full rebuild
2025-05-10 13:12:41,828 - INFO - Use pytorch device_name: cpu
2025-05-10 13:12:41,828 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:12:45,153 - INFO - Loading code-specific vector stores from stores...
2025-05-10 13:12:45,153 - INFO - Initialization complete:
2025-05-10 13:12:45,154 - INFO - Loaded 0 FAISS stores: None
2025-05-10 13:12:45,154 - INFO - Loaded 0 BM25 indexes: None
2025-05-10 13:12:45,168 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 13:12:45,168 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 13:13:12,758 - INFO - Use pytorch device_name: cpu
2025-05-10 13:13:12,759 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:13:21,139 - INFO - Store or BM25 index for loi_defense_contre_pratiques_deloyales_importation is missing. Will rebuild.
2025-05-10 13:13:21,139 - INFO - Store or BM25 index for loi_relative_commerce_exterieur is missing. Will rebuild.
2025-05-10 13:13:21,140 - INFO - Store or BM25 index for loi_relative_Startups is missing. Will rebuild.
2025-05-10 13:13:21,140 - INFO - Store or BM25 index for loi_societes_commerce_international is missing. Will rebuild.
2025-05-10 13:13:21,140 - INFO - Store or BM25 index for loi_societes_ligne is missing. Will rebuild.
2025-05-10 13:13:21,140 - INFO - Store or BM25 index for texte_code_societes_commerciales is missing. Will rebuild.
2025-05-10 13:13:21,141 - INFO - Selective rebuild needed for: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 13:13:21,144 - INFO - Use pytorch device_name: cpu
2025-05-10 13:13:21,144 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:13:24,595 - INFO - Updated metadata for selective rebuild of 6 codes
2025-05-10 13:13:24,606 - INFO - Use pytorch device_name: cpu
2025-05-10 13:13:24,606 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:13:27,473 - INFO - Loading code-specific vector stores from stores...
2025-05-10 13:13:27,474 - INFO - Initialization complete:
2025-05-10 13:13:27,474 - INFO - Loaded 0 FAISS stores: None
2025-05-10 13:13:27,474 - INFO - Loaded 0 BM25 indexes: None
2025-05-10 13:13:27,493 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 13:13:27,493 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 13:17:41,164 - INFO - Use pytorch device_name: cpu
2025-05-10 13:17:41,165 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:17:47,771 - INFO - Store or BM25 index for loi_defense_contre_pratiques_deloyales_importation is missing. Rebuild needed.
2025-05-10 13:17:47,773 - INFO - Saved build metadata to C:\Users\chtar\Desktop\bouba\stores\build_metadata.json
2025-05-10 13:18:20,194 - INFO - Use pytorch device_name: cpu
2025-05-10 13:18:20,195 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:18:26,921 - INFO - Use pytorch device_name: cpu
2025-05-10 13:18:26,921 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:19:17,966 - INFO - Use pytorch device_name: cpu
2025-05-10 13:19:17,968 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:19:21,076 - INFO - Loading code-specific vector stores from stores...
2025-05-10 13:19:21,077 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:19:21,096 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 13:19:21,106 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 13:19:21,106 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:19:21,121 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 13:19:21,130 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 13:19:21,130 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:19:21,144 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 13:19:21,153 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 13:19:21,154 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:19:21,168 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 13:19:21,177 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 13:19:21,177 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:19:21,187 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 13:19:21,188 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 13:19:21,188 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:19:21,206 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 13:19:21,233 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 13:19:21,234 - INFO - Initialization complete:
2025-05-10 13:19:21,234 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 13:19:21,234 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 13:19:21,253 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 13:19:21,254 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 13:21:37,788 - INFO - Use pytorch device_name: cpu
2025-05-10 13:21:37,789 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:21:45,880 - INFO - Build metadata file doesn't exist. Rebuild needed.
2025-05-10 13:21:45,907 - INFO - Use pytorch device_name: cpu
2025-05-10 13:21:45,907 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:22:35,327 - INFO - Saved build metadata to C:\Users\chtar\Desktop\bouba\stores\build_metadata.json
2025-05-10 13:22:35,339 - INFO - Use pytorch device_name: cpu
2025-05-10 13:22:35,339 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 13:22:39,275 - INFO - Loading code-specific vector stores from stores...
2025-05-10 13:22:39,276 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:22:39,316 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 13:22:39,341 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 13:22:39,341 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:22:39,372 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 13:22:39,387 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 13:22:39,387 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:22:39,420 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 13:22:39,440 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 13:22:39,440 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:22:39,463 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 13:22:39,476 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 13:22:39,476 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:22:39,487 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 13:22:39,489 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 13:22:39,489 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 13:22:39,526 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 13:22:39,581 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 13:22:39,581 - INFO - Initialization complete:
2025-05-10 13:22:39,581 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 13:22:39,581 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 13:22:39,606 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 13:22:39,607 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 13:26:15,428 - INFO - 127.0.0.1 - - [10/May/2025 13:26:15] "GET / HTTP/1.1" 200 -
2025-05-10 13:26:15,480 - INFO - 127.0.0.1 - - [10/May/2025 13:26:15] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 13:26:15,537 - INFO - 127.0.0.1 - - [10/May/2025 13:26:15] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 13:26:15,596 - INFO - 127.0.0.1 - - [10/May/2025 13:26:15] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-05-10 13:26:17,063 - INFO - 127.0.0.1 - - [10/May/2025 13:26:17] "GET /get_conversation/54 HTTP/1.1" 200 -
2025-05-10 13:26:22,945 - INFO - Processing query: 'qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?' for conversation 54
2025-05-10 13:26:22,952 - INFO - Query received: qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?
2025-05-10 13:26:24,263 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5990)
2025-05-10 13:26:24,354 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 13:26:24,354 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 13:26:27,674 - INFO - Token usage: prompt=2104, completion=775, total=2879
2025-05-10 13:26:27,676 - INFO - Agent workflow completed in 4.75s
2025-05-10 13:26:27,710 - INFO - Request processed in 4.78s (thinking: 3.33s)
2025-05-10 13:26:27,711 - INFO - 127.0.0.1 - - [10/May/2025 13:26:27] "POST /ask HTTP/1.1" 200 -
2025-05-10 14:20:08,013 - INFO - Use pytorch device_name: cpu
2025-05-10 14:20:08,013 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:20:16,912 - INFO - No rebuild needed. Using existing stores.
2025-05-10 14:20:16,918 - INFO - Use pytorch device_name: cpu
2025-05-10 14:20:16,919 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:20:21,504 - INFO - Loading code-specific vector stores from stores...
2025-05-10 14:20:21,504 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:20:21,505 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:20:21,515 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:20:21,515 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:20:21,516 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 14:20:21,517 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 14:20:21,518 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:20:21,518 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 14:20:21,521 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 14:20:21,522 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:20:21,523 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 14:20:21,527 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 14:20:21,527 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:20:21,528 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 14:20:21,529 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 14:20:21,529 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:20:21,535 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 14:20:21,566 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 14:20:21,566 - INFO - Initialization complete:
2025-05-10 14:20:21,567 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:20:21,567 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:20:21,599 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 14:20:21,599 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 14:20:59,086 - INFO - 127.0.0.1 - - [10/May/2025 14:20:59] "GET / HTTP/1.1" 200 -
2025-05-10 14:20:59,116 - INFO - 127.0.0.1 - - [10/May/2025 14:20:59] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 14:20:59,135 - INFO - 127.0.0.1 - - [10/May/2025 14:20:59] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 14:35:22,450 - INFO - Use pytorch device_name: cpu
2025-05-10 14:35:22,451 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:35:30,286 - INFO - No rebuild needed. Using existing stores.
2025-05-10 14:35:30,295 - INFO - Use pytorch device_name: cpu
2025-05-10 14:35:30,296 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:35:45,045 - INFO - Loading code-specific vector stores from stores...
2025-05-10 14:35:45,047 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:35:45,050 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:35:45,060 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:35:45,061 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:35:45,065 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 14:35:45,068 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 14:35:45,069 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:35:45,071 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 14:35:45,079 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 14:35:45,080 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:35:45,081 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 14:35:45,086 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 14:35:45,087 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:35:45,089 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 14:35:45,091 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 14:35:45,091 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:35:45,104 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 14:35:45,213 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 14:35:45,213 - INFO - Initialization complete:
2025-05-10 14:35:45,213 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:35:45,213 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:35:45,261 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 14:35:45,261 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 14:41:22,750 - INFO - 127.0.0.1 - - [10/May/2025 14:41:22] "GET /get_conversation/54 HTTP/1.1" 200 -
2025-05-10 14:41:31,726 - INFO - 127.0.0.1 - - [10/May/2025 14:41:31] "GET / HTTP/1.1" 200 -
2025-05-10 14:41:31,776 - INFO - 127.0.0.1 - - [10/May/2025 14:41:31] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 14:41:31,800 - INFO - 127.0.0.1 - - [10/May/2025 14:41:31] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 14:41:33,464 - INFO - 127.0.0.1 - - [10/May/2025 14:41:33] "GET /get_conversation/52 HTTP/1.1" 200 -
2025-05-10 14:41:37,881 - INFO - 127.0.0.1 - - [10/May/2025 14:41:37] "GET /get_conversation/49 HTTP/1.1" 200 -
2025-05-10 14:41:41,132 - INFO - 127.0.0.1 - - [10/May/2025 14:41:41] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-10 14:41:48,494 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 14:41:48,866 - INFO - Token usage: prompt=54, completion=12, total=66
2025-05-10 14:41:48,912 - INFO - Processing query: 'comment lancer une startup?' for conversation 55
2025-05-10 14:41:48,918 - INFO - Query received: comment lancer une startup?
2025-05-10 14:41:50,353 - INFO - Routing query to code: loi_relative_Startups (similarity: 0.5040)
2025-05-10 14:41:50,354 - ERROR - Search failed: hybrid_search_code() got an unexpected keyword argument 'alpha'
2025-05-10 14:41:50,355 - INFO - Agent workflow completed in 1.86s
2025-05-10 14:41:50,355 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1620, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 14:41:50,384 - INFO - 127.0.0.1 - - [10/May/2025 14:41:50] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 14:41:54,528 - INFO - 127.0.0.1 - - [10/May/2025 14:41:54] "GET /get_conversation/54 HTTP/1.1" 200 -
2025-05-10 14:42:19,450 - INFO - Processing query: 'qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?' for conversation 54
2025-05-10 14:42:19,451 - INFO - Query received: qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?
2025-05-10 14:42:19,954 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5990)
2025-05-10 14:42:19,954 - ERROR - Search failed: hybrid_search_code() got an unexpected keyword argument 'alpha'
2025-05-10 14:42:19,956 - INFO - Agent workflow completed in 0.52s
2025-05-10 14:42:19,956 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1620, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 14:42:19,957 - INFO - 127.0.0.1 - - [10/May/2025 14:42:19] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 14:45:47,145 - INFO - Use pytorch device_name: cpu
2025-05-10 14:45:47,148 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:45:52,660 - INFO - No rebuild needed. Using existing stores.
2025-05-10 14:45:52,666 - INFO - Use pytorch device_name: cpu
2025-05-10 14:45:52,666 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:45:55,108 - INFO - Loading code-specific vector stores from stores...
2025-05-10 14:45:55,108 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:45:55,109 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:45:55,111 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:45:55,111 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:45:55,112 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 14:45:55,113 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 14:45:55,113 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:45:55,113 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 14:45:55,115 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 14:45:55,115 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:45:55,115 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 14:45:55,116 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 14:45:55,116 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:45:55,116 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 14:45:55,118 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 14:45:55,118 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:45:55,120 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 14:45:55,140 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 14:45:55,141 - INFO - Initialization complete:
2025-05-10 14:45:55,141 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:45:55,141 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:45:55,154 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 14:45:55,154 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 14:46:01,646 - INFO - 127.0.0.1 - - [10/May/2025 14:46:01] "GET / HTTP/1.1" 200 -
2025-05-10 14:46:01,670 - INFO - 127.0.0.1 - - [10/May/2025 14:46:01] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 14:46:01,686 - INFO - 127.0.0.1 - - [10/May/2025 14:46:01] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 14:46:03,950 - INFO - 127.0.0.1 - - [10/May/2025 14:46:03] "GET /get_conversation/55 HTTP/1.1" 200 -
2025-05-10 14:46:07,625 - INFO - Processing query: 'comment lancer une startup?' for conversation 55
2025-05-10 14:46:07,628 - INFO - Query received: comment lancer une startup?
2025-05-10 14:46:08,971 - INFO - Routing query to code: loi_relative_Startups (similarity: 0.5040)
2025-05-10 14:46:08,971 - ERROR - Search failed: hybrid_search_code() got an unexpected keyword argument 'alpha'
2025-05-10 14:46:08,971 - INFO - Agent workflow completed in 1.36s
2025-05-10 14:46:08,972 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1617, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 14:46:08,973 - INFO - 127.0.0.1 - - [10/May/2025 14:46:08] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 14:49:57,020 - INFO - Use pytorch device_name: cpu
2025-05-10 14:49:57,020 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:50:04,132 - INFO - No rebuild needed. Using existing stores.
2025-05-10 14:50:04,138 - INFO - Use pytorch device_name: cpu
2025-05-10 14:50:04,139 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:50:07,426 - INFO - Loading code-specific vector stores from stores...
2025-05-10 14:50:07,428 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:50:07,429 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:50:07,436 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:50:07,436 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:50:07,438 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 14:50:07,440 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 14:50:07,441 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:50:07,442 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 14:50:07,446 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 14:50:07,446 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:50:07,447 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 14:50:07,452 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 14:50:07,452 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:50:07,453 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 14:50:07,454 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 14:50:07,455 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:50:07,461 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 14:50:07,508 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 14:50:07,508 - INFO - Initialization complete:
2025-05-10 14:50:07,508 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:50:07,508 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:50:07,534 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 14:50:07,534 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 14:51:19,145 - INFO - 127.0.0.1 - - [10/May/2025 14:51:19] "GET / HTTP/1.1" 200 -
2025-05-10 14:51:19,178 - INFO - 127.0.0.1 - - [10/May/2025 14:51:19] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 14:51:19,192 - INFO - 127.0.0.1 - - [10/May/2025 14:51:19] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 14:51:30,581 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 14:51:30,949 - INFO - Token usage: prompt=54, completion=14, total=68
2025-05-10 14:51:30,982 - INFO - Processing query: 'comment lancer une startup?' for conversation 56
2025-05-10 14:51:30,984 - INFO - Query received: comment lancer une startup?
2025-05-10 14:51:31,878 - INFO - Routing query to code: loi_relative_Startups (similarity: 0.5040)
2025-05-10 14:51:31,878 - ERROR - Search failed: hybrid_search_code() got an unexpected keyword argument 'alpha'
2025-05-10 14:51:31,879 - INFO - Agent workflow completed in 1.30s
2025-05-10 14:51:31,879 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1615, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 14:51:31,881 - INFO - 127.0.0.1 - - [10/May/2025 14:51:31] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 14:51:55,976 - INFO - Use pytorch device_name: cpu
2025-05-10 14:51:55,976 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:52:03,611 - INFO - No rebuild needed. Using existing stores.
2025-05-10 14:52:03,623 - INFO - Use pytorch device_name: cpu
2025-05-10 14:52:03,623 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:52:06,972 - INFO - Loading code-specific vector stores from stores...
2025-05-10 14:52:06,972 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:52:06,973 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:52:06,975 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:52:06,975 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:52:06,976 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 14:52:06,977 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 14:52:06,977 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:52:06,978 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 14:52:06,979 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 14:52:06,979 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:52:06,979 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 14:52:06,981 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 14:52:06,981 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:52:06,981 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 14:52:06,982 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 14:52:06,982 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:52:06,984 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 14:52:07,002 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 14:52:07,002 - INFO - Initialization complete:
2025-05-10 14:52:07,003 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:52:07,003 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:52:07,018 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 14:52:07,018 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 14:52:10,949 - INFO - 127.0.0.1 - - [10/May/2025 14:52:10] "GET / HTTP/1.1" 200 -
2025-05-10 14:52:10,979 - INFO - 127.0.0.1 - - [10/May/2025 14:52:10] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 14:52:10,992 - INFO - 127.0.0.1 - - [10/May/2025 14:52:10] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 14:52:12,607 - INFO - 127.0.0.1 - - [10/May/2025 14:52:12] "GET /get_conversation/56 HTTP/1.1" 200 -
2025-05-10 14:52:16,299 - INFO - Processing query: 'comment lancer une startup?' for conversation 56
2025-05-10 14:52:16,302 - INFO - Query received: comment lancer une startup?
2025-05-10 14:52:17,160 - INFO - Routing query to code: loi_relative_Startups (similarity: 0.5040)
2025-05-10 14:52:17,199 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 14:52:17,199 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 14:52:20,756 - INFO - Token usage: prompt=2110, completion=871, total=2981
2025-05-10 14:52:20,760 - INFO - Agent workflow completed in 4.48s
2025-05-10 14:52:20,815 - INFO - Request processed in 4.54s (thinking: 3.57s)
2025-05-10 14:52:20,815 - INFO - 127.0.0.1 - - [10/May/2025 14:52:20] "POST /ask HTTP/1.1" 200 -
2025-05-10 14:56:06,527 - INFO - Use pytorch device_name: cpu
2025-05-10 14:56:06,527 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:56:13,915 - INFO - No rebuild needed. Using existing stores.
2025-05-10 14:56:13,927 - INFO - Use pytorch device_name: cpu
2025-05-10 14:56:13,927 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:56:17,221 - INFO - Loading code-specific vector stores from stores...
2025-05-10 14:56:17,221 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:56:17,223 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:56:17,230 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:56:17,231 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:56:17,232 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 14:56:17,234 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 14:56:17,234 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:56:17,235 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 14:56:17,238 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 14:56:17,238 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:56:17,240 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 14:56:17,242 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 14:56:17,243 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:56:17,244 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 14:56:17,244 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 14:56:17,245 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:56:17,250 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 14:56:17,299 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 14:56:17,299 - INFO - Initialization complete:
2025-05-10 14:56:17,299 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:56:17,299 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:56:17,323 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 14:56:17,323 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 14:56:29,178 - INFO - 127.0.0.1 - - [10/May/2025 14:56:29] "GET / HTTP/1.1" 200 -
2025-05-10 14:56:29,203 - INFO - 127.0.0.1 - - [10/May/2025 14:56:29] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 14:56:29,213 - INFO - 127.0.0.1 - - [10/May/2025 14:56:29] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 14:56:31,069 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 14:56:31,390 - INFO - Token usage: prompt=54, completion=12, total=66
2025-05-10 14:56:31,421 - INFO - Processing query: 'comment lancer une startup?' for conversation 57
2025-05-10 14:56:31,423 - INFO - Query received: comment lancer une startup?
2025-05-10 14:56:32,341 - INFO - Routing query to code: loi_relative_Startups (similarity: 0.5040)
2025-05-10 14:56:32,342 - ERROR - Search failed: hybrid_search_code() got an unexpected keyword argument 'alpha'
2025-05-10 14:56:32,342 - INFO - Agent workflow completed in 1.27s
2025-05-10 14:56:32,343 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1692, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 14:56:32,344 - INFO - 127.0.0.1 - - [10/May/2025 14:56:32] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 14:58:47,762 - INFO - Use pytorch device_name: cpu
2025-05-10 14:58:47,762 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:58:54,778 - INFO - No rebuild needed. Using existing stores.
2025-05-10 14:58:54,793 - INFO - Use pytorch device_name: cpu
2025-05-10 14:58:54,793 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 14:58:58,107 - INFO - Loading code-specific vector stores from stores...
2025-05-10 14:58:58,108 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:58:58,109 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:58:58,117 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 14:58:58,117 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:58:58,118 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 14:58:58,120 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 14:58:58,122 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:58:58,123 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 14:58:58,127 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 14:58:58,127 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:58:58,128 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 14:58:58,131 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 14:58:58,132 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:58:58,132 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 14:58:58,133 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 14:58:58,134 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 14:58:58,141 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 14:58:58,183 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 14:58:58,183 - INFO - Initialization complete:
2025-05-10 14:58:58,183 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:58:58,183 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 14:58:58,199 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 14:58:58,199 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 14:59:35,544 - INFO - 127.0.0.1 - - [10/May/2025 14:59:35] "GET / HTTP/1.1" 200 -
2025-05-10 14:59:35,564 - INFO - 127.0.0.1 - - [10/May/2025 14:59:35] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 14:59:35,584 - INFO - 127.0.0.1 - - [10/May/2025 14:59:35] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 14:59:37,298 - INFO - 127.0.0.1 - - [10/May/2025 14:59:37] "GET /get_conversation/57 HTTP/1.1" 200 -
2025-05-10 14:59:42,446 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 14:59:42,826 - INFO - Token usage: prompt=54, completion=12, total=66
2025-05-10 14:59:42,853 - INFO - Processing query: 'comment lancer une startup?' for conversation 58
2025-05-10 14:59:42,855 - INFO - Query received: comment lancer une startup?
2025-05-10 14:59:43,705 - INFO - Routing query to code: loi_relative_Startups (similarity: 0.5040)
2025-05-10 14:59:43,736 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 14:59:43,736 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 14:59:48,369 - INFO - Token usage: prompt=1792, completion=1181, total=2973
2025-05-10 14:59:48,374 - INFO - Agent workflow completed in 5.93s
2025-05-10 14:59:48,453 - INFO - Request processed in 6.01s (thinking: 4.64s)
2025-05-10 14:59:48,454 - INFO - 127.0.0.1 - - [10/May/2025 14:59:48] "POST /ask HTTP/1.1" 200 -
2025-05-10 14:59:53,377 - INFO - 127.0.0.1 - - [10/May/2025 14:59:53] "GET /get_conversation/56 HTTP/1.1" 200 -
2025-05-10 14:59:57,074 - INFO - 127.0.0.1 - - [10/May/2025 14:59:57] "GET /get_conversation/57 HTTP/1.1" 200 -
2025-05-10 15:00:00,904 - INFO - 127.0.0.1 - - [10/May/2025 15:00:00] "GET /get_conversation/56 HTTP/1.1" 200 -
2025-05-10 15:00:04,806 - INFO - 127.0.0.1 - - [10/May/2025 15:00:04] "GET /get_conversation/57 HTTP/1.1" 200 -
2025-05-10 15:00:08,790 - INFO - 127.0.0.1 - - [10/May/2025 15:00:08] "DELETE /delete_conversation/57 HTTP/1.1" 200 -
2025-05-10 15:00:09,936 - INFO - 127.0.0.1 - - [10/May/2025 15:00:09] "GET /get_conversation/56 HTTP/1.1" 200 -
2025-05-10 15:00:11,587 - INFO - 127.0.0.1 - - [10/May/2025 15:00:11] "GET /get_conversation/55 HTTP/1.1" 200 -
2025-05-10 15:00:12,866 - INFO - 127.0.0.1 - - [10/May/2025 15:00:12] "GET /get_conversation/53 HTTP/1.1" 200 -
2025-05-10 15:00:17,097 - INFO - 127.0.0.1 - - [10/May/2025 15:00:17] "GET /get_conversation/52 HTTP/1.1" 200 -
2025-05-10 15:00:26,921 - INFO - 127.0.0.1 - - [10/May/2025 15:00:26] "GET /get_conversation/49 HTTP/1.1" 200 -
2025-05-10 15:00:33,304 - INFO - 127.0.0.1 - - [10/May/2025 15:00:33] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-10 15:00:38,712 - INFO - 127.0.0.1 - - [10/May/2025 15:00:38] "GET /get_conversation/56 HTTP/1.1" 200 -
2025-05-10 15:00:43,393 - INFO - 127.0.0.1 - - [10/May/2025 15:00:43] "GET /get_conversation/55 HTTP/1.1" 200 -
2025-05-10 15:00:47,143 - INFO - 127.0.0.1 - - [10/May/2025 15:00:47] "DELETE /delete_conversation/55 HTTP/1.1" 200 -
2025-05-10 15:00:48,932 - INFO - 127.0.0.1 - - [10/May/2025 15:00:48] "GET /get_conversation/54 HTTP/1.1" 200 -
2025-05-10 15:00:59,682 - INFO - 127.0.0.1 - - [10/May/2025 15:00:59] "GET / HTTP/1.1" 200 -
2025-05-10 15:00:59,750 - INFO - 127.0.0.1 - - [10/May/2025 15:00:59] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 15:00:59,795 - INFO - 127.0.0.1 - - [10/May/2025 15:00:59] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 15:01:02,565 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 15:01:02,887 - INFO - Token usage: prompt=64, completion=10, total=74
2025-05-10 15:01:02,915 - INFO - Processing query: 'qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?' for conversation 59
2025-05-10 15:01:02,916 - INFO - Query received: qu'elles sont les activités que les sociétés de commerce international peuvent exercer ?
2025-05-10 15:01:03,222 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5990)
2025-05-10 15:01:03,252 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 15:01:03,253 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 15:01:11,045 - INFO - Token usage: prompt=2422, completion=877, total=3299
2025-05-10 15:01:11,048 - INFO - Agent workflow completed in 8.48s
2025-05-10 15:01:11,087 - INFO - Request processed in 8.52s (thinking: 7.80s)
2025-05-10 15:01:11,088 - INFO - 127.0.0.1 - - [10/May/2025 15:01:11] "POST /ask HTTP/1.1" 200 -
2025-05-10 15:15:53,837 - INFO - 127.0.0.1 - - [10/May/2025 15:15:53] "GET /get_conversation/53 HTTP/1.1" 200 -
2025-05-10 15:28:57,216 - INFO - 127.0.0.1 - - [10/May/2025 15:28:57] "GET /get_conversation/52 HTTP/1.1" 200 -
2025-05-10 15:29:04,821 - INFO - 127.0.0.1 - - [10/May/2025 15:29:04] "GET /get_conversation/53 HTTP/1.1" 200 -
2025-05-10 15:29:09,082 - INFO - 127.0.0.1 - - [10/May/2025 15:29:09] "DELETE /delete_conversation/52 HTTP/1.1" 200 -
2025-05-10 15:29:10,031 - INFO - 127.0.0.1 - - [10/May/2025 15:29:10] "GET /get_conversation/49 HTTP/1.1" 200 -
2025-05-10 15:29:12,560 - INFO - 127.0.0.1 - - [10/May/2025 15:29:12] "GET /get_conversation/41 HTTP/1.1" 200 -
2025-05-10 15:29:17,111 - INFO - 127.0.0.1 - - [10/May/2025 15:29:17] "GET /get_conversation/28 HTTP/1.1" 200 -
2025-05-10 15:29:20,799 - INFO - 127.0.0.1 - - [10/May/2025 15:29:20] "DELETE /delete_conversation/28 HTTP/1.1" 200 -
2025-05-10 15:51:38,542 - INFO - 127.0.0.1 - - [10/May/2025 15:51:38] "[31m[1mGET /ask HTTP/1.1[0m" 405 -
2025-05-10 15:51:38,573 - INFO - 127.0.0.1 - - [10/May/2025 15:51:38] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-05-10 15:52:00,481 - INFO - 127.0.0.1 - - [10/May/2025 15:52:00] "GET / HTTP/1.1" 200 -
2025-05-10 15:52:00,540 - INFO - 127.0.0.1 - - [10/May/2025 15:52:00] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 15:52:00,584 - INFO - 127.0.0.1 - - [10/May/2025 15:52:00] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 15:52:04,871 - INFO - 127.0.0.1 - - [10/May/2025 15:52:04] "[31m[1mGET /ask HTTP/1.1[0m" 405 -
2025-05-10 15:53:49,433 - INFO - 127.0.0.1 - - [10/May/2025 15:53:49] "GET / HTTP/1.1" 200 -
2025-05-10 15:53:49,522 - INFO - 127.0.0.1 - - [10/May/2025 15:53:49] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 15:53:49,591 - INFO - 127.0.0.1 - - [10/May/2025 15:53:49] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 15:53:49,687 - INFO - 127.0.0.1 - - [10/May/2025 15:53:49] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-05-10 15:54:02,928 - INFO - 127.0.0.1 - - [10/May/2025 15:54:02] "[31m[1mGET /ask HTTP/1.1[0m" 405 -
2025-05-10 15:54:06,173 - INFO - 127.0.0.1 - - [10/May/2025 15:54:06] "GET / HTTP/1.1" 200 -
2025-05-10 15:54:06,202 - INFO - 127.0.0.1 - - [10/May/2025 15:54:06] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-10 15:54:06,239 - INFO - 127.0.0.1 - - [10/May/2025 15:54:06] "GET /get_conversations HTTP/1.1" 200 -
2025-05-10 17:22:01,142 - INFO - Use pytorch device_name: cpu
2025-05-10 17:22:01,142 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 17:22:11,645 - INFO - No rebuild needed. Using existing stores.
2025-05-10 17:22:11,656 - INFO - Use pytorch device_name: cpu
2025-05-10 17:22:11,656 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-10 17:22:15,554 - INFO - Loading code-specific vector stores from stores...
2025-05-10 17:22:15,555 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 17:22:15,563 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 17:22:15,569 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-10 17:22:15,570 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 17:22:15,571 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-10 17:22:15,573 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-10 17:22:15,574 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 17:22:15,574 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-10 17:22:15,577 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-10 17:22:15,577 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 17:22:15,579 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-10 17:22:15,582 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-10 17:22:15,582 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 17:22:15,583 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-10 17:22:15,584 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-10 17:22:15,584 - INFO - Using langchain_community.vectorstores FAISS
2025-05-10 17:22:15,589 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-10 17:22:15,621 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-10 17:22:15,622 - INFO - Initialization complete:
2025-05-10 17:22:15,622 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 17:22:15,622 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-10 17:22:15,649 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.100.9:5000
2025-05-10 17:22:15,649 - INFO - [33mPress CTRL+C to quit[0m
2025-05-10 17:29:38,945 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:29:39,913 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 17:29:39,942 - INFO - Processing query: 'Qu'est-ce que le droit antidumping selon la loi tunisienne ?' for conversation 60
2025-05-10 17:29:39,947 - INFO - Query received: Qu'est-ce que le droit antidumping selon la loi tunisienne ?
2025-05-10 17:29:41,545 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7042)
2025-05-10 17:29:41,656 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:29:41,657 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:29:44,183 - INFO - Token usage: prompt=2238, completion=554, total=2792
2025-05-10 17:29:44,190 - INFO - Agent workflow completed in 5.24s
2025-05-10 17:29:44,215 - INFO - Request processed in 5.27s (thinking: 2.54s)
2025-05-10 17:29:44,216 - INFO - 127.0.0.1 - - [10/May/2025 17:29:44] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:35:22,342 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:35:22,701 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 17:35:22,730 - INFO - Processing query: 'Qu'est-ce que le droit antidumping selon la loi tunisienne ?' for conversation 61
2025-05-10 17:35:22,732 - INFO - Query received: Qu'est-ce que le droit antidumping selon la loi tunisienne ?
2025-05-10 17:35:23,482 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7042)
2025-05-10 17:35:23,583 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:35:23,583 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:35:26,341 - INFO - Token usage: prompt=2238, completion=652, total=2890
2025-05-10 17:35:26,351 - INFO - Agent workflow completed in 4.01s
2025-05-10 17:35:26,397 - INFO - Request processed in 4.06s (thinking: 2.78s)
2025-05-10 17:35:26,398 - INFO - 127.0.0.1 - - [10/May/2025 17:35:26] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:35:27,541 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:35:27,851 - INFO - Token usage: prompt=62, completion=14, total=76
2025-05-10 17:35:27,879 - INFO - Processing query: 'Dans quel cas une subvention est-elle considérée comme spécifique ?' for conversation 62
2025-05-10 17:35:27,882 - INFO - Query received: Dans quel cas une subvention est-elle considérée comme spécifique ?
2025-05-10 17:35:28,873 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4032)
2025-05-10 17:35:28,981 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:35:28,981 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:35:30,584 - INFO - Token usage: prompt=1544, completion=345, total=1889
2025-05-10 17:35:30,592 - INFO - Agent workflow completed in 3.05s
2025-05-10 17:35:30,618 - INFO - Request processed in 3.08s (thinking: 1.62s)
2025-05-10 17:35:30,619 - INFO - 127.0.0.1 - - [10/May/2025 17:35:30] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:35:31,640 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:35:31,983 - INFO - Token usage: prompt=63, completion=20, total=83
2025-05-10 17:35:32,010 - INFO - Processing query: 'Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?' for conversation 63
2025-05-10 17:35:32,024 - INFO - Query received: Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?
2025-05-10 17:35:32,854 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6102)
2025-05-10 17:35:32,952 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:35:32,952 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:35:34,435 - INFO - Token usage: prompt=1545, completion=313, total=1858
2025-05-10 17:35:34,444 - INFO - Agent workflow completed in 2.80s
2025-05-10 17:35:34,470 - INFO - Request processed in 2.83s (thinking: 1.50s)
2025-05-10 17:35:34,472 - INFO - 127.0.0.1 - - [10/May/2025 17:35:34] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:35:35,490 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:35:35,858 - INFO - Token usage: prompt=64, completion=15, total=79
2025-05-10 17:35:35,895 - INFO - Processing query: 'Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?' for conversation 64
2025-05-10 17:35:35,895 - INFO - Query received: Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?
2025-05-10 17:35:36,348 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5187)
2025-05-10 17:35:36,406 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:35:36,406 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:35:36,519 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:35:36,520 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:35:38,647 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:35:38,647 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:35:42,791 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:35:42,791 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:35:42,791 - INFO - Agent workflow completed in 7.30s
2025-05-10 17:35:42,791 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:35:42,797 - INFO - 127.0.0.1 - - [10/May/2025 17:35:42] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:41:32,409 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:41:33,497 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 17:41:33,527 - INFO - Processing query: 'Qu'est-ce que le droit antidumping selon la loi tunisienne ?' for conversation 65
2025-05-10 17:41:33,528 - INFO - Query received: Qu'est-ce que le droit antidumping selon la loi tunisienne ?
2025-05-10 17:41:33,945 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7042)
2025-05-10 17:41:34,008 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:41:34,009 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:41:36,133 - INFO - Token usage: prompt=2238, completion=432, total=2670
2025-05-10 17:41:36,139 - INFO - Agent workflow completed in 3.73s
2025-05-10 17:41:36,167 - INFO - Request processed in 3.76s (thinking: 2.14s)
2025-05-10 17:41:36,168 - INFO - 127.0.0.1 - - [10/May/2025 17:41:36] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:41:37,203 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:41:37,527 - INFO - Token usage: prompt=62, completion=12, total=74
2025-05-10 17:41:37,559 - INFO - Processing query: 'Dans quel cas une subvention est-elle considérée comme spécifique ?' for conversation 66
2025-05-10 17:41:37,561 - INFO - Query received: Dans quel cas une subvention est-elle considérée comme spécifique ?
2025-05-10 17:41:38,031 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4032)
2025-05-10 17:41:38,082 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:41:38,083 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:41:40,101 - INFO - Token usage: prompt=1544, completion=405, total=1949
2025-05-10 17:41:40,108 - INFO - Agent workflow completed in 2.90s
2025-05-10 17:41:40,136 - INFO - Request processed in 2.93s (thinking: 2.03s)
2025-05-10 17:41:40,136 - INFO - 127.0.0.1 - - [10/May/2025 17:41:40] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:41:41,168 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:41:41,503 - INFO - Token usage: prompt=63, completion=19, total=82
2025-05-10 17:41:41,543 - INFO - Processing query: 'Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?' for conversation 67
2025-05-10 17:41:41,545 - INFO - Query received: Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?
2025-05-10 17:41:42,000 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6102)
2025-05-10 17:41:42,054 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:41:42,054 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:41:43,491 - INFO - Token usage: prompt=1545, completion=276, total=1821
2025-05-10 17:41:43,497 - INFO - Agent workflow completed in 2.33s
2025-05-10 17:41:43,525 - INFO - Request processed in 2.36s (thinking: 1.45s)
2025-05-10 17:41:43,525 - INFO - 127.0.0.1 - - [10/May/2025 17:41:43] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:41:44,539 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:41:44,848 - INFO - Token usage: prompt=64, completion=15, total=79
2025-05-10 17:41:44,879 - INFO - Processing query: 'Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?' for conversation 68
2025-05-10 17:41:44,880 - INFO - Query received: Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?
2025-05-10 17:41:45,376 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5187)
2025-05-10 17:41:45,439 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:41:45,440 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:41:45,593 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:41:45,594 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:41:47,734 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:41:47,735 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:41:51,879 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:41:51,880 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:41:51,881 - INFO - Agent workflow completed in 7.34s
2025-05-10 17:41:51,881 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:41:51,881 - INFO - 127.0.0.1 - - [10/May/2025 17:41:51] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:41:52,902 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:41:53,257 - INFO - Token usage: prompt=66, completion=17, total=83
2025-05-10 17:41:53,292 - INFO - Processing query: 'Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?' for conversation 69
2025-05-10 17:41:53,293 - INFO - Query received: Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?
2025-05-10 17:41:53,750 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6496)
2025-05-10 17:41:53,800 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:41:53,800 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:41:53,917 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:41:53,917 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:41:56,068 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:41:56,068 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:42:03,097 - INFO - Token usage: prompt=1808, completion=734, total=2542
2025-05-10 17:42:03,104 - INFO - Agent workflow completed in 10.20s
2025-05-10 17:42:03,144 - INFO - Request processed in 10.24s (thinking: 9.31s)
2025-05-10 17:42:03,145 - INFO - 127.0.0.1 - - [10/May/2025 17:42:03] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:42:04,166 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:42:04,489 - INFO - Token usage: prompt=63, completion=14, total=77
2025-05-10 17:42:04,520 - INFO - Processing query: 'Quelle est la durée maximale d’un droit antidumping provisoire ?' for conversation 70
2025-05-10 17:42:04,521 - INFO - Query received: Quelle est la durée maximale d’un droit antidumping provisoire ?
2025-05-10 17:42:04,954 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4843)
2025-05-10 17:42:05,001 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:42:05,001 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:42:05,118 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:05,118 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:42:07,281 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:07,281 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:42:11,434 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:11,434 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:42:11,435 - INFO - Agent workflow completed in 7.27s
2025-05-10 17:42:11,435 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:42:11,437 - INFO - 127.0.0.1 - - [10/May/2025 17:42:11] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:42:12,450 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:42:12,762 - INFO - Token usage: prompt=62, completion=13, total=75
2025-05-10 17:42:12,795 - INFO - Processing query: 'Comment est traité un engagement de prix de l’exportateur ?' for conversation 71
2025-05-10 17:42:12,796 - INFO - Query received: Comment est traité un engagement de prix de l’exportateur ?
2025-05-10 17:42:13,222 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4960)
2025-05-10 17:42:13,267 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:42:13,267 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:42:13,391 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:13,392 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:42:15,528 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:15,528 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:42:19,668 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:19,669 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:42:19,670 - INFO - Agent workflow completed in 7.22s
2025-05-10 17:42:19,671 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:42:19,673 - INFO - 127.0.0.1 - - [10/May/2025 17:42:19] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:42:20,696 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:42:21,066 - INFO - Token usage: prompt=65, completion=15, total=80
2025-05-10 17:42:21,098 - INFO - Processing query: 'Quel est le délai pour demander le remboursement de droits antidumping en excès ?' for conversation 72
2025-05-10 17:42:21,098 - INFO - Query received: Quel est le délai pour demander le remboursement de droits antidumping en excès ?
2025-05-10 17:42:21,578 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5211)
2025-05-10 17:42:21,621 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:42:21,621 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:42:24,491 - INFO - Token usage: prompt=1696, completion=700, total=2396
2025-05-10 17:42:24,497 - INFO - Agent workflow completed in 3.80s
2025-05-10 17:42:24,532 - INFO - Request processed in 3.84s (thinking: 2.88s)
2025-05-10 17:42:24,532 - INFO - 127.0.0.1 - - [10/May/2025 17:42:24] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:42:25,556 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:42:25,890 - INFO - Token usage: prompt=67, completion=18, total=85
2025-05-10 17:42:25,919 - INFO - Processing query: 'Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?' for conversation 73
2025-05-10 17:42:25,920 - INFO - Query received: Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?
2025-05-10 17:42:26,362 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3436)
2025-05-10 17:42:26,419 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:42:26,419 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:42:26,566 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:26,567 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:42:28,685 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:28,685 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:42:32,812 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:32,812 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:42:32,813 - INFO - Agent workflow completed in 7.26s
2025-05-10 17:42:32,813 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:42:32,814 - INFO - 127.0.0.1 - - [10/May/2025 17:42:32] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:42:33,834 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:42:34,204 - INFO - Token usage: prompt=63, completion=15, total=78
2025-05-10 17:42:34,232 - INFO - Processing query: 'Quel tribunal est compétent pour la révision judiciaire des décisions prises ?' for conversation 74
2025-05-10 17:42:34,233 - INFO - Query received: Quel tribunal est compétent pour la révision judiciaire des décisions prises ?
2025-05-10 17:42:34,700 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3625)
2025-05-10 17:42:34,738 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:42:34,738 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:42:34,851 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:34,851 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:42:37,393 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:37,393 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:42:42,029 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:42:42,029 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:42:42,030 - INFO - Agent workflow completed in 8.20s
2025-05-10 17:42:42,031 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:42:42,031 - INFO - 127.0.0.1 - - [10/May/2025 17:42:42] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:47:21,088 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:47:21,394 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 17:47:21,420 - INFO - Processing query: 'Qu'est-ce que le droit antidumping selon la loi tunisienne ?' for conversation 75
2025-05-10 17:47:21,421 - INFO - Query received: Qu'est-ce que le droit antidumping selon la loi tunisienne ?
2025-05-10 17:47:21,835 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7042)
2025-05-10 17:47:21,910 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:47:21,910 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:47:23,738 - INFO - Token usage: prompt=2238, completion=377, total=2615
2025-05-10 17:47:23,743 - INFO - Agent workflow completed in 2.65s
2025-05-10 17:47:23,759 - INFO - Request processed in 2.67s (thinking: 1.84s)
2025-05-10 17:47:23,759 - INFO - 127.0.0.1 - - [10/May/2025 17:47:23] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:47:24,802 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:47:25,112 - INFO - Token usage: prompt=62, completion=11, total=73
2025-05-10 17:47:25,140 - INFO - Processing query: 'Dans quel cas une subvention est-elle considérée comme spécifique ?' for conversation 76
2025-05-10 17:47:25,142 - INFO - Query received: Dans quel cas une subvention est-elle considérée comme spécifique ?
2025-05-10 17:47:25,579 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4032)
2025-05-10 17:47:25,613 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:47:25,613 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:47:27,589 - INFO - Token usage: prompt=1544, completion=456, total=2000
2025-05-10 17:47:27,593 - INFO - Agent workflow completed in 2.79s
2025-05-10 17:47:27,610 - INFO - Request processed in 2.81s (thinking: 1.98s)
2025-05-10 17:47:27,611 - INFO - 127.0.0.1 - - [10/May/2025 17:47:27] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:47:28,634 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:47:28,957 - INFO - Token usage: prompt=63, completion=19, total=82
2025-05-10 17:47:28,987 - INFO - Processing query: 'Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?' for conversation 77
2025-05-10 17:47:28,989 - INFO - Query received: Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?
2025-05-10 17:47:29,334 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6102)
2025-05-10 17:47:29,364 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:47:29,364 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:47:31,086 - INFO - Token usage: prompt=1545, completion=327, total=1872
2025-05-10 17:47:31,089 - INFO - Agent workflow completed in 2.46s
2025-05-10 17:47:31,107 - INFO - Request processed in 2.47s (thinking: 1.73s)
2025-05-10 17:47:31,108 - INFO - 127.0.0.1 - - [10/May/2025 17:47:31] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:47:32,119 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:47:32,471 - INFO - Token usage: prompt=64, completion=15, total=79
2025-05-10 17:47:32,499 - INFO - Processing query: 'Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?' for conversation 78
2025-05-10 17:47:32,500 - INFO - Query received: Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?
2025-05-10 17:47:32,835 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5187)
2025-05-10 17:47:32,862 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:47:32,862 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:47:33,020 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:47:33,020 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:47:35,139 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:47:35,139 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:47:39,296 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:47:39,296 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:47:39,297 - INFO - Agent workflow completed in 7.18s
2025-05-10 17:47:39,297 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:47:39,297 - INFO - 127.0.0.1 - - [10/May/2025 17:47:39] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:47:40,318 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:47:40,643 - INFO - Token usage: prompt=66, completion=16, total=82
2025-05-10 17:47:40,675 - INFO - Processing query: 'Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?' for conversation 79
2025-05-10 17:47:40,676 - INFO - Query received: Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?
2025-05-10 17:47:41,055 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6496)
2025-05-10 17:47:41,098 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:47:41,099 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:47:41,214 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:47:41,214 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:47:43,357 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:47:43,357 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:47:49,945 - INFO - Token usage: prompt=1808, completion=584, total=2392
2025-05-10 17:47:49,947 - INFO - Agent workflow completed in 9.63s
2025-05-10 17:47:49,974 - INFO - Request processed in 9.66s (thinking: 8.85s)
2025-05-10 17:47:49,975 - INFO - 127.0.0.1 - - [10/May/2025 17:47:49] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:47:50,998 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:47:51,521 - INFO - Token usage: prompt=63, completion=14, total=77
2025-05-10 17:47:51,550 - INFO - Processing query: 'Quelle est la durée maximale d’un droit antidumping provisoire ?' for conversation 80
2025-05-10 17:47:51,551 - INFO - Query received: Quelle est la durée maximale d’un droit antidumping provisoire ?
2025-05-10 17:47:51,898 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4843)
2025-05-10 17:47:51,930 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:47:51,930 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:47:52,452 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:47:52,452 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:47:54,585 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:47:54,585 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:47:58,709 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:47:58,710 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:47:58,710 - INFO - Agent workflow completed in 7.71s
2025-05-10 17:47:58,710 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:47:58,710 - INFO - 127.0.0.1 - - [10/May/2025 17:47:58] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:47:59,730 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:48:00,037 - INFO - Token usage: prompt=62, completion=14, total=76
2025-05-10 17:48:00,072 - INFO - Processing query: 'Comment est traité un engagement de prix de l’exportateur ?' for conversation 81
2025-05-10 17:48:00,073 - INFO - Query received: Comment est traité un engagement de prix de l’exportateur ?
2025-05-10 17:48:00,489 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4960)
2025-05-10 17:48:00,527 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:48:00,527 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:48:00,644 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:48:00,644 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:48:02,761 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:48:02,761 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:48:06,887 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:48:06,888 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:48:06,888 - INFO - Agent workflow completed in 7.16s
2025-05-10 17:48:06,888 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:48:06,889 - INFO - 127.0.0.1 - - [10/May/2025 17:48:06] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:48:07,906 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:48:08,223 - INFO - Token usage: prompt=65, completion=18, total=83
2025-05-10 17:48:08,252 - INFO - Processing query: 'Quel est le délai pour demander le remboursement de droits antidumping en excès ?' for conversation 82
2025-05-10 17:48:08,253 - INFO - Query received: Quel est le délai pour demander le remboursement de droits antidumping en excès ?
2025-05-10 17:48:08,687 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5211)
2025-05-10 17:48:08,732 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:48:08,732 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:48:11,443 - INFO - Token usage: prompt=1696, completion=652, total=2348
2025-05-10 17:48:11,446 - INFO - Agent workflow completed in 3.54s
2025-05-10 17:48:11,468 - INFO - Request processed in 3.56s (thinking: 2.72s)
2025-05-10 17:48:11,469 - INFO - 127.0.0.1 - - [10/May/2025 17:48:11] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:48:12,486 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:48:12,809 - INFO - Token usage: prompt=67, completion=18, total=85
2025-05-10 17:48:12,835 - INFO - Processing query: 'Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?' for conversation 83
2025-05-10 17:48:12,835 - INFO - Query received: Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?
2025-05-10 17:48:13,311 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3436)
2025-05-10 17:48:13,389 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:48:13,389 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:48:13,535 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:48:13,535 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:48:15,668 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:48:15,668 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:48:19,824 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:48:19,824 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:48:19,825 - INFO - Agent workflow completed in 7.34s
2025-05-10 17:48:19,825 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:48:19,826 - INFO - 127.0.0.1 - - [10/May/2025 17:48:19] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:48:20,835 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:48:21,169 - INFO - Token usage: prompt=63, completion=17, total=80
2025-05-10 17:48:21,200 - INFO - Processing query: 'Quel tribunal est compétent pour la révision judiciaire des décisions prises ?' for conversation 84
2025-05-10 17:48:21,201 - INFO - Query received: Quel tribunal est compétent pour la révision judiciaire des décisions prises ?
2025-05-10 17:48:21,544 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3625)
2025-05-10 17:48:21,580 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:48:21,581 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:48:21,707 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:48:21,707 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:48:24,294 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:48:24,294 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:48:28,431 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:48:28,431 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:48:28,432 - INFO - Agent workflow completed in 7.60s
2025-05-10 17:48:28,432 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:48:28,433 - INFO - 127.0.0.1 - - [10/May/2025 17:48:28] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:49:46,084 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:49:46,394 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 17:49:46,422 - INFO - Processing query: 'Qu'est-ce que le droit antidumping selon la loi tunisienne ?' for conversation 85
2025-05-10 17:49:46,423 - INFO - Query received: Qu'est-ce que le droit antidumping selon la loi tunisienne ?
2025-05-10 17:49:47,073 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7042)
2025-05-10 17:49:47,142 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:49:47,142 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:49:49,140 - INFO - Token usage: prompt=2238, completion=420, total=2658
2025-05-10 17:49:49,145 - INFO - Agent workflow completed in 3.06s
2025-05-10 17:49:49,165 - INFO - Request processed in 3.08s (thinking: 2.01s)
2025-05-10 17:49:49,165 - INFO - 127.0.0.1 - - [10/May/2025 17:49:49] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:49:50,193 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:49:50,562 - INFO - Token usage: prompt=62, completion=11, total=73
2025-05-10 17:49:50,586 - INFO - Processing query: 'Dans quel cas une subvention est-elle considérée comme spécifique ?' for conversation 86
2025-05-10 17:49:50,587 - INFO - Query received: Dans quel cas une subvention est-elle considérée comme spécifique ?
2025-05-10 17:49:50,948 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4032)
2025-05-10 17:49:50,986 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:49:50,987 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:49:52,737 - INFO - Token usage: prompt=1544, completion=373, total=1917
2025-05-10 17:49:52,740 - INFO - Agent workflow completed in 2.55s
2025-05-10 17:49:52,759 - INFO - Request processed in 2.57s (thinking: 1.76s)
2025-05-10 17:49:52,759 - INFO - 127.0.0.1 - - [10/May/2025 17:49:52] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:49:53,771 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:49:54,158 - INFO - Token usage: prompt=63, completion=16, total=79
2025-05-10 17:49:54,229 - INFO - Processing query: 'Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?' for conversation 87
2025-05-10 17:49:54,231 - INFO - Query received: Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?
2025-05-10 17:49:54,853 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6102)
2025-05-10 17:49:54,914 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:49:54,914 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:49:56,587 - INFO - Token usage: prompt=1545, completion=368, total=1913
2025-05-10 17:49:56,590 - INFO - Agent workflow completed in 2.82s
2025-05-10 17:49:56,609 - INFO - Request processed in 2.84s (thinking: 1.68s)
2025-05-10 17:49:56,609 - INFO - 127.0.0.1 - - [10/May/2025 17:49:56] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:49:57,633 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:49:57,958 - INFO - Token usage: prompt=64, completion=15, total=79
2025-05-10 17:49:57,986 - INFO - Processing query: 'Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?' for conversation 88
2025-05-10 17:49:57,987 - INFO - Query received: Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?
2025-05-10 17:49:58,667 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5187)
2025-05-10 17:49:58,764 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:49:58,766 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:49:58,928 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:49:58,929 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:50:01,102 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:01,102 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:50:05,213 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:05,213 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:50:05,214 - INFO - Agent workflow completed in 7.58s
2025-05-10 17:50:05,215 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:50:05,215 - INFO - 127.0.0.1 - - [10/May/2025 17:50:05] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:50:06,227 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:50:06,541 - INFO - Token usage: prompt=66, completion=16, total=82
2025-05-10 17:50:06,572 - INFO - Processing query: 'Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?' for conversation 89
2025-05-10 17:50:06,573 - INFO - Query received: Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?
2025-05-10 17:50:07,030 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6496)
2025-05-10 17:50:07,083 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:50:07,083 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:50:07,273 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:07,273 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:50:09,465 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:09,465 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:50:16,574 - INFO - Token usage: prompt=1808, completion=744, total=2552
2025-05-10 17:50:16,579 - INFO - Agent workflow completed in 10.35s
2025-05-10 17:50:16,614 - INFO - Request processed in 10.39s (thinking: 9.50s)
2025-05-10 17:50:16,615 - INFO - 127.0.0.1 - - [10/May/2025 17:50:16] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:50:17,639 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:50:17,949 - INFO - Token usage: prompt=63, completion=14, total=77
2025-05-10 17:50:17,978 - INFO - Processing query: 'Quelle est la durée maximale d’un droit antidumping provisoire ?' for conversation 90
2025-05-10 17:50:17,979 - INFO - Query received: Quelle est la durée maximale d’un droit antidumping provisoire ?
2025-05-10 17:50:18,449 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4843)
2025-05-10 17:50:18,497 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:50:18,497 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:50:18,619 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:18,621 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:50:20,749 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:20,749 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:50:24,873 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:24,873 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:50:24,874 - INFO - Agent workflow completed in 7.24s
2025-05-10 17:50:24,874 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:50:24,876 - INFO - 127.0.0.1 - - [10/May/2025 17:50:24] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:50:25,887 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:50:26,224 - INFO - Token usage: prompt=62, completion=17, total=79
2025-05-10 17:50:26,252 - INFO - Processing query: 'Comment est traité un engagement de prix de l’exportateur ?' for conversation 91
2025-05-10 17:50:26,253 - INFO - Query received: Comment est traité un engagement de prix de l’exportateur ?
2025-05-10 17:50:26,677 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4960)
2025-05-10 17:50:26,720 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:50:26,720 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:50:26,827 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:26,827 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:50:28,958 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:28,958 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:50:33,125 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:33,125 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:50:33,126 - INFO - Agent workflow completed in 7.24s
2025-05-10 17:50:33,126 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:50:33,128 - INFO - 127.0.0.1 - - [10/May/2025 17:50:33] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:50:34,143 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:50:34,470 - INFO - Token usage: prompt=65, completion=15, total=80
2025-05-10 17:50:34,503 - INFO - Processing query: 'Quel est le délai pour demander le remboursement de droits antidumping en excès ?' for conversation 92
2025-05-10 17:50:34,504 - INFO - Query received: Quel est le délai pour demander le remboursement de droits antidumping en excès ?
2025-05-10 17:50:34,971 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5211)
2025-05-10 17:50:35,018 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:50:35,018 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:50:38,519 - INFO - Token usage: prompt=1696, completion=584, total=2280
2025-05-10 17:50:38,523 - INFO - Agent workflow completed in 4.38s
2025-05-10 17:50:38,553 - INFO - Request processed in 4.41s (thinking: 3.51s)
2025-05-10 17:50:38,554 - INFO - 127.0.0.1 - - [10/May/2025 17:50:38] "POST /ask HTTP/1.1" 200 -
2025-05-10 17:50:39,593 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:50:39,923 - INFO - Token usage: prompt=67, completion=18, total=85
2025-05-10 17:50:39,957 - INFO - Processing query: 'Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?' for conversation 93
2025-05-10 17:50:39,960 - INFO - Query received: Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?
2025-05-10 17:50:40,406 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3436)
2025-05-10 17:50:40,451 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:50:40,452 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:50:40,588 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:40,588 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:50:42,715 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:42,715 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:50:46,856 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:46,856 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:50:46,857 - INFO - Agent workflow completed in 7.26s
2025-05-10 17:50:46,858 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:50:46,859 - INFO - 127.0.0.1 - - [10/May/2025 17:50:46] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 17:50:47,875 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 17:50:48,195 - INFO - Token usage: prompt=63, completion=15, total=78
2025-05-10 17:50:48,229 - INFO - Processing query: 'Quel tribunal est compétent pour la révision judiciaire des décisions prises ?' for conversation 94
2025-05-10 17:50:48,230 - INFO - Query received: Quel tribunal est compétent pour la révision judiciaire des décisions prises ?
2025-05-10 17:50:48,713 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3625)
2025-05-10 17:50:48,757 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 17:50:48,757 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 17:50:48,882 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:48,882 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 17:50:51,027 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:51,027 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 17:50:55,156 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 17:50:55,156 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 17:50:55,157 - INFO - Agent workflow completed in 7.28s
2025-05-10 17:50:55,159 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 17:50:55,161 - INFO - 127.0.0.1 - - [10/May/2025 17:50:55] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:16:06,661 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:16:07,170 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 18:16:07,195 - INFO - Processing query: 'Qu'est-ce que le droit antidumping selon la loi tunisienne ?' for conversation 95
2025-05-10 18:16:07,196 - INFO - Query received: Qu'est-ce que le droit antidumping selon la loi tunisienne ?
2025-05-10 18:16:07,623 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7042)
2025-05-10 18:16:07,667 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:16:07,667 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:16:10,136 - INFO - Token usage: prompt=2238, completion=559, total=2797
2025-05-10 18:16:10,139 - INFO - Agent workflow completed in 3.48s
2025-05-10 18:16:10,161 - INFO - Request processed in 3.50s (thinking: 2.48s)
2025-05-10 18:16:10,162 - INFO - 127.0.0.1 - - [10/May/2025 18:16:10] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:16:11,188 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:16:11,506 - INFO - Token usage: prompt=62, completion=11, total=73
2025-05-10 18:16:11,537 - INFO - Processing query: 'Dans quel cas une subvention est-elle considérée comme spécifique ?' for conversation 96
2025-05-10 18:16:11,537 - INFO - Query received: Dans quel cas une subvention est-elle considérée comme spécifique ?
2025-05-10 18:16:11,950 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4032)
2025-05-10 18:16:12,003 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:16:12,003 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:16:13,786 - INFO - Token usage: prompt=1544, completion=400, total=1944
2025-05-10 18:16:13,790 - INFO - Agent workflow completed in 2.60s
2025-05-10 18:16:13,811 - INFO - Request processed in 2.62s (thinking: 1.79s)
2025-05-10 18:16:13,812 - INFO - 127.0.0.1 - - [10/May/2025 18:16:13] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:16:14,834 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:16:15,169 - INFO - Token usage: prompt=63, completion=19, total=82
2025-05-10 18:16:15,241 - INFO - Processing query: 'Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?' for conversation 97
2025-05-10 18:16:15,242 - INFO - Query received: Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?
2025-05-10 18:16:15,658 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6102)
2025-05-10 18:16:15,701 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:16:15,701 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:16:18,230 - INFO - Token usage: prompt=1545, completion=546, total=2091
2025-05-10 18:16:18,237 - INFO - Agent workflow completed in 3.40s
2025-05-10 18:16:18,271 - INFO - Request processed in 3.44s (thinking: 2.54s)
2025-05-10 18:16:18,271 - INFO - 127.0.0.1 - - [10/May/2025 18:16:18] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:16:19,295 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:16:19,857 - INFO - Token usage: prompt=64, completion=15, total=79
2025-05-10 18:16:19,907 - INFO - Processing query: 'Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?' for conversation 98
2025-05-10 18:16:19,910 - INFO - Query received: Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?
2025-05-10 18:16:20,401 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5187)
2025-05-10 18:16:20,443 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:16:20,443 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:16:20,819 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:20,819 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:16:23,562 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:23,562 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:16:27,721 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:27,722 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:16:27,723 - INFO - Agent workflow completed in 8.43s
2025-05-10 18:16:27,723 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:16:27,725 - INFO - 127.0.0.1 - - [10/May/2025 18:16:27] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:16:28,743 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:16:29,102 - INFO - Token usage: prompt=66, completion=17, total=83
2025-05-10 18:16:29,132 - INFO - Processing query: 'Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?' for conversation 99
2025-05-10 18:16:29,132 - INFO - Query received: Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?
2025-05-10 18:16:29,577 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6496)
2025-05-10 18:16:29,624 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:16:29,625 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:16:29,766 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:29,766 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:16:31,900 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:31,900 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:16:39,388 - INFO - Token usage: prompt=1808, completion=856, total=2664
2025-05-10 18:16:39,395 - INFO - Agent workflow completed in 10.65s
2025-05-10 18:16:39,432 - INFO - Request processed in 10.69s (thinking: 9.78s)
2025-05-10 18:16:39,433 - INFO - 127.0.0.1 - - [10/May/2025 18:16:39] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:16:40,458 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:16:40,773 - INFO - Token usage: prompt=63, completion=14, total=77
2025-05-10 18:16:40,807 - INFO - Processing query: 'Quelle est la durée maximale d’un droit antidumping provisoire ?' for conversation 100
2025-05-10 18:16:40,809 - INFO - Query received: Quelle est la durée maximale d’un droit antidumping provisoire ?
2025-05-10 18:16:41,259 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4843)
2025-05-10 18:16:41,305 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:16:41,305 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:16:41,415 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:41,415 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:16:43,588 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:43,588 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:16:47,745 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:47,745 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:16:47,746 - INFO - Agent workflow completed in 7.29s
2025-05-10 18:16:47,746 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:16:47,747 - INFO - 127.0.0.1 - - [10/May/2025 18:16:47] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:16:48,755 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:16:49,121 - INFO - Token usage: prompt=62, completion=13, total=75
2025-05-10 18:16:49,154 - INFO - Processing query: 'Comment est traité un engagement de prix de l’exportateur ?' for conversation 101
2025-05-10 18:16:49,156 - INFO - Query received: Comment est traité un engagement de prix de l’exportateur ?
2025-05-10 18:16:49,616 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4960)
2025-05-10 18:16:49,654 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:16:49,654 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:16:49,804 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:49,804 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:16:52,021 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:52,021 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:16:56,193 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:56,193 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:16:56,195 - INFO - Agent workflow completed in 7.44s
2025-05-10 18:16:56,195 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:16:56,198 - INFO - 127.0.0.1 - - [10/May/2025 18:16:56] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:16:57,216 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:16:57,534 - INFO - Token usage: prompt=65, completion=15, total=80
2025-05-10 18:16:57,571 - INFO - Processing query: 'Quel est le délai pour demander le remboursement de droits antidumping en excès ?' for conversation 102
2025-05-10 18:16:57,572 - INFO - Query received: Quel est le délai pour demander le remboursement de droits antidumping en excès ?
2025-05-10 18:16:58,052 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5211)
2025-05-10 18:16:58,106 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:16:58,107 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:16:58,222 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:16:58,222 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:17:00,377 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:17:00,377 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:17:07,684 - INFO - Token usage: prompt=1696, completion=724, total=2420
2025-05-10 18:17:07,692 - INFO - Agent workflow completed in 10.48s
2025-05-10 18:17:07,734 - INFO - Request processed in 10.52s (thinking: 9.59s)
2025-05-10 18:17:07,735 - INFO - 127.0.0.1 - - [10/May/2025 18:17:07] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:17:08,768 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:17:09,100 - INFO - Token usage: prompt=67, completion=16, total=83
2025-05-10 18:17:09,133 - INFO - Processing query: 'Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?' for conversation 103
2025-05-10 18:17:09,134 - INFO - Query received: Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?
2025-05-10 18:17:09,610 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3436)
2025-05-10 18:17:09,668 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:17:09,668 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:17:09,784 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:17:09,784 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:17:11,902 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:17:11,902 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:17:16,395 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:17:16,395 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:17:16,396 - INFO - Agent workflow completed in 7.63s
2025-05-10 18:17:16,396 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:17:16,397 - INFO - 127.0.0.1 - - [10/May/2025 18:17:16] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:17:17,418 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:17:18,036 - INFO - Token usage: prompt=63, completion=19, total=82
2025-05-10 18:17:18,073 - INFO - Processing query: 'Quel tribunal est compétent pour la révision judiciaire des décisions prises ?' for conversation 104
2025-05-10 18:17:18,074 - INFO - Query received: Quel tribunal est compétent pour la révision judiciaire des décisions prises ?
2025-05-10 18:17:18,504 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3625)
2025-05-10 18:17:18,548 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:17:18,548 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:17:18,963 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:17:18,964 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:17:21,473 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:17:21,473 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:17:25,636 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:17:25,636 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:17:25,637 - INFO - Agent workflow completed in 8.22s
2025-05-10 18:17:25,637 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:17:25,639 - INFO - 127.0.0.1 - - [10/May/2025 18:17:25] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:24:41,244 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:24:41,904 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 18:24:41,933 - INFO - Processing query: 'Qu'est-ce que le droit antidumping selon la loi tunisienne ?' for conversation 105
2025-05-10 18:24:41,935 - INFO - Query received: Qu'est-ce que le droit antidumping selon la loi tunisienne ?
2025-05-10 18:24:42,293 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7042)
2025-05-10 18:24:42,332 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:24:42,332 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:24:44,867 - INFO - Token usage: prompt=2238, completion=538, total=2776
2025-05-10 18:24:44,873 - INFO - Agent workflow completed in 3.63s
2025-05-10 18:24:44,897 - INFO - Request processed in 3.65s (thinking: 2.55s)
2025-05-10 18:24:44,897 - INFO - 127.0.0.1 - - [10/May/2025 18:24:44] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:24:45,935 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:24:46,254 - INFO - Token usage: prompt=62, completion=14, total=76
2025-05-10 18:24:46,276 - INFO - Processing query: 'Dans quel cas une subvention est-elle considérée comme spécifique ?' for conversation 106
2025-05-10 18:24:46,277 - INFO - Query received: Dans quel cas une subvention est-elle considérée comme spécifique ?
2025-05-10 18:24:46,634 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4032)
2025-05-10 18:24:46,664 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:24:46,664 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:24:48,895 - INFO - Token usage: prompt=1544, completion=518, total=2062
2025-05-10 18:24:48,899 - INFO - Agent workflow completed in 2.96s
2025-05-10 18:24:48,922 - INFO - Request processed in 2.99s (thinking: 2.24s)
2025-05-10 18:24:48,923 - INFO - 127.0.0.1 - - [10/May/2025 18:24:48] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:24:49,939 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:24:50,271 - INFO - Token usage: prompt=63, completion=15, total=78
2025-05-10 18:24:50,311 - INFO - Processing query: 'Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?' for conversation 107
2025-05-10 18:24:50,312 - INFO - Query received: Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?
2025-05-10 18:24:50,801 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6102)
2025-05-10 18:24:50,852 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:24:50,852 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:24:52,235 - INFO - Token usage: prompt=1545, completion=275, total=1820
2025-05-10 18:24:52,238 - INFO - Agent workflow completed in 2.30s
2025-05-10 18:24:52,258 - INFO - Request processed in 2.32s (thinking: 1.39s)
2025-05-10 18:24:52,258 - INFO - 127.0.0.1 - - [10/May/2025 18:24:52] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:24:53,282 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:24:53,592 - INFO - Token usage: prompt=64, completion=15, total=79
2025-05-10 18:24:53,617 - INFO - Processing query: 'Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?' for conversation 108
2025-05-10 18:24:53,618 - INFO - Query received: Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?
2025-05-10 18:24:53,976 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5187)
2025-05-10 18:24:54,021 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:24:54,021 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:24:54,139 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:24:54,139 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:24:56,263 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:24:56,264 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:25:00,429 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:00,429 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:25:00,430 - INFO - Agent workflow completed in 7.15s
2025-05-10 18:25:00,431 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:25:00,432 - INFO - 127.0.0.1 - - [10/May/2025 18:25:00] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:25:01,445 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:25:01,759 - INFO - Token usage: prompt=66, completion=17, total=83
2025-05-10 18:25:01,782 - INFO - Processing query: 'Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?' for conversation 109
2025-05-10 18:25:01,783 - INFO - Query received: Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?
2025-05-10 18:25:02,161 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6496)
2025-05-10 18:25:02,198 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:25:02,198 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:25:02,332 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:02,332 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:25:04,493 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:04,494 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:25:11,797 - INFO - Token usage: prompt=1808, completion=798, total=2606
2025-05-10 18:25:11,807 - INFO - Agent workflow completed in 10.36s
2025-05-10 18:25:11,855 - INFO - Request processed in 10.41s (thinking: 9.61s)
2025-05-10 18:25:11,856 - INFO - 127.0.0.1 - - [10/May/2025 18:25:11] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:25:12,878 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:25:13,224 - INFO - Token usage: prompt=63, completion=14, total=77
2025-05-10 18:25:13,260 - INFO - Processing query: 'Quelle est la durée maximale d’un droit antidumping provisoire ?' for conversation 110
2025-05-10 18:25:13,261 - INFO - Query received: Quelle est la durée maximale d’un droit antidumping provisoire ?
2025-05-10 18:25:13,719 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4843)
2025-05-10 18:25:13,762 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:25:13,763 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:25:13,894 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:13,894 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:25:16,030 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:16,030 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:25:20,158 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:20,159 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:25:20,160 - INFO - Agent workflow completed in 7.28s
2025-05-10 18:25:20,160 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:25:20,161 - INFO - 127.0.0.1 - - [10/May/2025 18:25:20] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:25:21,171 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:25:21,487 - INFO - Token usage: prompt=62, completion=15, total=77
2025-05-10 18:25:21,553 - INFO - Processing query: 'Comment est traité un engagement de prix de l’exportateur ?' for conversation 111
2025-05-10 18:25:21,555 - INFO - Query received: Comment est traité un engagement de prix de l’exportateur ?
2025-05-10 18:25:22,052 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4960)
2025-05-10 18:25:22,099 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:25:22,099 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:25:22,261 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:22,261 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:25:24,395 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:24,395 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:25:28,583 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:28,583 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:25:28,583 - INFO - Agent workflow completed in 7.41s
2025-05-10 18:25:28,583 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:25:28,584 - INFO - 127.0.0.1 - - [10/May/2025 18:25:28] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:25:29,594 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:25:29,926 - INFO - Token usage: prompt=65, completion=19, total=84
2025-05-10 18:25:29,953 - INFO - Processing query: 'Quel est le délai pour demander le remboursement de droits antidumping en excès ?' for conversation 112
2025-05-10 18:25:29,955 - INFO - Query received: Quel est le délai pour demander le remboursement de droits antidumping en excès ?
2025-05-10 18:25:30,342 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5211)
2025-05-10 18:25:30,385 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:25:30,385 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:25:30,512 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:30,512 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:25:32,654 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:32,654 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:25:39,433 - INFO - Token usage: prompt=1696, completion=655, total=2351
2025-05-10 18:25:39,437 - INFO - Agent workflow completed in 9.84s
2025-05-10 18:25:39,473 - INFO - Request processed in 9.88s (thinking: 9.06s)
2025-05-10 18:25:39,473 - INFO - 127.0.0.1 - - [10/May/2025 18:25:39] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:25:40,493 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:25:40,806 - INFO - Token usage: prompt=67, completion=18, total=85
2025-05-10 18:25:40,841 - INFO - Processing query: 'Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?' for conversation 113
2025-05-10 18:25:40,843 - INFO - Query received: Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?
2025-05-10 18:25:41,249 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3436)
2025-05-10 18:25:41,289 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:25:41,289 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:25:41,408 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:41,408 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:25:43,575 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:43,575 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:25:47,729 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:47,729 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:25:47,729 - INFO - Agent workflow completed in 7.24s
2025-05-10 18:25:47,730 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:25:47,730 - INFO - 127.0.0.1 - - [10/May/2025 18:25:47] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:25:48,743 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:25:49,421 - INFO - Token usage: prompt=63, completion=15, total=78
2025-05-10 18:25:49,454 - INFO - Processing query: 'Quel tribunal est compétent pour la révision judiciaire des décisions prises ?' for conversation 114
2025-05-10 18:25:49,455 - INFO - Query received: Quel tribunal est compétent pour la révision judiciaire des décisions prises ?
2025-05-10 18:25:49,904 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3625)
2025-05-10 18:25:49,948 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:25:49,948 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:25:50,588 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:50,589 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:25:53,090 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:53,091 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:25:57,231 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:25:57,231 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:25:57,233 - INFO - Agent workflow completed in 8.49s
2025-05-10 18:25:57,233 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:25:57,235 - INFO - 127.0.0.1 - - [10/May/2025 18:25:57] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:34:26,014 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:34:26,402 - INFO - Token usage: prompt=67, completion=12, total=79
2025-05-10 18:34:26,432 - INFO - Processing query: 'Qu'est-ce que le droit antidumping selon la loi tunisienne ?' for conversation 115
2025-05-10 18:34:26,433 - INFO - Query received: Qu'est-ce que le droit antidumping selon la loi tunisienne ?
2025-05-10 18:34:26,844 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7042)
2025-05-10 18:34:26,908 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:34:26,908 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:34:29,122 - INFO - Token usage: prompt=2238, completion=452, total=2690
2025-05-10 18:34:29,125 - INFO - Agent workflow completed in 3.11s
2025-05-10 18:34:29,147 - INFO - Request processed in 3.13s (thinking: 2.22s)
2025-05-10 18:34:29,147 - INFO - 127.0.0.1 - - [10/May/2025 18:34:29] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:34:39,185 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:34:39,509 - INFO - Token usage: prompt=62, completion=12, total=74
2025-05-10 18:34:39,540 - INFO - Processing query: 'Dans quel cas une subvention est-elle considérée comme spécifique ?' for conversation 116
2025-05-10 18:34:39,541 - INFO - Query received: Dans quel cas une subvention est-elle considérée comme spécifique ?
2025-05-10 18:34:39,916 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4032)
2025-05-10 18:34:39,947 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:34:39,948 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:34:42,082 - INFO - Token usage: prompt=1544, completion=490, total=2034
2025-05-10 18:34:42,087 - INFO - Agent workflow completed in 2.90s
2025-05-10 18:34:42,106 - INFO - Request processed in 2.92s (thinking: 2.14s)
2025-05-10 18:34:42,107 - INFO - 127.0.0.1 - - [10/May/2025 18:34:42] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:34:52,125 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:34:52,433 - INFO - Token usage: prompt=63, completion=16, total=79
2025-05-10 18:34:52,463 - INFO - Processing query: 'Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?' for conversation 117
2025-05-10 18:34:52,464 - INFO - Query received: Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?
2025-05-10 18:34:52,816 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6102)
2025-05-10 18:34:52,847 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:34:52,847 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:34:55,836 - INFO - Token usage: prompt=1545, completion=730, total=2275
2025-05-10 18:34:55,838 - INFO - Agent workflow completed in 3.71s
2025-05-10 18:34:55,871 - INFO - Request processed in 3.75s (thinking: 2.99s)
2025-05-10 18:34:55,871 - INFO - 127.0.0.1 - - [10/May/2025 18:34:55] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:35:05,893 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:35:06,221 - INFO - Token usage: prompt=64, completion=15, total=79
2025-05-10 18:35:06,254 - INFO - Processing query: 'Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?' for conversation 118
2025-05-10 18:35:06,255 - INFO - Query received: Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?
2025-05-10 18:35:06,612 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5187)
2025-05-10 18:35:06,645 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:35:06,645 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:35:08,737 - INFO - Token usage: prompt=1547, completion=445, total=1992
2025-05-10 18:35:08,740 - INFO - Agent workflow completed in 2.85s
2025-05-10 18:35:08,758 - INFO - Request processed in 2.86s (thinking: 2.10s)
2025-05-10 18:35:08,759 - INFO - 127.0.0.1 - - [10/May/2025 18:35:08] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:35:18,786 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:35:19,164 - INFO - Token usage: prompt=66, completion=13, total=79
2025-05-10 18:35:19,192 - INFO - Processing query: 'Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?' for conversation 119
2025-05-10 18:35:19,193 - INFO - Query received: Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?
2025-05-10 18:35:19,549 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6496)
2025-05-10 18:35:19,585 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:35:19,585 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:35:22,765 - INFO - Token usage: prompt=1808, completion=731, total=2539
2025-05-10 18:35:22,767 - INFO - Agent workflow completed in 3.98s
2025-05-10 18:35:22,799 - INFO - Request processed in 4.01s (thinking: 3.19s)
2025-05-10 18:35:22,800 - INFO - 127.0.0.1 - - [10/May/2025 18:35:22] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:35:32,830 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:35:33,205 - INFO - Token usage: prompt=63, completion=14, total=77
2025-05-10 18:35:33,240 - INFO - Processing query: 'Quelle est la durée maximale d’un droit antidumping provisoire ?' for conversation 120
2025-05-10 18:35:33,241 - INFO - Query received: Quelle est la durée maximale d’un droit antidumping provisoire ?
2025-05-10 18:35:33,613 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4843)
2025-05-10 18:35:33,646 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:35:33,646 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:35:33,785 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:35:33,785 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:35:35,902 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:35:35,902 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:35:40,145 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:35:40,145 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:35:40,146 - INFO - Agent workflow completed in 7.32s
2025-05-10 18:35:40,146 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:35:40,146 - INFO - 127.0.0.1 - - [10/May/2025 18:35:40] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:35:43,173 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:35:43,531 - INFO - Token usage: prompt=63, completion=14, total=77
2025-05-10 18:35:43,559 - INFO - Processing query: 'Quelle est la durée maximale d’un droit antidumping provisoire ?' for conversation 121
2025-05-10 18:35:43,559 - INFO - Query received: Quelle est la durée maximale d’un droit antidumping provisoire ?
2025-05-10 18:35:43,923 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4843)
2025-05-10 18:35:43,957 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:35:43,957 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:35:44,081 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:35:44,081 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:35:48,799 - INFO - Token usage: prompt=2315, completion=559, total=2874
2025-05-10 18:35:48,804 - INFO - Agent workflow completed in 5.63s
2025-05-10 18:35:48,825 - INFO - Request processed in 5.65s (thinking: 4.85s)
2025-05-10 18:35:48,826 - INFO - 127.0.0.1 - - [10/May/2025 18:35:48] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:35:58,860 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:35:59,220 - INFO - Token usage: prompt=62, completion=13, total=75
2025-05-10 18:35:59,247 - INFO - Processing query: 'Comment est traité un engagement de prix de l’exportateur ?' for conversation 122
2025-05-10 18:35:59,249 - INFO - Query received: Comment est traité un engagement de prix de l’exportateur ?
2025-05-10 18:35:59,589 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4960)
2025-05-10 18:35:59,617 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:35:59,617 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:35:59,735 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:35:59,736 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:36:01,882 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:36:01,882 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:36:06,017 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:36:06,017 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:36:06,019 - INFO - Agent workflow completed in 7.16s
2025-05-10 18:36:06,020 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:36:06,021 - INFO - 127.0.0.1 - - [10/May/2025 18:36:06] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:36:09,043 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:36:09,672 - INFO - Token usage: prompt=62, completion=13, total=75
2025-05-10 18:36:09,698 - INFO - Processing query: 'Comment est traité un engagement de prix de l’exportateur ?' for conversation 123
2025-05-10 18:36:09,699 - INFO - Query received: Comment est traité un engagement de prix de l’exportateur ?
2025-05-10 18:36:10,059 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4960)
2025-05-10 18:36:10,089 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:36:10,089 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:36:14,114 - INFO - Token usage: prompt=1624, completion=946, total=2570
2025-05-10 18:36:14,118 - INFO - Agent workflow completed in 5.07s
2025-05-10 18:36:14,163 - INFO - Request processed in 5.12s (thinking: 4.03s)
2025-05-10 18:36:14,164 - INFO - 127.0.0.1 - - [10/May/2025 18:36:14] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:36:24,189 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:36:24,524 - INFO - Token usage: prompt=65, completion=15, total=80
2025-05-10 18:36:24,555 - INFO - Processing query: 'Quel est le délai pour demander le remboursement de droits antidumping en excès ?' for conversation 124
2025-05-10 18:36:24,556 - INFO - Query received: Quel est le délai pour demander le remboursement de droits antidumping en excès ?
2025-05-10 18:36:24,957 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5211)
2025-05-10 18:36:24,995 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:36:24,995 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:36:25,181 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:36:25,181 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:36:27,369 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:36:27,369 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:36:31,496 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:36:31,496 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:36:31,497 - INFO - Agent workflow completed in 7.31s
2025-05-10 18:36:31,498 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:36:31,498 - INFO - 127.0.0.1 - - [10/May/2025 18:36:31] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:36:34,511 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:36:34,848 - INFO - Token usage: prompt=65, completion=15, total=80
2025-05-10 18:36:34,880 - INFO - Processing query: 'Quel est le délai pour demander le remboursement de droits antidumping en excès ?' for conversation 125
2025-05-10 18:36:34,881 - INFO - Query received: Quel est le délai pour demander le remboursement de droits antidumping en excès ?
2025-05-10 18:36:35,257 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5211)
2025-05-10 18:36:35,295 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:36:35,295 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:36:38,337 - INFO - Token usage: prompt=1696, completion=735, total=2431
2025-05-10 18:36:38,339 - INFO - Agent workflow completed in 3.83s
2025-05-10 18:36:38,361 - INFO - Request processed in 3.85s (thinking: 3.05s)
2025-05-10 18:36:38,361 - INFO - 127.0.0.1 - - [10/May/2025 18:36:38] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:36:48,400 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:36:48,713 - INFO - Token usage: prompt=67, completion=18, total=85
2025-05-10 18:36:48,744 - INFO - Processing query: 'Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?' for conversation 126
2025-05-10 18:36:48,745 - INFO - Query received: Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?
2025-05-10 18:36:49,257 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3436)
2025-05-10 18:36:49,300 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:36:49,300 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:36:49,702 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:36:49,702 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:36:51,859 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:36:51,859 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:36:56,019 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:36:56,019 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:36:56,020 - INFO - Agent workflow completed in 7.62s
2025-05-10 18:36:56,021 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:36:56,023 - INFO - 127.0.0.1 - - [10/May/2025 18:36:56] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:36:59,041 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:36:59,373 - INFO - Token usage: prompt=67, completion=18, total=85
2025-05-10 18:36:59,414 - INFO - Processing query: 'Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?' for conversation 127
2025-05-10 18:36:59,416 - INFO - Query received: Quelles sont les conséquences en cas de retrait ou de violation d’un engagement de prix ?
2025-05-10 18:36:59,902 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3436)
2025-05-10 18:36:59,949 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:36:59,949 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:37:03,351 - INFO - Token usage: prompt=1549, completion=601, total=2150
2025-05-10 18:37:03,355 - INFO - Agent workflow completed in 4.31s
2025-05-10 18:37:03,386 - INFO - Request processed in 4.34s (thinking: 3.41s)
2025-05-10 18:37:03,387 - INFO - 127.0.0.1 - - [10/May/2025 18:37:03] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:37:13,422 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:37:13,832 - INFO - Token usage: prompt=63, completion=17, total=80
2025-05-10 18:37:13,861 - INFO - Processing query: 'Quel tribunal est compétent pour la révision judiciaire des décisions prises ?' for conversation 128
2025-05-10 18:37:13,862 - INFO - Query received: Quel tribunal est compétent pour la révision judiciaire des décisions prises ?
2025-05-10 18:37:14,320 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3625)
2025-05-10 18:37:14,372 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:37:14,372 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:37:14,669 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:37:14,669 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:37:16,815 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:37:16,815 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:37:20,952 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:37:20,953 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:37:20,954 - INFO - Agent workflow completed in 7.53s
2025-05-10 18:37:20,954 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:37:20,955 - INFO - 127.0.0.1 - - [10/May/2025 18:37:20] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:37:23,987 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:37:24,633 - INFO - Token usage: prompt=63, completion=14, total=77
2025-05-10 18:37:24,662 - INFO - Processing query: 'Quel tribunal est compétent pour la révision judiciaire des décisions prises ?' for conversation 129
2025-05-10 18:37:24,663 - INFO - Query received: Quel tribunal est compétent pour la révision judiciaire des décisions prises ?
2025-05-10 18:37:25,106 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3625)
2025-05-10 18:37:25,141 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:37:25,141 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:37:25,542 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:37:25,542 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:37:30,372 - INFO - Token usage: prompt=2418, completion=456, total=2874
2025-05-10 18:37:30,375 - INFO - Agent workflow completed in 6.39s
2025-05-10 18:37:30,397 - INFO - Request processed in 6.41s (thinking: 5.24s)
2025-05-10 18:37:30,398 - INFO - 127.0.0.1 - - [10/May/2025 18:37:30] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:51:08,051 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:51:08,484 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 18:51:08,515 - INFO - Processing query: 'Qu'est-ce que le droit antidumping selon la loi tunisienne ?' for conversation 130
2025-05-10 18:51:08,516 - INFO - Query received: Qu'est-ce que le droit antidumping selon la loi tunisienne ?
2025-05-10 18:51:08,934 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7042)
2025-05-10 18:51:08,967 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:51:08,967 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:51:11,086 - INFO - Token usage: prompt=2238, completion=474, total=2712
2025-05-10 18:51:11,090 - INFO - Agent workflow completed in 3.04s
2025-05-10 18:51:11,109 - INFO - Request processed in 3.06s (thinking: 2.13s)
2025-05-10 18:51:11,109 - INFO - 127.0.0.1 - - [10/May/2025 18:51:11] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:52:56,915 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:52:57,299 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 18:52:57,337 - INFO - Processing query: 'Qu'est-ce que le droit antidumping selon la loi tunisienne ?' for conversation 131
2025-05-10 18:52:57,338 - INFO - Query received: Qu'est-ce que le droit antidumping selon la loi tunisienne ?
2025-05-10 18:52:57,841 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7042)
2025-05-10 18:52:57,908 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:52:57,908 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:52:59,694 - INFO - Token usage: prompt=2238, completion=368, total=2606
2025-05-10 18:52:59,700 - INFO - Agent workflow completed in 2.78s
2025-05-10 18:52:59,719 - INFO - Request processed in 2.80s (thinking: 1.80s)
2025-05-10 18:52:59,721 - INFO - 127.0.0.1 - - [10/May/2025 18:52:59] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:53:09,759 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:53:10,079 - INFO - Token usage: prompt=62, completion=12, total=74
2025-05-10 18:53:10,109 - INFO - Processing query: 'Dans quel cas une subvention est-elle considérée comme spécifique ?' for conversation 132
2025-05-10 18:53:10,110 - INFO - Query received: Dans quel cas une subvention est-elle considérée comme spécifique ?
2025-05-10 18:53:10,601 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4032)
2025-05-10 18:53:10,643 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:53:10,644 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:53:12,397 - INFO - Token usage: prompt=1544, completion=384, total=1928
2025-05-10 18:53:12,403 - INFO - Agent workflow completed in 2.64s
2025-05-10 18:53:12,431 - INFO - Request processed in 2.67s (thinking: 1.76s)
2025-05-10 18:53:12,431 - INFO - 127.0.0.1 - - [10/May/2025 18:53:12] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:53:22,469 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:53:22,924 - INFO - Token usage: prompt=63, completion=19, total=82
2025-05-10 18:53:22,990 - INFO - Processing query: 'Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?' for conversation 133
2025-05-10 18:53:22,994 - INFO - Query received: Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?
2025-05-10 18:53:27,433 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6102)
2025-05-10 18:53:27,777 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:53:27,780 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:53:29,160 - INFO - Token usage: prompt=1545, completion=286, total=1831
2025-05-10 18:53:29,173 - INFO - Agent workflow completed in 6.70s
2025-05-10 18:53:29,209 - INFO - Request processed in 6.74s (thinking: 1.45s)
2025-05-10 18:53:29,211 - INFO - 127.0.0.1 - - [10/May/2025 18:53:29] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:53:39,238 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:53:39,901 - INFO - Token usage: prompt=64, completion=15, total=79
2025-05-10 18:53:39,939 - INFO - Processing query: 'Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?' for conversation 134
2025-05-10 18:53:39,941 - INFO - Query received: Quelle est la durée maximale d’une enquête sur le dumping en Tunisie ?
2025-05-10 18:53:41,705 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5187)
2025-05-10 18:53:41,826 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:53:41,827 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:53:43,850 - INFO - Token usage: prompt=1547, completion=460, total=2007
2025-05-10 18:53:43,860 - INFO - Agent workflow completed in 4.62s
2025-05-10 18:53:43,891 - INFO - Request processed in 4.65s (thinking: 2.04s)
2025-05-10 18:53:43,891 - INFO - 127.0.0.1 - - [10/May/2025 18:53:43] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:53:53,936 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:53:54,249 - INFO - Token usage: prompt=66, completion=16, total=82
2025-05-10 18:53:54,274 - INFO - Processing query: 'Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?' for conversation 135
2025-05-10 18:53:54,274 - INFO - Query received: Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?
2025-05-10 18:53:55,044 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6496)
2025-05-10 18:53:55,126 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:53:55,126 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:53:58,279 - INFO - Token usage: prompt=1808, completion=760, total=2568
2025-05-10 18:53:58,283 - INFO - Agent workflow completed in 4.35s
2025-05-10 18:53:58,312 - INFO - Request processed in 4.38s (thinking: 3.16s)
2025-05-10 18:53:58,312 - INFO - 127.0.0.1 - - [10/May/2025 18:53:58] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:57:01,884 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:57:02,199 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 18:57:02,231 - INFO - Processing query: 'Qu'est-ce que le droit antidumping selon la loi tunisienne ?' for conversation 136
2025-05-10 18:57:02,232 - INFO - Query received: Qu'est-ce que le droit antidumping selon la loi tunisienne ?
2025-05-10 18:57:02,741 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7042)
2025-05-10 18:57:02,828 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:57:02,828 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:57:05,661 - INFO - Token usage: prompt=2238, completion=393, total=2631
2025-05-10 18:57:05,664 - INFO - Agent workflow completed in 3.78s
2025-05-10 18:57:05,694 - INFO - Request processed in 3.81s (thinking: 2.84s)
2025-05-10 18:57:05,695 - INFO - 127.0.0.1 - - [10/May/2025 18:57:05] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:57:15,731 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:57:16,209 - INFO - Token usage: prompt=62, completion=10, total=72
2025-05-10 18:57:16,237 - INFO - Processing query: 'Dans quel cas une subvention est-elle considérée comme spécifique ?' for conversation 137
2025-05-10 18:57:16,238 - INFO - Query received: Dans quel cas une subvention est-elle considérée comme spécifique ?
2025-05-10 18:57:16,637 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4032)
2025-05-10 18:57:16,674 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:57:16,674 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:57:18,774 - INFO - Token usage: prompt=1544, completion=419, total=1963
2025-05-10 18:57:18,777 - INFO - Agent workflow completed in 3.05s
2025-05-10 18:57:18,806 - INFO - Request processed in 3.08s (thinking: 2.11s)
2025-05-10 18:57:18,807 - INFO - 127.0.0.1 - - [10/May/2025 18:57:18] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:57:28,835 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:57:29,189 - INFO - Token usage: prompt=63, completion=19, total=82
2025-05-10 18:57:29,216 - INFO - Processing query: 'Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?' for conversation 138
2025-05-10 18:57:29,216 - INFO - Query received: Qui peut initier une enquête sur les pratiques de dumping en Tunisie ?
2025-05-10 18:57:29,559 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6102)
2025-05-10 18:57:29,594 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:57:29,594 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:57:30,945 - INFO - Token usage: prompt=1545, completion=277, total=1822
2025-05-10 18:57:30,948 - INFO - Agent workflow completed in 2.11s
2025-05-10 18:57:30,968 - INFO - Request processed in 2.13s (thinking: 1.36s)
2025-05-10 18:57:30,969 - INFO - 127.0.0.1 - - [10/May/2025 18:57:30] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:57:40,991 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:57:41,298 - INFO - Token usage: prompt=64, completion=15, total=79
2025-05-10 18:57:41,326 - INFO - Processing query: 'Quelle est la durée maximale d'une enquête sur le dumping en Tunisie ?' for conversation 139
2025-05-10 18:57:41,327 - INFO - Query received: Quelle est la durée maximale d'une enquête sur le dumping en Tunisie ?
2025-05-10 18:57:41,771 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5081)
2025-05-10 18:57:41,829 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:57:41,830 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:57:43,944 - INFO - Token usage: prompt=1547, completion=484, total=2031
2025-05-10 18:57:43,946 - INFO - Agent workflow completed in 2.95s
2025-05-10 18:57:43,967 - INFO - Request processed in 2.98s (thinking: 2.12s)
2025-05-10 18:57:43,968 - INFO - 127.0.0.1 - - [10/May/2025 18:57:43] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:57:54,004 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:57:55,334 - INFO - Token usage: prompt=66, completion=17, total=83
2025-05-10 18:57:55,364 - INFO - Processing query: 'Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?' for conversation 140
2025-05-10 18:57:55,365 - INFO - Query received: Quelles conditions doivent être remplies pour instituer des droits antidumping provisoires ?
2025-05-10 18:57:55,755 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6496)
2025-05-10 18:57:55,796 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:57:55,797 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:57:59,169 - INFO - Token usage: prompt=1808, completion=794, total=2602
2025-05-10 18:57:59,173 - INFO - Agent workflow completed in 5.17s
2025-05-10 18:57:59,243 - INFO - Request processed in 5.24s (thinking: 3.38s)
2025-05-10 18:57:59,244 - INFO - 127.0.0.1 - - [10/May/2025 18:57:59] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:58:09,275 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:58:09,590 - INFO - Token usage: prompt=63, completion=14, total=77
2025-05-10 18:58:09,621 - INFO - Processing query: 'Quelle est la durée maximale d'un droit antidumping provisoire ?' for conversation 141
2025-05-10 18:58:09,621 - INFO - Query received: Quelle est la durée maximale d'un droit antidumping provisoire ?
2025-05-10 18:58:10,039 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4791)
2025-05-10 18:58:10,105 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:58:10,106 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:58:10,623 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:58:10,623 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:58:12,794 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:58:12,794 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:58:16,959 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:58:16,959 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:58:16,959 - INFO - Agent workflow completed in 7.68s
2025-05-10 18:58:16,960 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:58:16,961 - INFO - 127.0.0.1 - - [10/May/2025 18:58:16] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:58:19,975 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:58:20,293 - INFO - Token usage: prompt=63, completion=14, total=77
2025-05-10 18:58:20,322 - INFO - Processing query: 'Quelle est la durée maximale d'un droit antidumping provisoire ?' for conversation 142
2025-05-10 18:58:20,324 - INFO - Query received: Quelle est la durée maximale d'un droit antidumping provisoire ?
2025-05-10 18:58:21,131 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4791)
2025-05-10 18:58:21,234 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:58:21,234 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:58:23,325 - INFO - Token usage: prompt=2366, completion=435, total=2801
2025-05-10 18:58:23,327 - INFO - Agent workflow completed in 3.35s
2025-05-10 18:58:23,349 - INFO - Request processed in 3.37s (thinking: 2.11s)
2025-05-10 18:58:23,350 - INFO - 127.0.0.1 - - [10/May/2025 18:58:23] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:58:33,378 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:58:33,690 - INFO - Token usage: prompt=62, completion=12, total=74
2025-05-10 18:58:33,717 - INFO - Processing query: 'Comment est traité un engagement de prix de l'exportateur ?' for conversation 143
2025-05-10 18:58:33,718 - INFO - Query received: Comment est traité un engagement de prix de l'exportateur ?
2025-05-10 18:58:34,114 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4871)
2025-05-10 18:58:34,150 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:58:34,150 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:58:34,312 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:58:34,312 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:58:36,491 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:58:36,491 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:58:44,035 - INFO - Token usage: prompt=1624, completion=858, total=2482
2025-05-10 18:58:44,039 - INFO - Agent workflow completed in 10.66s
2025-05-10 18:58:44,076 - INFO - Request processed in 10.70s (thinking: 9.89s)
2025-05-10 18:58:44,077 - INFO - 127.0.0.1 - - [10/May/2025 18:58:44] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:58:54,108 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:58:54,633 - INFO - Token usage: prompt=65, completion=15, total=80
2025-05-10 18:58:54,660 - INFO - Processing query: 'Quel est le délai pour demander le remboursement de droits antidumping en excès ?' for conversation 144
2025-05-10 18:58:54,661 - INFO - Query received: Quel est le délai pour demander le remboursement de droits antidumping en excès ?
2025-05-10 18:58:55,062 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5211)
2025-05-10 18:58:55,118 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:58:55,119 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:58:55,545 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:58:55,546 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:58:57,697 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:58:57,697 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:59:01,852 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:59:01,853 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:59:01,855 - INFO - Agent workflow completed in 7.75s
2025-05-10 18:59:01,855 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:59:01,856 - INFO - 127.0.0.1 - - [10/May/2025 18:59:01] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:59:04,872 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:59:05,177 - INFO - Token usage: prompt=65, completion=15, total=80
2025-05-10 18:59:05,209 - INFO - Processing query: 'Quel est le délai pour demander le remboursement de droits antidumping en excès ?' for conversation 145
2025-05-10 18:59:05,210 - INFO - Query received: Quel est le délai pour demander le remboursement de droits antidumping en excès ?
2025-05-10 18:59:05,704 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5211)
2025-05-10 18:59:05,843 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:59:05,844 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:59:08,589 - INFO - Token usage: prompt=1696, completion=651, total=2347
2025-05-10 18:59:08,592 - INFO - Agent workflow completed in 3.72s
2025-05-10 18:59:08,615 - INFO - Request processed in 3.74s (thinking: 2.76s)
2025-05-10 18:59:08,616 - INFO - 127.0.0.1 - - [10/May/2025 18:59:08] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:59:18,648 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:59:18,962 - INFO - Token usage: prompt=67, completion=18, total=85
2025-05-10 18:59:18,987 - INFO - Processing query: 'Quelles sont les conséquences en cas de retrait ou de violation d'un engagement de prix ?' for conversation 146
2025-05-10 18:59:18,988 - INFO - Query received: Quelles sont les conséquences en cas de retrait ou de violation d'un engagement de prix ?
2025-05-10 18:59:19,443 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3369)
2025-05-10 18:59:19,516 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:59:19,516 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:59:19,977 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:59:19,977 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:59:23,511 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:59:23,511 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:59:29,666 - INFO - Token usage: prompt=1549, completion=454, total=2003
2025-05-10 18:59:29,670 - INFO - Agent workflow completed in 11.02s
2025-05-10 18:59:29,693 - INFO - Request processed in 11.04s (thinking: 10.16s)
2025-05-10 18:59:29,694 - INFO - 127.0.0.1 - - [10/May/2025 18:59:29] "POST /ask HTTP/1.1" 200 -
2025-05-10 18:59:39,719 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:59:40,047 - INFO - Token usage: prompt=63, completion=16, total=79
2025-05-10 18:59:40,074 - INFO - Processing query: 'Quel tribunal est compétent pour la révision judiciaire des décisions prises ?' for conversation 147
2025-05-10 18:59:40,074 - INFO - Query received: Quel tribunal est compétent pour la révision judiciaire des décisions prises ?
2025-05-10 18:59:40,466 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3625)
2025-05-10 18:59:40,506 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 18:59:40,506 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 18:59:48,499 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:59:48,499 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 18:59:51,051 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:59:51,051 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 18:59:55,238 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 18:59:55,238 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 18:59:55,239 - INFO - Agent workflow completed in 15.52s
2025-05-10 18:59:55,239 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 18:59:55,241 - INFO - 127.0.0.1 - - [10/May/2025 18:59:55] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 18:59:58,272 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 18:59:59,612 - INFO - Token usage: prompt=63, completion=16, total=79
2025-05-10 18:59:59,640 - INFO - Processing query: 'Quel tribunal est compétent pour la révision judiciaire des décisions prises ?' for conversation 148
2025-05-10 18:59:59,641 - INFO - Query received: Quel tribunal est compétent pour la révision judiciaire des décisions prises ?
2025-05-10 19:00:00,125 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3625)
2025-05-10 19:00:00,201 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 19:00:00,202 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 19:00:03,204 - INFO - Token usage: prompt=2418, completion=527, total=2945
2025-05-10 19:00:03,208 - INFO - Agent workflow completed in 4.94s
2025-05-10 19:00:03,234 - INFO - Request processed in 4.96s (thinking: 3.01s)
2025-05-10 19:00:03,235 - INFO - 127.0.0.1 - - [10/May/2025 19:00:03] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:03:36,103 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:03:36,590 - INFO - Token usage: prompt=91, completion=20, total=111
2025-05-10 21:03:36,622 - INFO - Processing query: 'Dans quel délai un importateur peut-il demander le remboursement des droits perçus en dépassement de la marge de dumping ou du montant réel de la subvention, selon la législation tunisienne ?' for conversation 149
2025-05-10 21:03:36,629 - INFO - Query received: Dans quel délai un importateur peut-il demander le remboursement des droits perçus en dépassement de la marge de dumping ou du montant réel de la subvention, selon la législation tunisienne ?
2025-05-10 21:03:37,240 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.6574)
2025-05-10 21:03:37,366 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:03:37,366 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:03:39,412 - INFO - Token usage: prompt=2458, completion=425, total=2883
2025-05-10 21:03:39,421 - INFO - Agent workflow completed in 3.32s
2025-05-10 21:03:39,453 - INFO - Request processed in 3.35s (thinking: 2.06s)
2025-05-10 21:03:39,455 - INFO - 127.0.0.1 - - [10/May/2025 21:03:39] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:03:49,586 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:03:50,518 - INFO - Token usage: prompt=83, completion=19, total=102
2025-05-10 21:03:50,566 - INFO - Processing query: 'Selon la législation tunisienne, quelles obligations peuvent être imposées aux exportateurs après l'acceptation d'un engagement en matière de prix ou de subvention ?' for conversation 150
2025-05-10 21:03:50,568 - INFO - Query received: Selon la législation tunisienne, quelles obligations peuvent être imposées aux exportateurs après l'acceptation d'un engagement en matière de prix ou de subvention ?
2025-05-10 21:03:51,011 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.6779)
2025-05-10 21:03:51,064 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:03:51,066 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:03:58,761 - INFO - Token usage: prompt=2501, completion=1066, total=3567
2025-05-10 21:03:58,772 - INFO - Agent workflow completed in 9.19s
2025-05-10 21:03:58,886 - INFO - Request processed in 9.30s (thinking: 7.71s)
2025-05-10 21:03:58,888 - INFO - 127.0.0.1 - - [10/May/2025 21:03:58] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:04:08,940 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:04:10,544 - INFO - Token usage: prompt=85, completion=25, total=110
2025-05-10 21:04:10,590 - INFO - Processing query: 'Dans quelles conditions un droit antidumping ou un droit compensateur définitif peut-il être institué en Tunisie, et comment son montant est-il déterminé selon la loi ?' for conversation 151
2025-05-10 21:04:10,594 - INFO - Query received: Dans quelles conditions un droit antidumping ou un droit compensateur définitif peut-il être institué en Tunisie, et comment son montant est-il déterminé selon la loi ?
2025-05-10 21:04:11,765 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6831)
2025-05-10 21:04:11,891 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:04:11,891 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:04:14,075 - INFO - Token usage: prompt=1567, completion=403, total=1970
2025-05-10 21:04:14,084 - INFO - Agent workflow completed in 5.14s
2025-05-10 21:04:14,126 - INFO - Request processed in 5.19s (thinking: 2.20s)
2025-05-10 21:04:14,129 - INFO - 127.0.0.1 - - [10/May/2025 21:04:14] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:04:24,184 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:04:24,569 - INFO - Token usage: prompt=81, completion=17, total=98
2025-05-10 21:04:24,618 - INFO - Processing query: 'Quelles sont les conditions requises pour qu'un engagement en matière de prix soit accepté dans le cadre d'une enquête pour dumping ou subvention en Tunisie ?' for conversation 152
2025-05-10 21:04:24,620 - INFO - Query received: Quelles sont les conditions requises pour qu'un engagement en matière de prix soit accepté dans le cadre d'une enquête pour dumping ou subvention en Tunisie ?
2025-05-10 21:04:25,811 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6418)
2025-05-10 21:04:25,944 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:04:25,945 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:04:31,941 - INFO - Token usage: prompt=1563, completion=995, total=2558
2025-05-10 21:04:31,951 - INFO - Agent workflow completed in 7.77s
2025-05-10 21:04:32,076 - INFO - Request processed in 7.89s (thinking: 6.02s)
2025-05-10 21:04:32,078 - INFO - 127.0.0.1 - - [10/May/2025 21:04:32] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:04:42,170 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:04:43,597 - INFO - Token usage: prompt=97, completion=14, total=111
2025-05-10 21:04:43,648 - INFO - Processing query: 'Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?' for conversation 153
2025-05-10 21:04:43,651 - INFO - Query received: Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?
2025-05-10 21:04:44,835 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7009)
2025-05-10 21:04:44,990 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:04:44,990 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:04:45,877 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:04:45,877 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:04:48,164 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:04:48,166 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:04:52,373 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:04:52,373 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:04:52,375 - INFO - Agent workflow completed in 10.20s
2025-05-10 21:04:52,375 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:04:52,379 - INFO - 127.0.0.1 - - [10/May/2025 21:04:52] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:04:55,408 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:04:56,209 - INFO - Token usage: prompt=97, completion=26, total=123
2025-05-10 21:04:56,258 - INFO - Processing query: 'Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?' for conversation 154
2025-05-10 21:04:56,261 - INFO - Query received: Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?
2025-05-10 21:04:57,475 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7009)
2025-05-10 21:04:57,631 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:04:57,632 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:05:05,730 - INFO - Token usage: prompt=2519, completion=1094, total=3613
2025-05-10 21:05:05,740 - INFO - Agent workflow completed in 10.33s
2025-05-10 21:05:05,897 - INFO - Request processed in 10.49s (thinking: 8.12s)
2025-05-10 21:05:05,899 - INFO - 127.0.0.1 - - [10/May/2025 21:05:05] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:05:16,014 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:05:16,380 - INFO - Token usage: prompt=81, completion=18, total=99
2025-05-10 21:05:16,430 - INFO - Processing query: 'Quels sont les recours juridiques possibles pour contester les décisions prises dans le cadre des procédures antidumping ou de subvention, selon la législation tunisienne ?' for conversation 155
2025-05-10 21:05:16,433 - INFO - Query received: Quels sont les recours juridiques possibles pour contester les décisions prises dans le cadre des procédures antidumping ou de subvention, selon la législation tunisienne ?
2025-05-10 21:05:17,660 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.7332)
2025-05-10 21:05:17,805 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:05:17,806 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:05:17,943 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:05:17,943 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:05:20,400 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:05:20,400 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:05:31,847 - INFO - Token usage: prompt=1570, completion=901, total=2471
2025-05-10 21:05:31,857 - INFO - Agent workflow completed in 15.84s
2025-05-10 21:05:31,939 - INFO - Request processed in 15.93s (thinking: 14.06s)
2025-05-10 21:05:31,941 - INFO - 127.0.0.1 - - [10/May/2025 21:05:31] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:05:42,034 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:05:43,107 - INFO - Token usage: prompt=79, completion=29, total=108
2025-05-10 21:05:43,158 - INFO - Processing query: 'Quelles dispositions légales antérieures sont abrogées par la loi tunisienne relative à la défense contre les pratiques déloyales à l'importation ?' for conversation 156
2025-05-10 21:05:43,162 - INFO - Query received: Quelles dispositions légales antérieures sont abrogées par la loi tunisienne relative à la défense contre les pratiques déloyales à l'importation ?
2025-05-10 21:05:44,336 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.8111)
2025-05-10 21:05:44,472 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:05:44,472 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:05:45,773 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:05:45,773 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:05:48,276 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:05:48,276 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:05:55,606 - INFO - Token usage: prompt=1934, completion=744, total=2678
2025-05-10 21:05:55,619 - INFO - Agent workflow completed in 13.59s
2025-05-10 21:05:55,680 - INFO - Request processed in 13.65s (thinking: 11.16s)
2025-05-10 21:05:55,681 - INFO - 127.0.0.1 - - [10/May/2025 21:05:55] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:06:05,758 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:06:06,497 - INFO - Token usage: prompt=70, completion=15, total=85
2025-05-10 21:06:06,546 - INFO - Processing query: 'Quel est le délai accordé au ministère des finances pour procéder au remboursement selon l'article 48 ?' for conversation 157
2025-05-10 21:06:06,549 - INFO - Query received: Quel est le délai accordé au ministère des finances pour procéder au remboursement selon l'article 48 ?
2025-05-10 21:06:07,717 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3369)
2025-05-10 21:06:07,828 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:06:07,828 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:06:08,206 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:06:08,207 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:06:11,496 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:06:11,496 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:06:17,430 - INFO - Token usage: prompt=1556, completion=348, total=1904
2025-05-10 21:06:17,438 - INFO - Agent workflow completed in 11.68s
2025-05-10 21:06:17,476 - INFO - Request processed in 11.72s (thinking: 9.62s)
2025-05-10 21:06:17,477 - INFO - 127.0.0.1 - - [10/May/2025 21:06:17] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:06:27,544 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:06:29,087 - INFO - Token usage: prompt=78, completion=21, total=99
2025-05-10 21:06:29,141 - INFO - Processing query: 'Dans quelles conditions les droits antidumping et compensateurs définitifs peuvent-ils être réexaminés selon l'article 42 ?' for conversation 158
2025-05-10 21:06:29,143 - INFO - Query received: Dans quelles conditions les droits antidumping et compensateurs définitifs peuvent-ils être réexaminés selon l'article 42 ?
2025-05-10 21:06:30,342 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6171)
2025-05-10 21:06:30,479 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:06:30,479 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:06:32,155 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:06:32,156 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:06:39,943 - INFO - Token usage: prompt=1941, completion=612, total=2553
2025-05-10 21:06:39,950 - INFO - Agent workflow completed in 12.41s
2025-05-10 21:06:39,996 - INFO - Request processed in 12.45s (thinking: 9.48s)
2025-05-10 21:06:39,997 - INFO - 127.0.0.1 - - [10/May/2025 21:06:39] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:06:50,050 - INFO - 127.0.0.1 - - [10/May/2025 21:06:50] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2025-05-10 21:07:00,073 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:07:01,035 - INFO - Token usage: prompt=80, completion=24, total=104
2025-05-10 21:07:01,082 - INFO - Processing query: 'Comment une enquête en matière de subvention peut-elle être clôturée sans l'institution de droits compensateurs selon l'article 33 ?' for conversation 159
2025-05-10 21:07:01,084 - INFO - Query received: Comment une enquête en matière de subvention peut-elle être clôturée sans l'institution de droits compensateurs selon l'article 33 ?
2025-05-10 21:07:01,666 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5127)
2025-05-10 21:07:01,718 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:07:01,718 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:07:06,164 - INFO - Token usage: prompt=1560, completion=563, total=2123
2025-05-10 21:07:06,168 - INFO - Agent workflow completed in 6.10s
2025-05-10 21:07:06,205 - INFO - Request processed in 6.13s (thinking: 4.46s)
2025-05-10 21:07:06,206 - INFO - 127.0.0.1 - - [10/May/2025 21:07:06] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:08:19,086 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:08:19,724 - INFO - Token usage: prompt=91, completion=21, total=112
2025-05-10 21:08:19,760 - INFO - Processing query: 'Dans quel délai un importateur peut-il demander le remboursement des droits perçus en dépassement de la marge de dumping ou du montant réel de la subvention, selon la législation tunisienne ?' for conversation 160
2025-05-10 21:08:19,761 - INFO - Query received: Dans quel délai un importateur peut-il demander le remboursement des droits perçus en dépassement de la marge de dumping ou du montant réel de la subvention, selon la législation tunisienne ?
2025-05-10 21:08:20,271 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.6574)
2025-05-10 21:08:20,331 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:08:20,331 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:08:23,210 - INFO - Token usage: prompt=2458, completion=617, total=3075
2025-05-10 21:08:23,223 - INFO - Agent workflow completed in 4.14s
2025-05-10 21:08:23,268 - INFO - Request processed in 4.18s (thinking: 2.90s)
2025-05-10 21:08:23,270 - INFO - 127.0.0.1 - - [10/May/2025 21:08:23] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:08:33,444 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:08:34,655 - INFO - Token usage: prompt=83, completion=19, total=102
2025-05-10 21:08:34,707 - INFO - Processing query: 'Selon la législation tunisienne, quelles obligations peuvent être imposées aux exportateurs après l'acceptation d'un engagement en matière de prix ou de subvention ?' for conversation 161
2025-05-10 21:08:34,710 - INFO - Query received: Selon la législation tunisienne, quelles obligations peuvent être imposées aux exportateurs après l'acceptation d'un engagement en matière de prix ou de subvention ?
2025-05-10 21:08:35,895 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.6779)
2025-05-10 21:08:36,032 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:08:36,033 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:08:42,390 - INFO - Token usage: prompt=2501, completion=1193, total=3694
2025-05-10 21:08:42,400 - INFO - Agent workflow completed in 8.96s
2025-05-10 21:08:42,617 - INFO - Request processed in 9.17s (thinking: 6.38s)
2025-05-10 21:08:42,618 - INFO - 127.0.0.1 - - [10/May/2025 21:08:42] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:08:52,744 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:08:53,270 - INFO - Token usage: prompt=85, completion=24, total=109
2025-05-10 21:08:53,321 - INFO - Processing query: 'Dans quelles conditions un droit antidumping ou un droit compensateur définitif peut-il être institué en Tunisie, et comment son montant est-il déterminé selon la loi ?' for conversation 162
2025-05-10 21:08:53,324 - INFO - Query received: Dans quelles conditions un droit antidumping ou un droit compensateur définitif peut-il être institué en Tunisie, et comment son montant est-il déterminé selon la loi ?
2025-05-10 21:08:54,671 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6831)
2025-05-10 21:08:54,801 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:08:54,801 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:08:58,600 - INFO - Token usage: prompt=1567, completion=904, total=2471
2025-05-10 21:08:58,616 - INFO - Agent workflow completed in 5.87s
2025-05-10 21:08:58,715 - INFO - Request processed in 5.97s (thinking: 3.82s)
2025-05-10 21:08:58,717 - INFO - 127.0.0.1 - - [10/May/2025 21:08:58] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:09:08,795 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:09:09,870 - INFO - Token usage: prompt=81, completion=25, total=106
2025-05-10 21:09:09,918 - INFO - Processing query: 'Quelles sont les conditions requises pour qu'un engagement en matière de prix soit accepté dans le cadre d'une enquête pour dumping ou subvention en Tunisie ?' for conversation 163
2025-05-10 21:09:09,922 - INFO - Query received: Quelles sont les conditions requises pour qu'un engagement en matière de prix soit accepté dans le cadre d'une enquête pour dumping ou subvention en Tunisie ?
2025-05-10 21:09:11,113 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6418)
2025-05-10 21:09:11,261 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:09:11,261 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:09:16,920 - INFO - Token usage: prompt=1563, completion=1032, total=2595
2025-05-10 21:09:16,932 - INFO - Agent workflow completed in 8.14s
2025-05-10 21:09:17,040 - INFO - Request processed in 8.24s (thinking: 5.68s)
2025-05-10 21:09:17,041 - INFO - 127.0.0.1 - - [10/May/2025 21:09:17] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:09:27,142 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:09:28,495 - INFO - Token usage: prompt=97, completion=25, total=122
2025-05-10 21:09:28,547 - INFO - Processing query: 'Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?' for conversation 164
2025-05-10 21:09:28,548 - INFO - Query received: Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?
2025-05-10 21:09:29,773 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7009)
2025-05-10 21:09:29,924 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:09:29,925 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:09:30,062 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:09:30,062 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:09:32,597 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:09:32,597 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:09:38,592 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:09:38,592 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:09:38,594 - INFO - Agent workflow completed in 11.45s
2025-05-10 21:09:38,595 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:09:38,598 - INFO - 127.0.0.1 - - [10/May/2025 21:09:38] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:09:41,627 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:09:42,271 - INFO - Token usage: prompt=97, completion=23, total=120
2025-05-10 21:09:42,321 - INFO - Processing query: 'Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?' for conversation 165
2025-05-10 21:09:42,323 - INFO - Query received: Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?
2025-05-10 21:09:43,552 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7009)
2025-05-10 21:09:43,703 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:09:43,703 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:09:44,929 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:09:44,929 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:09:51,167 - INFO - Token usage: prompt=2519, completion=1000, total=3519
2025-05-10 21:09:51,180 - INFO - Agent workflow completed in 9.55s
2025-05-10 21:09:51,327 - INFO - Request processed in 9.70s (thinking: 7.49s)
2025-05-10 21:09:51,328 - INFO - 127.0.0.1 - - [10/May/2025 21:09:51] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:10:01,459 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:10:02,794 - INFO - Token usage: prompt=81, completion=23, total=104
2025-05-10 21:10:02,844 - INFO - Processing query: 'Quels sont les recours juridiques possibles pour contester les décisions prises dans le cadre des procédures antidumping ou de subvention, selon la législation tunisienne ?' for conversation 166
2025-05-10 21:10:02,847 - INFO - Query received: Quels sont les recours juridiques possibles pour contester les décisions prises dans le cadre des procédures antidumping ou de subvention, selon la législation tunisienne ?
2025-05-10 21:10:04,125 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.7332)
2025-05-10 21:10:04,256 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:10:04,257 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:10:05,561 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:10:05,561 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:10:08,356 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:10:08,357 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:10:16,855 - INFO - Token usage: prompt=1570, completion=1110, total=2680
2025-05-10 21:10:16,865 - INFO - Agent workflow completed in 15.41s
2025-05-10 21:10:17,046 - INFO - Request processed in 15.59s (thinking: 12.62s)
2025-05-10 21:10:17,047 - INFO - 127.0.0.1 - - [10/May/2025 21:10:17] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:10:27,162 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:10:27,985 - INFO - Token usage: prompt=79, completion=27, total=106
2025-05-10 21:10:28,039 - INFO - Processing query: 'Quelles dispositions légales antérieures sont abrogées par la loi tunisienne relative à la défense contre les pratiques déloyales à l'importation ?' for conversation 167
2025-05-10 21:10:28,041 - INFO - Query received: Quelles dispositions légales antérieures sont abrogées par la loi tunisienne relative à la défense contre les pratiques déloyales à l'importation ?
2025-05-10 21:10:29,243 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.8111)
2025-05-10 21:10:29,368 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:10:29,369 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:10:30,558 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:10:30,558 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:10:33,313 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:10:33,313 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:10:37,703 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:10:37,703 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:10:37,704 - INFO - Agent workflow completed in 10.54s
2025-05-10 21:10:37,704 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:10:37,707 - INFO - 127.0.0.1 - - [10/May/2025 21:10:37] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:10:40,740 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:10:41,103 - INFO - Token usage: prompt=79, completion=27, total=106
2025-05-10 21:10:41,155 - INFO - Processing query: 'Quelles dispositions légales antérieures sont abrogées par la loi tunisienne relative à la défense contre les pratiques déloyales à l'importation ?' for conversation 168
2025-05-10 21:10:41,158 - INFO - Query received: Quelles dispositions légales antérieures sont abrogées par la loi tunisienne relative à la défense contre les pratiques déloyales à l'importation ?
2025-05-10 21:10:42,384 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.8111)
2025-05-10 21:10:42,511 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:10:42,511 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:10:46,110 - INFO - Token usage: prompt=1934, completion=673, total=2607
2025-05-10 21:10:46,121 - INFO - Agent workflow completed in 5.38s
2025-05-10 21:10:46,168 - INFO - Request processed in 5.43s (thinking: 3.62s)
2025-05-10 21:10:46,170 - INFO - 127.0.0.1 - - [10/May/2025 21:10:46] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:10:56,232 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:10:57,171 - INFO - Token usage: prompt=70, completion=15, total=85
2025-05-10 21:10:57,223 - INFO - Processing query: 'Quel est le délai accordé au ministère des finances pour procéder au remboursement selon l'article 48 ?' for conversation 169
2025-05-10 21:10:57,226 - INFO - Query received: Quel est le délai accordé au ministère des finances pour procéder au remboursement selon l'article 48 ?
2025-05-10 21:10:58,442 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3369)
2025-05-10 21:10:58,562 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:10:58,562 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:10:58,913 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:10:58,913 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:11:01,372 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:11:01,373 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:11:07,412 - INFO - Token usage: prompt=1556, completion=329, total=1885
2025-05-10 21:11:07,421 - INFO - Agent workflow completed in 11.19s
2025-05-10 21:11:07,458 - INFO - Request processed in 11.23s (thinking: 8.87s)
2025-05-10 21:11:07,460 - INFO - 127.0.0.1 - - [10/May/2025 21:11:07] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:11:17,510 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:11:18,571 - INFO - Token usage: prompt=78, completion=21, total=99
2025-05-10 21:11:18,615 - INFO - Processing query: 'Dans quelles conditions les droits antidumping et compensateurs définitifs peuvent-ils être réexaminés selon l'article 42 ?' for conversation 170
2025-05-10 21:11:18,618 - INFO - Query received: Dans quelles conditions les droits antidumping et compensateurs définitifs peuvent-ils être réexaminés selon l'article 42 ?
2025-05-10 21:11:19,818 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6171)
2025-05-10 21:11:19,940 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:11:19,941 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:11:20,559 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:11:20,559 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:11:24,004 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:11:24,004 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:11:36,311 - INFO - Token usage: prompt=1941, completion=675, total=2616
2025-05-10 21:11:36,320 - INFO - Agent workflow completed in 18.81s
2025-05-10 21:11:36,366 - INFO - Request processed in 18.86s (thinking: 16.39s)
2025-05-10 21:11:36,367 - INFO - 127.0.0.1 - - [10/May/2025 21:11:36] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:11:46,403 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:11:48,060 - INFO - Token usage: prompt=66, completion=13, total=79
2025-05-10 21:11:48,110 - INFO - Processing query: 'Quel est le principe général régissant les importations et les exportations de produits?' for conversation 171
2025-05-10 21:11:48,112 - INFO - Query received: Quel est le principe général régissant les importations et les exportations de produits?
2025-05-10 21:11:49,312 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6423)
2025-05-10 21:11:49,435 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:11:49,435 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:11:49,909 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:11:49,909 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:11:52,077 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:11:52,077 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:11:56,463 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:11:56,465 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:11:56,466 - INFO - Agent workflow completed in 10.06s
2025-05-10 21:11:56,467 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:11:56,468 - INFO - 127.0.0.1 - - [10/May/2025 21:11:56] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:11:59,490 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:12:01,210 - INFO - Token usage: prompt=66, completion=13, total=79
2025-05-10 21:12:01,254 - INFO - Processing query: 'Quel est le principe général régissant les importations et les exportations de produits?' for conversation 172
2025-05-10 21:12:01,257 - INFO - Query received: Quel est le principe général régissant les importations et les exportations de produits?
2025-05-10 21:12:02,416 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6423)
2025-05-10 21:12:02,523 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:12:02,523 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:12:03,256 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:12:03,256 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:12:10,389 - INFO - Token usage: prompt=2974, completion=1206, total=4180
2025-05-10 21:12:10,400 - INFO - Agent workflow completed in 10.91s
2025-05-10 21:12:10,591 - INFO - Request processed in 11.10s (thinking: 7.88s)
2025-05-10 21:12:10,593 - INFO - 127.0.0.1 - - [10/May/2025 21:12:10] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:12:20,693 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:12:21,344 - INFO - Token usage: prompt=63, completion=16, total=79
2025-05-10 21:12:21,395 - INFO - Processing query: 'La liberté de commerce extérieur est-elle totale et inconditionnelle?' for conversation 173
2025-05-10 21:12:21,398 - INFO - Query received: La liberté de commerce extérieur est-elle totale et inconditionnelle?
2025-05-10 21:12:22,582 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5763)
2025-05-10 21:12:22,690 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:12:22,691 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:12:24,005 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:12:24,007 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:12:26,565 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:12:26,565 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:12:30,984 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:12:30,984 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:12:30,986 - INFO - Agent workflow completed in 10.29s
2025-05-10 21:12:30,987 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:12:30,989 - INFO - 127.0.0.1 - - [10/May/2025 21:12:30] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:12:34,024 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:12:34,394 - INFO - Token usage: prompt=63, completion=19, total=82
2025-05-10 21:12:34,446 - INFO - Processing query: 'La liberté de commerce extérieur est-elle totale et inconditionnelle?' for conversation 174
2025-05-10 21:12:34,450 - INFO - Query received: La liberté de commerce extérieur est-elle totale et inconditionnelle?
2025-05-10 21:12:35,664 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5763)
2025-05-10 21:12:35,776 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:12:35,777 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:12:40,081 - INFO - Token usage: prompt=1597, completion=797, total=2394
2025-05-10 21:12:40,091 - INFO - Agent workflow completed in 6.07s
2025-05-10 21:12:40,221 - INFO - Request processed in 6.20s (thinking: 4.32s)
2025-05-10 21:12:40,222 - INFO - 127.0.0.1 - - [10/May/2025 21:12:40] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:12:50,341 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:12:51,096 - INFO - Token usage: prompt=65, completion=15, total=80
2025-05-10 21:12:51,148 - INFO - Processing query: 'Quelles sont les implications du principe de liberté du commerce extérieur pour les acteurs économiques?' for conversation 175
2025-05-10 21:12:51,152 - INFO - Query received: Quelles sont les implications du principe de liberté du commerce extérieur pour les acteurs économiques?
2025-05-10 21:12:52,442 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6284)
2025-05-10 21:12:52,558 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:12:52,559 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:12:53,135 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:12:53,136 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:12:55,284 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:12:55,285 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:13:04,627 - INFO - Token usage: prompt=1647, completion=1064, total=2711
2025-05-10 21:13:04,638 - INFO - Agent workflow completed in 14.30s
2025-05-10 21:13:04,734 - INFO - Request processed in 14.39s (thinking: 12.09s)
2025-05-10 21:13:04,736 - INFO - 127.0.0.1 - - [10/May/2025 21:13:04] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:13:14,793 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:13:15,135 - INFO - Token usage: prompt=67, completion=13, total=80
2025-05-10 21:13:15,180 - INFO - Processing query: 'Quelles catégories de produits sont explicitement exclues du régime de la liberté de commerce extérieur?' for conversation 176
2025-05-10 21:13:15,182 - INFO - Query received: Quelles catégories de produits sont explicitement exclues du régime de la liberté de commerce extérieur?
2025-05-10 21:13:15,697 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6783)
2025-05-10 21:13:15,747 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:13:15,747 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:13:16,123 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:13:16,123 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:13:18,688 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:13:18,688 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:13:26,842 - INFO - Token usage: prompt=1604, completion=882, total=2486
2025-05-10 21:13:26,854 - INFO - Agent workflow completed in 12.06s
2025-05-10 21:13:26,941 - INFO - Request processed in 12.15s (thinking: 11.11s)
2025-05-10 21:13:26,942 - INFO - 127.0.0.1 - - [10/May/2025 21:13:26] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:13:37,010 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:13:37,466 - INFO - Token usage: prompt=70, completion=16, total=86
2025-05-10 21:13:37,517 - INFO - Processing query: 'Comment la liste précise des produits exclus du régime de la liberté de commerce est-elle déterminée?' for conversation 177
2025-05-10 21:13:37,521 - INFO - Query received: Comment la liste précise des produits exclus du régime de la liberté de commerce est-elle déterminée?
2025-05-10 21:13:38,745 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6279)
2025-05-10 21:13:38,865 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:13:38,865 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:13:39,004 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:13:39,005 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:13:41,173 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:13:41,174 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:13:45,340 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:13:45,341 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:13:45,343 - INFO - Agent workflow completed in 8.33s
2025-05-10 21:13:45,344 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:13:45,347 - INFO - 127.0.0.1 - - [10/May/2025 21:13:45] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:13:48,362 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:13:49,714 - INFO - Token usage: prompt=70, completion=15, total=85
2025-05-10 21:13:49,760 - INFO - Processing query: 'Comment la liste précise des produits exclus du régime de la liberté de commerce est-elle déterminée?' for conversation 178
2025-05-10 21:13:49,762 - INFO - Query received: Comment la liste précise des produits exclus du régime de la liberté de commerce est-elle déterminée?
2025-05-10 21:13:50,921 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6279)
2025-05-10 21:13:51,068 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:13:51,069 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:13:56,259 - INFO - Token usage: prompt=1449, completion=836, total=2285
2025-05-10 21:13:56,270 - INFO - Agent workflow completed in 7.91s
2025-05-10 21:13:56,359 - INFO - Request processed in 8.00s (thinking: 5.21s)
2025-05-10 21:13:56,361 - INFO - 127.0.0.1 - - [10/May/2025 21:13:56] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:14:06,443 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:14:06,834 - INFO - Token usage: prompt=71, completion=15, total=86
2025-05-10 21:14:06,881 - INFO - Processing query: 'Quelle est la justification derrière l'exclusion de certaines catégories de produits du régime de la liberté de commerce extérieur?' for conversation 179
2025-05-10 21:14:06,885 - INFO - Query received: Quelle est la justification derrière l'exclusion de certaines catégories de produits du régime de la liberté de commerce extérieur?
2025-05-10 21:14:08,095 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6760)
2025-05-10 21:14:08,234 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:14:08,234 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:14:08,747 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:14:08,748 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:14:14,394 - INFO - Token usage: prompt=1610, completion=726, total=2336
2025-05-10 21:14:14,404 - INFO - Agent workflow completed in 7.96s
2025-05-10 21:14:14,478 - INFO - Request processed in 8.03s (thinking: 6.18s)
2025-05-10 21:14:14,480 - INFO - 127.0.0.1 - - [10/May/2025 21:14:14] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:14:24,549 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:14:24,880 - INFO - Token usage: prompt=78, completion=18, total=96
2025-05-10 21:14:24,929 - INFO - Processing query: 'Qui est habilité à réaliser des opérations d'importation et d'exportation de produits, en dehors des opérations occasionnelles sans caractère commercial?' for conversation 180
2025-05-10 21:14:24,931 - INFO - Query received: Qui est habilité à réaliser des opérations d'importation et d'exportation de produits, en dehors des opérations occasionnelles sans caractère commercial?
2025-05-10 21:14:26,547 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5360)
2025-05-10 21:14:26,681 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:14:26,681 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:14:26,823 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:14:26,823 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:14:28,998 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:14:28,999 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:14:36,521 - INFO - Token usage: prompt=1485, completion=807, total=2292
2025-05-10 21:14:36,530 - INFO - Agent workflow completed in 11.98s
2025-05-10 21:14:36,604 - INFO - Request processed in 12.06s (thinking: 9.86s)
2025-05-10 21:14:36,606 - INFO - 127.0.0.1 - - [10/May/2025 21:14:36] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:14:46,672 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:14:48,284 - INFO - Token usage: prompt=76, completion=13, total=89
2025-05-10 21:14:48,320 - INFO - Processing query: 'Des conditions spécifiques sont-elles imposées aux personnes physiques ou morales souhaitant effectuer des opérations d'importation ou d'exportation?' for conversation 181
2025-05-10 21:14:48,322 - INFO - Query received: Des conditions spécifiques sont-elles imposées aux personnes physiques ou morales souhaitant effectuer des opérations d'importation ou d'exportation?
2025-05-10 21:14:48,836 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5669)
2025-05-10 21:14:48,887 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:14:48,887 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:14:49,824 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:14:49,824 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:14:52,286 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:14:52,287 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:14:59,900 - INFO - Token usage: prompt=1543, completion=827, total=2370
2025-05-10 21:14:59,911 - INFO - Agent workflow completed in 13.24s
2025-05-10 21:15:00,041 - INFO - Request processed in 13.37s (thinking: 11.03s)
2025-05-10 21:15:00,043 - INFO - 127.0.0.1 - - [10/May/2025 21:15:00] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:15:10,143 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:15:10,615 - INFO - Token usage: prompt=74, completion=13, total=87
2025-05-10 21:15:10,664 - INFO - Processing query: 'Une exception est-elle prévue concernant les personnes habilitées à réaliser des opérations d'importation et d'exportation?' for conversation 182
2025-05-10 21:15:10,666 - INFO - Query received: Une exception est-elle prévue concernant les personnes habilitées à réaliser des opérations d'importation et d'exportation?
2025-05-10 21:15:11,848 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5915)
2025-05-10 21:15:11,963 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:15:11,963 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:15:12,253 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:15:12,253 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:15:15,136 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:15:15,136 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:15:22,286 - INFO - Token usage: prompt=1410, completion=658, total=2068
2025-05-10 21:15:22,300 - INFO - Agent workflow completed in 12.16s
2025-05-10 21:15:22,356 - INFO - Request processed in 12.21s (thinking: 10.34s)
2025-05-10 21:15:22,358 - INFO - 127.0.0.1 - - [10/May/2025 21:15:22] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:15:32,457 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:15:33,346 - INFO - Token usage: prompt=74, completion=20, total=94
2025-05-10 21:15:33,404 - INFO - Processing query: 'Quel mécanisme est mis en place pour l'importation ou l'exportation des produits exclus du régime de la liberté?' for conversation 183
2025-05-10 21:15:33,407 - INFO - Query received: Quel mécanisme est mis en place pour l'importation ou l'exportation des produits exclus du régime de la liberté?
2025-05-10 21:15:34,679 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6960)
2025-05-10 21:15:34,797 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:15:34,797 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:15:35,008 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:15:35,009 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:15:37,150 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:15:37,151 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:15:41,323 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:15:41,323 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:15:41,325 - INFO - Agent workflow completed in 8.87s
2025-05-10 21:15:41,326 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:15:41,329 - INFO - 127.0.0.1 - - [10/May/2025 21:15:41] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:15:44,338 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:15:44,676 - INFO - Token usage: prompt=74, completion=18, total=92
2025-05-10 21:15:44,715 - INFO - Processing query: 'Quel mécanisme est mis en place pour l'importation ou l'exportation des produits exclus du régime de la liberté?' for conversation 184
2025-05-10 21:15:44,718 - INFO - Query received: Quel mécanisme est mis en place pour l'importation ou l'exportation des produits exclus du régime de la liberté?
2025-05-10 21:15:45,833 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6960)
2025-05-10 21:15:45,936 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:15:45,937 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:15:50,122 - INFO - Token usage: prompt=1610, completion=995, total=2605
2025-05-10 21:15:50,131 - INFO - Agent workflow completed in 5.79s
2025-05-10 21:15:50,277 - INFO - Request processed in 5.94s (thinking: 4.20s)
2025-05-10 21:15:50,278 - INFO - 127.0.0.1 - - [10/May/2025 21:15:50] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:16:00,366 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:16:01,835 - INFO - Token usage: prompt=78, completion=17, total=95
2025-05-10 21:16:01,882 - INFO - Processing query: 'Quelle autorité est compétente pour accorder les autorisations d'importation et d'exportation des produits exclus du régime de la liberté?' for conversation 185
2025-05-10 21:16:01,885 - INFO - Query received: Quelle autorité est compétente pour accorder les autorisations d'importation et d'exportation des produits exclus du régime de la liberté?
2025-05-10 21:16:03,167 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6835)
2025-05-10 21:16:03,286 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:16:03,287 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:16:04,166 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:16:04,167 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:16:06,526 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:16:06,528 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:16:13,374 - INFO - Token usage: prompt=1613, completion=639, total=2252
2025-05-10 21:16:13,386 - INFO - Agent workflow completed in 13.02s
2025-05-10 21:16:13,456 - INFO - Request processed in 13.09s (thinking: 10.11s)
2025-05-10 21:16:13,457 - INFO - 127.0.0.1 - - [10/May/2025 21:16:13] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:16:23,517 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:16:23,882 - INFO - Token usage: prompt=82, completion=25, total=107
2025-05-10 21:16:23,927 - INFO - Processing query: 'Quelle est la conséquence directe de l'exclusion d'un produit du régime de la liberté en ce qui concerne sa procédure d'importation ou d'exportation?' for conversation 186
2025-05-10 21:16:23,929 - INFO - Query received: Quelle est la conséquence directe de l'exclusion d'un produit du régime de la liberté en ce qui concerne sa procédure d'importation ou d'exportation?
2025-05-10 21:16:25,361 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6673)
2025-05-10 21:16:25,492 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:16:25,492 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:16:25,783 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:16:25,783 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:16:27,961 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:16:27,961 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:16:36,195 - INFO - Token usage: prompt=1708, completion=886, total=2594
2025-05-10 21:16:36,208 - INFO - Agent workflow completed in 12.69s
2025-05-10 21:16:36,306 - INFO - Request processed in 12.79s (thinking: 10.73s)
2025-05-10 21:16:36,308 - INFO - 127.0.0.1 - - [10/May/2025 21:16:36] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:16:46,384 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:16:46,716 - INFO - Token usage: prompt=70, completion=21, total=91
2025-05-10 21:16:46,764 - INFO - Processing query: 'Comment sont déterminées les modalités relatives à la réalisation des opérations d'importation et d'exportation?' for conversation 187
2025-05-10 21:16:46,768 - INFO - Query received: Comment sont déterminées les modalités relatives à la réalisation des opérations d'importation et d'exportation?
2025-05-10 21:16:48,101 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5693)
2025-05-10 21:16:48,205 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:16:48,206 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:16:48,538 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:16:48,538 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:16:51,206 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:16:51,206 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:16:55,675 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:16:55,675 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:16:55,678 - INFO - Agent workflow completed in 9.29s
2025-05-10 21:16:55,678 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:16:55,680 - INFO - 127.0.0.1 - - [10/May/2025 21:16:55] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:16:58,703 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:16:59,564 - INFO - Token usage: prompt=70, completion=19, total=89
2025-05-10 21:16:59,615 - INFO - Processing query: 'Comment sont déterminées les modalités relatives à la réalisation des opérations d'importation et d'exportation?' for conversation 188
2025-05-10 21:16:59,617 - INFO - Query received: Comment sont déterminées les modalités relatives à la réalisation des opérations d'importation et d'exportation?
2025-05-10 21:17:00,821 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5693)
2025-05-10 21:17:00,938 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:17:00,938 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:17:01,343 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:17:01,343 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:17:03,763 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:17:03,763 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:17:14,310 - INFO - Token usage: prompt=2533, completion=1160, total=3693
2025-05-10 21:17:14,320 - INFO - Agent workflow completed in 15.62s
2025-05-10 21:17:14,621 - INFO - Request processed in 15.92s (thinking: 13.39s)
2025-05-10 21:17:14,623 - INFO - 127.0.0.1 - - [10/May/2025 21:17:14] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:28:01,923 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:28:02,914 - INFO - Token usage: prompt=91, completion=21, total=112
2025-05-10 21:28:02,953 - INFO - Processing query: 'Dans quel délai un importateur peut-il demander le remboursement des droits perçus en dépassement de la marge de dumping ou du montant réel de la subvention, selon la législation tunisienne ?' for conversation 189
2025-05-10 21:28:02,956 - INFO - Query received: Dans quel délai un importateur peut-il demander le remboursement des droits perçus en dépassement de la marge de dumping ou du montant réel de la subvention, selon la législation tunisienne ?
2025-05-10 21:28:03,394 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.6574)
2025-05-10 21:28:03,444 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:28:03,445 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:28:07,826 - INFO - Token usage: prompt=2458, completion=480, total=2938
2025-05-10 21:28:07,834 - INFO - Agent workflow completed in 5.91s
2025-05-10 21:28:07,866 - INFO - Request processed in 5.94s (thinking: 4.39s)
2025-05-10 21:28:07,868 - INFO - 127.0.0.1 - - [10/May/2025 21:28:07] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:28:17,941 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:28:20,215 - INFO - Token usage: prompt=83, completion=18, total=101
2025-05-10 21:28:20,255 - INFO - Processing query: 'Selon la législation tunisienne, quelles obligations peuvent être imposées aux exportateurs après l'acceptation d'un engagement en matière de prix ou de subvention ?' for conversation 190
2025-05-10 21:28:20,256 - INFO - Query received: Selon la législation tunisienne, quelles obligations peuvent être imposées aux exportateurs après l'acceptation d'un engagement en matière de prix ou de subvention ?
2025-05-10 21:28:20,720 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.6779)
2025-05-10 21:28:20,766 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:28:20,766 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:28:25,739 - INFO - Token usage: prompt=2501, completion=1039, total=3540
2025-05-10 21:28:25,747 - INFO - Agent workflow completed in 7.81s
2025-05-10 21:28:25,865 - INFO - Request processed in 7.92s (thinking: 4.99s)
2025-05-10 21:28:25,867 - INFO - 127.0.0.1 - - [10/May/2025 21:28:25] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:28:35,942 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:28:37,202 - INFO - Token usage: prompt=85, completion=23, total=108
2025-05-10 21:28:37,234 - INFO - Processing query: 'Dans quelles conditions un droit antidumping ou un droit compensateur définitif peut-il être institué en Tunisie, et comment son montant est-il déterminé selon la loi ?' for conversation 191
2025-05-10 21:28:37,236 - INFO - Query received: Dans quelles conditions un droit antidumping ou un droit compensateur définitif peut-il être institué en Tunisie, et comment son montant est-il déterminé selon la loi ?
2025-05-10 21:28:37,714 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6831)
2025-05-10 21:28:37,763 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:28:37,763 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:28:41,971 - INFO - Token usage: prompt=1567, completion=956, total=2523
2025-05-10 21:28:41,978 - INFO - Agent workflow completed in 6.04s
2025-05-10 21:28:42,034 - INFO - Request processed in 6.09s (thinking: 4.22s)
2025-05-10 21:28:42,035 - INFO - 127.0.0.1 - - [10/May/2025 21:28:42] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:28:52,083 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:28:53,829 - INFO - Token usage: prompt=81, completion=28, total=109
2025-05-10 21:28:53,880 - INFO - Processing query: 'Quelles sont les conditions requises pour qu'un engagement en matière de prix soit accepté dans le cadre d'une enquête pour dumping ou subvention en Tunisie ?' for conversation 192
2025-05-10 21:28:53,882 - INFO - Query received: Quelles sont les conditions requises pour qu'un engagement en matière de prix soit accepté dans le cadre d'une enquête pour dumping ou subvention en Tunisie ?
2025-05-10 21:28:55,047 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6418)
2025-05-10 21:28:55,170 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:28:55,171 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:28:59,148 - INFO - Token usage: prompt=1563, completion=972, total=2535
2025-05-10 21:28:59,158 - INFO - Agent workflow completed in 7.08s
2025-05-10 21:28:59,285 - INFO - Request processed in 7.20s (thinking: 4.00s)
2025-05-10 21:28:59,286 - INFO - 127.0.0.1 - - [10/May/2025 21:28:59] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:29:09,384 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:29:10,186 - INFO - Token usage: prompt=97, completion=25, total=122
2025-05-10 21:29:10,238 - INFO - Processing query: 'Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?' for conversation 193
2025-05-10 21:29:10,243 - INFO - Query received: Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?
2025-05-10 21:29:11,619 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7009)
2025-05-10 21:29:11,773 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:29:11,773 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:29:12,948 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:29:12,949 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:29:15,714 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:29:15,714 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:29:20,169 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:29:20,170 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:29:20,173 - INFO - Agent workflow completed in 10.79s
2025-05-10 21:29:20,174 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:29:20,176 - INFO - 127.0.0.1 - - [10/May/2025 21:29:20] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:29:23,200 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:29:23,746 - INFO - Token usage: prompt=97, completion=19, total=116
2025-05-10 21:29:23,789 - INFO - Processing query: 'Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?' for conversation 194
2025-05-10 21:29:23,792 - INFO - Query received: Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?
2025-05-10 21:29:25,095 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7009)
2025-05-10 21:29:25,252 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:29:25,253 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:29:25,400 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:29:25,400 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:29:32,303 - INFO - Token usage: prompt=2519, completion=1130, total=3649
2025-05-10 21:29:32,315 - INFO - Agent workflow completed in 9.12s
2025-05-10 21:29:32,403 - INFO - Request processed in 9.20s (thinking: 7.08s)
2025-05-10 21:29:32,405 - INFO - 127.0.0.1 - - [10/May/2025 21:29:32] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:29:42,503 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:29:43,029 - INFO - Token usage: prompt=81, completion=22, total=103
2025-05-10 21:29:43,075 - INFO - Processing query: 'Quels sont les recours juridiques possibles pour contester les décisions prises dans le cadre des procédures antidumping ou de subvention, selon la législation tunisienne ?' for conversation 195
2025-05-10 21:29:43,077 - INFO - Query received: Quels sont les recours juridiques possibles pour contester les décisions prises dans le cadre des procédures antidumping ou de subvention, selon la législation tunisienne ?
2025-05-10 21:29:44,281 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.7332)
2025-05-10 21:29:44,417 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:29:44,417 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:29:45,719 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:29:45,719 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:29:48,178 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:29:48,178 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:29:52,582 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:29:52,582 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:29:52,583 - INFO - Agent workflow completed in 10.08s
2025-05-10 21:29:52,584 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:29:52,586 - INFO - 127.0.0.1 - - [10/May/2025 21:29:52] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:29:55,612 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:29:57,433 - INFO - Token usage: prompt=81, completion=19, total=100
2025-05-10 21:29:57,480 - INFO - Processing query: 'Quels sont les recours juridiques possibles pour contester les décisions prises dans le cadre des procédures antidumping ou de subvention, selon la législation tunisienne ?' for conversation 196
2025-05-10 21:29:57,484 - INFO - Query received: Quels sont les recours juridiques possibles pour contester les décisions prises dans le cadre des procédures antidumping ou de subvention, selon la législation tunisienne ?
2025-05-10 21:29:58,675 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.7332)
2025-05-10 21:29:58,804 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:29:58,805 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:30:02,023 - INFO - Token usage: prompt=1570, completion=492, total=2062
2025-05-10 21:30:02,036 - INFO - Agent workflow completed in 6.42s
2025-05-10 21:30:02,086 - INFO - Request processed in 6.47s (thinking: 3.24s)
2025-05-10 21:30:02,087 - INFO - 127.0.0.1 - - [10/May/2025 21:30:02] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:30:12,159 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:30:12,958 - INFO - Token usage: prompt=79, completion=27, total=106
2025-05-10 21:30:13,001 - INFO - Processing query: 'Quelles dispositions légales antérieures sont abrogées par la loi tunisienne relative à la défense contre les pratiques déloyales à l'importation ?' for conversation 197
2025-05-10 21:30:13,004 - INFO - Query received: Quelles dispositions légales antérieures sont abrogées par la loi tunisienne relative à la défense contre les pratiques déloyales à l'importation ?
2025-05-10 21:30:13,638 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.8111)
2025-05-10 21:30:13,691 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:30:13,691 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:30:14,135 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:30:14,135 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:30:16,425 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:30:16,426 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:30:23,598 - INFO - Token usage: prompt=1934, completion=726, total=2660
2025-05-10 21:30:23,604 - INFO - Agent workflow completed in 11.45s
2025-05-10 21:30:23,647 - INFO - Request processed in 11.49s (thinking: 9.92s)
2025-05-10 21:30:23,648 - INFO - 127.0.0.1 - - [10/May/2025 21:30:23] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:30:33,694 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:30:34,256 - INFO - Token usage: prompt=70, completion=15, total=85
2025-05-10 21:30:34,302 - INFO - Processing query: 'Quel est le délai accordé au ministère des finances pour procéder au remboursement selon l'article 48 ?' for conversation 198
2025-05-10 21:30:34,304 - INFO - Query received: Quel est le délai accordé au ministère des finances pour procéder au remboursement selon l'article 48 ?
2025-05-10 21:30:34,764 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3369)
2025-05-10 21:30:34,816 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:30:34,816 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:30:35,060 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:30:35,060 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:30:38,765 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:30:38,765 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:30:44,978 - INFO - Token usage: prompt=1556, completion=375, total=1931
2025-05-10 21:30:44,988 - INFO - Agent workflow completed in 11.29s
2025-05-10 21:30:45,018 - INFO - Request processed in 11.32s (thinking: 10.18s)
2025-05-10 21:30:45,019 - INFO - 127.0.0.1 - - [10/May/2025 21:30:45] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:30:55,042 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:30:55,820 - INFO - Token usage: prompt=78, completion=23, total=101
2025-05-10 21:30:55,859 - INFO - Processing query: 'Dans quelles conditions les droits antidumping et compensateurs définitifs peuvent-ils être réexaminés selon l'article 42 ?' for conversation 199
2025-05-10 21:30:55,860 - INFO - Query received: Dans quelles conditions les droits antidumping et compensateurs définitifs peuvent-ils être réexaminés selon l'article 42 ?
2025-05-10 21:30:56,984 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6171)
2025-05-10 21:30:57,106 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:30:57,106 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:30:57,555 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:30:57,556 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:30:59,877 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:30:59,877 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:31:04,041 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:31:04,041 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:31:04,043 - INFO - Agent workflow completed in 9.00s
2025-05-10 21:31:04,043 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:31:04,045 - INFO - 127.0.0.1 - - [10/May/2025 21:31:04] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:31:07,061 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:31:07,421 - INFO - Token usage: prompt=78, completion=23, total=101
2025-05-10 21:31:07,467 - INFO - Processing query: 'Dans quelles conditions les droits antidumping et compensateurs définitifs peuvent-ils être réexaminés selon l'article 42 ?' for conversation 200
2025-05-10 21:31:07,468 - INFO - Query received: Dans quelles conditions les droits antidumping et compensateurs définitifs peuvent-ils être réexaminés selon l'article 42 ?
2025-05-10 21:31:07,941 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6171)
2025-05-10 21:31:07,990 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:31:07,990 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:31:11,343 - INFO - Token usage: prompt=1941, completion=718, total=2659
2025-05-10 21:31:11,347 - INFO - Agent workflow completed in 4.29s
2025-05-10 21:31:11,389 - INFO - Request processed in 4.33s (thinking: 3.36s)
2025-05-10 21:31:11,389 - INFO - 127.0.0.1 - - [10/May/2025 21:31:11] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:31:21,440 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:31:21,779 - INFO - Token usage: prompt=66, completion=13, total=79
2025-05-10 21:31:21,827 - INFO - Processing query: 'Quel est le principe général régissant les importations et les exportations de produits?' for conversation 201
2025-05-10 21:31:21,829 - INFO - Query received: Quel est le principe général régissant les importations et les exportations de produits?
2025-05-10 21:31:22,323 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6423)
2025-05-10 21:31:22,364 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:31:22,364 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:31:22,475 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:31:22,475 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:31:24,617 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:31:24,617 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:31:28,775 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:31:28,775 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:31:28,775 - INFO - Agent workflow completed in 7.34s
2025-05-10 21:31:28,777 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:31:28,778 - INFO - 127.0.0.1 - - [10/May/2025 21:31:28] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:31:31,798 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:31:33,033 - INFO - Token usage: prompt=66, completion=17, total=83
2025-05-10 21:31:33,073 - INFO - Processing query: 'Quel est le principe général régissant les importations et les exportations de produits?' for conversation 202
2025-05-10 21:31:33,075 - INFO - Query received: Quel est le principe général régissant les importations et les exportations de produits?
2025-05-10 21:31:33,542 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6423)
2025-05-10 21:31:33,578 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:31:33,578 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:31:34,366 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:31:34,366 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:31:36,822 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:31:36,822 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:31:46,479 - INFO - Token usage: prompt=2974, completion=1023, total=3997
2025-05-10 21:31:46,486 - INFO - Agent workflow completed in 14.69s
2025-05-10 21:31:46,558 - INFO - Request processed in 14.76s (thinking: 12.91s)
2025-05-10 21:31:46,559 - INFO - 127.0.0.1 - - [10/May/2025 21:31:46] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:31:56,611 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:31:56,928 - INFO - Token usage: prompt=63, completion=18, total=81
2025-05-10 21:31:56,971 - INFO - Processing query: 'La liberté de commerce extérieur est-elle totale et inconditionnelle?' for conversation 203
2025-05-10 21:31:56,972 - INFO - Query received: La liberté de commerce extérieur est-elle totale et inconditionnelle?
2025-05-10 21:31:57,462 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5763)
2025-05-10 21:31:57,512 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:31:57,512 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:31:57,628 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:31:57,629 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:32:00,074 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:32:00,074 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:32:04,471 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:32:04,473 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:32:04,474 - INFO - Agent workflow completed in 7.86s
2025-05-10 21:32:04,474 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:32:04,476 - INFO - 127.0.0.1 - - [10/May/2025 21:32:04] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:32:07,496 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:32:08,104 - INFO - Token usage: prompt=63, completion=16, total=79
2025-05-10 21:32:08,148 - INFO - Processing query: 'La liberté de commerce extérieur est-elle totale et inconditionnelle?' for conversation 204
2025-05-10 21:32:08,150 - INFO - Query received: La liberté de commerce extérieur est-elle totale et inconditionnelle?
2025-05-10 21:32:08,625 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5763)
2025-05-10 21:32:08,661 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:32:08,661 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:32:11,974 - INFO - Token usage: prompt=1597, completion=753, total=2350
2025-05-10 21:32:11,983 - INFO - Agent workflow completed in 4.49s
2025-05-10 21:32:12,048 - INFO - Request processed in 4.55s (thinking: 3.32s)
2025-05-10 21:32:12,049 - INFO - 127.0.0.1 - - [10/May/2025 21:32:12] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:32:22,108 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:32:22,446 - INFO - Token usage: prompt=65, completion=15, total=80
2025-05-10 21:32:22,481 - INFO - Processing query: 'Quelles sont les implications du principe de liberté du commerce extérieur pour les acteurs économiques?' for conversation 205
2025-05-10 21:32:22,483 - INFO - Query received: Quelles sont les implications du principe de liberté du commerce extérieur pour les acteurs économiques?
2025-05-10 21:32:23,698 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6284)
2025-05-10 21:32:23,817 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:32:23,818 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:32:23,944 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:32:23,944 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:32:26,284 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:32:26,286 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:32:30,888 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:32:30,889 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:32:30,891 - INFO - Agent workflow completed in 8.78s
2025-05-10 21:32:30,892 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:32:30,894 - INFO - 127.0.0.1 - - [10/May/2025 21:32:30] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:32:33,924 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:32:34,442 - INFO - Token usage: prompt=65, completion=18, total=83
2025-05-10 21:32:34,486 - INFO - Processing query: 'Quelles sont les implications du principe de liberté du commerce extérieur pour les acteurs économiques?' for conversation 206
2025-05-10 21:32:34,490 - INFO - Query received: Quelles sont les implications du principe de liberté du commerce extérieur pour les acteurs économiques?
2025-05-10 21:32:35,673 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6284)
2025-05-10 21:32:35,783 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:32:35,785 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:32:39,983 - INFO - Token usage: prompt=1647, completion=1049, total=2696
2025-05-10 21:32:39,994 - INFO - Agent workflow completed in 6.07s
2025-05-10 21:32:40,261 - INFO - Request processed in 6.34s (thinking: 4.22s)
2025-05-10 21:32:40,263 - INFO - 127.0.0.1 - - [10/May/2025 21:32:40] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:32:50,382 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:32:51,060 - INFO - Token usage: prompt=67, completion=15, total=82
2025-05-10 21:32:51,108 - INFO - Processing query: 'Quelles catégories de produits sont explicitement exclues du régime de la liberté de commerce extérieur?' for conversation 207
2025-05-10 21:32:51,110 - INFO - Query received: Quelles catégories de produits sont explicitement exclues du régime de la liberté de commerce extérieur?
2025-05-10 21:32:52,260 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6783)
2025-05-10 21:32:52,384 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:32:52,385 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:32:54,234 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:32:54,234 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:32:56,606 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:32:56,606 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:33:03,866 - INFO - Token usage: prompt=1604, completion=722, total=2326
2025-05-10 21:33:03,879 - INFO - Agent workflow completed in 13.50s
2025-05-10 21:33:03,966 - INFO - Request processed in 13.58s (thinking: 11.51s)
2025-05-10 21:33:03,967 - INFO - 127.0.0.1 - - [10/May/2025 21:33:03] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:33:14,053 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:33:15,126 - INFO - Token usage: prompt=70, completion=18, total=88
2025-05-10 21:33:15,172 - INFO - Processing query: 'Comment la liste précise des produits exclus du régime de la liberté de commerce est-elle déterminée?' for conversation 208
2025-05-10 21:33:15,175 - INFO - Query received: Comment la liste précise des produits exclus du régime de la liberté de commerce est-elle déterminée?
2025-05-10 21:33:16,336 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6279)
2025-05-10 21:33:16,446 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:33:16,446 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:33:16,908 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:33:16,908 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:33:19,328 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:33:19,329 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:33:26,598 - INFO - Token usage: prompt=1449, completion=767, total=2216
2025-05-10 21:33:26,632 - INFO - Agent workflow completed in 12.58s
2025-05-10 21:33:26,765 - INFO - Request processed in 12.71s (thinking: 10.19s)
2025-05-10 21:33:26,766 - INFO - 127.0.0.1 - - [10/May/2025 21:33:26] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:33:36,880 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:33:37,429 - INFO - Token usage: prompt=71, completion=13, total=84
2025-05-10 21:33:37,468 - INFO - Processing query: 'Quelle est la justification derrière l'exclusion de certaines catégories de produits du régime de la liberté de commerce extérieur?' for conversation 209
2025-05-10 21:33:37,471 - INFO - Query received: Quelle est la justification derrière l'exclusion de certaines catégories de produits du régime de la liberté de commerce extérieur?
2025-05-10 21:33:37,963 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6760)
2025-05-10 21:33:38,004 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:33:38,004 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:33:38,548 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:33:38,549 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:33:41,952 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:33:41,953 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:33:50,459 - INFO - Token usage: prompt=1610, completion=828, total=2438
2025-05-10 21:33:50,471 - INFO - Agent workflow completed in 13.59s
2025-05-10 21:33:50,533 - INFO - Request processed in 13.65s (thinking: 12.47s)
2025-05-10 21:33:50,534 - INFO - 127.0.0.1 - - [10/May/2025 21:33:50] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:34:00,570 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:34:01,820 - INFO - Token usage: prompt=78, completion=18, total=96
2025-05-10 21:34:01,865 - INFO - Processing query: 'Qui est habilité à réaliser des opérations d'importation et d'exportation de produits, en dehors des opérations occasionnelles sans caractère commercial?' for conversation 210
2025-05-10 21:34:01,867 - INFO - Query received: Qui est habilité à réaliser des opérations d'importation et d'exportation de produits, en dehors des opérations occasionnelles sans caractère commercial?
2025-05-10 21:34:02,327 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5360)
2025-05-10 21:34:02,368 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:34:02,369 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:34:03,460 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:34:03,460 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:34:05,918 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:34:05,918 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:34:15,809 - INFO - Token usage: prompt=1485, completion=703, total=2188
2025-05-10 21:34:15,817 - INFO - Agent workflow completed in 15.25s
2025-05-10 21:34:15,862 - INFO - Request processed in 15.29s (thinking: 13.45s)
2025-05-10 21:34:15,864 - INFO - 127.0.0.1 - - [10/May/2025 21:34:15] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:34:25,918 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:34:26,602 - INFO - Token usage: prompt=76, completion=15, total=91
2025-05-10 21:34:26,636 - INFO - Processing query: 'Des conditions spécifiques sont-elles imposées aux personnes physiques ou morales souhaitant effectuer des opérations d'importation ou d'exportation?' for conversation 211
2025-05-10 21:34:26,637 - INFO - Query received: Des conditions spécifiques sont-elles imposées aux personnes physiques ou morales souhaitant effectuer des opérations d'importation ou d'exportation?
2025-05-10 21:34:27,067 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5669)
2025-05-10 21:34:27,105 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:34:27,106 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:34:28,664 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:34:28,665 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:34:34,610 - INFO - Token usage: prompt=1543, completion=954, total=2497
2025-05-10 21:34:34,616 - INFO - Agent workflow completed in 8.70s
2025-05-10 21:34:34,724 - INFO - Request processed in 8.81s (thinking: 7.51s)
2025-05-10 21:34:34,725 - INFO - 127.0.0.1 - - [10/May/2025 21:34:34] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:34:44,814 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:34:46,070 - INFO - Token usage: prompt=74, completion=17, total=91
2025-05-10 21:34:46,108 - INFO - Processing query: 'Une exception est-elle prévue concernant les personnes habilitées à réaliser des opérations d'importation et d'exportation?' for conversation 212
2025-05-10 21:34:46,111 - INFO - Query received: Une exception est-elle prévue concernant les personnes habilitées à réaliser des opérations d'importation et d'exportation?
2025-05-10 21:34:46,573 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5915)
2025-05-10 21:34:46,614 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:34:46,614 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:34:46,979 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:34:46,979 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:34:49,294 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:34:49,294 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:34:56,143 - INFO - Token usage: prompt=1410, completion=668, total=2078
2025-05-10 21:34:56,155 - INFO - Agent workflow completed in 11.34s
2025-05-10 21:34:56,227 - INFO - Request processed in 11.41s (thinking: 9.54s)
2025-05-10 21:34:56,230 - INFO - 127.0.0.1 - - [10/May/2025 21:34:56] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:35:06,304 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:35:06,987 - INFO - Token usage: prompt=74, completion=15, total=89
2025-05-10 21:35:07,037 - INFO - Processing query: 'Quel mécanisme est mis en place pour l'importation ou l'exportation des produits exclus du régime de la liberté?' for conversation 213
2025-05-10 21:35:07,039 - INFO - Query received: Quel mécanisme est mis en place pour l'importation ou l'exportation des produits exclus du régime de la liberté?
2025-05-10 21:35:08,218 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6960)
2025-05-10 21:35:08,324 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:35:08,324 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:35:08,894 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:35:08,895 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:35:11,762 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:35:11,762 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:35:20,262 - INFO - Token usage: prompt=1610, completion=736, total=2346
2025-05-10 21:35:20,270 - INFO - Agent workflow completed in 13.97s
2025-05-10 21:35:20,326 - INFO - Request processed in 14.02s (thinking: 11.95s)
2025-05-10 21:35:20,327 - INFO - 127.0.0.1 - - [10/May/2025 21:35:20] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:35:30,375 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:35:30,998 - INFO - Token usage: prompt=78, completion=19, total=97
2025-05-10 21:35:31,045 - INFO - Processing query: 'Quelle autorité est compétente pour accorder les autorisations d'importation et d'exportation des produits exclus du régime de la liberté?' for conversation 214
2025-05-10 21:35:31,048 - INFO - Query received: Quelle autorité est compétente pour accorder les autorisations d'importation et d'exportation des produits exclus du régime de la liberté?
2025-05-10 21:35:32,297 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6835)
2025-05-10 21:35:32,419 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:35:32,419 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:35:33,268 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:35:33,268 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:35:35,726 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:35:35,726 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:35:42,890 - INFO - Token usage: prompt=1613, completion=687, total=2300
2025-05-10 21:35:42,896 - INFO - Agent workflow completed in 12.52s
2025-05-10 21:35:42,930 - INFO - Request processed in 12.55s (thinking: 10.49s)
2025-05-10 21:35:42,931 - INFO - 127.0.0.1 - - [10/May/2025 21:35:42] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:35:52,966 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:35:53,389 - INFO - Token usage: prompt=82, completion=20, total=102
2025-05-10 21:35:53,436 - INFO - Processing query: 'Quelle est la conséquence directe de l'exclusion d'un produit du régime de la liberté en ce qui concerne sa procédure d'importation ou d'exportation?' for conversation 215
2025-05-10 21:35:53,441 - INFO - Query received: Quelle est la conséquence directe de l'exclusion d'un produit du régime de la liberté en ce qui concerne sa procédure d'importation ou d'exportation?
2025-05-10 21:35:54,699 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6673)
2025-05-10 21:35:54,834 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:35:54,835 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:35:55,006 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:35:55,006 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:35:57,534 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:35:57,536 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:36:02,551 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:36:02,551 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:36:02,552 - INFO - Agent workflow completed in 9.59s
2025-05-10 21:36:02,553 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:36:02,554 - INFO - 127.0.0.1 - - [10/May/2025 21:36:02] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:36:05,577 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:36:07,464 - INFO - Token usage: prompt=82, completion=19, total=101
2025-05-10 21:36:07,505 - INFO - Processing query: 'Quelle est la conséquence directe de l'exclusion d'un produit du régime de la liberté en ce qui concerne sa procédure d'importation ou d'exportation?' for conversation 216
2025-05-10 21:36:07,508 - INFO - Query received: Quelle est la conséquence directe de l'exclusion d'un produit du régime de la liberté en ce qui concerne sa procédure d'importation ou d'exportation?
2025-05-10 21:36:07,911 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6673)
2025-05-10 21:36:07,953 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:36:07,954 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:36:11,160 - INFO - Token usage: prompt=1708, completion=665, total=2373
2025-05-10 21:36:18,058 - INFO - Agent workflow completed in 12.48s
2025-05-10 21:36:18,108 - INFO - Request processed in 12.53s (thinking: 10.11s)
2025-05-10 21:36:18,109 - INFO - 127.0.0.1 - - [10/May/2025 21:36:18] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:36:28,161 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:36:28,743 - INFO - Token usage: prompt=70, completion=16, total=86
2025-05-10 21:36:28,788 - INFO - Processing query: 'Comment sont déterminées les modalités relatives à la réalisation des opérations d'importation et d'exportation?' for conversation 217
2025-05-10 21:36:28,790 - INFO - Query received: Comment sont déterminées les modalités relatives à la réalisation des opérations d'importation et d'exportation?
2025-05-10 21:36:29,343 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5693)
2025-05-10 21:36:29,391 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:36:29,391 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:36:30,917 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:36:30,917 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:36:33,476 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:36:33,477 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:36:41,976 - INFO - Token usage: prompt=2533, completion=953, total=3486
2025-05-10 21:36:41,984 - INFO - Agent workflow completed in 13.82s
2025-05-10 21:36:42,064 - INFO - Request processed in 13.90s (thinking: 12.59s)
2025-05-10 21:36:42,065 - INFO - 127.0.0.1 - - [10/May/2025 21:36:42] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:36:52,150 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:36:52,684 - INFO - Token usage: prompt=81, completion=13, total=94
2025-05-10 21:36:52,728 - INFO - Processing query: 'Quel type d'informations peut-on s'attendre à trouver dans le décret mentionné concernant les modalités des opérations d'importation et d'exportation?' for conversation 218
2025-05-10 21:36:52,731 - INFO - Query received: Quel type d'informations peut-on s'attendre à trouver dans le décret mentionné concernant les modalités des opérations d'importation et d'exportation?
2025-05-10 21:36:53,847 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5906)
2025-05-10 21:36:54,024 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:36:54,024 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:36:54,153 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:36:54,153 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:36:56,604 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:36:56,605 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:37:04,059 - INFO - Token usage: prompt=1486, completion=679, total=2165
2025-05-10 21:37:04,074 - INFO - Agent workflow completed in 11.92s
2025-05-10 21:37:04,165 - INFO - Request processed in 12.02s (thinking: 10.07s)
2025-05-10 21:37:04,167 - INFO - 127.0.0.1 - - [10/May/2025 21:37:04] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:47:54,712 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:47:55,280 - INFO - Token usage: prompt=91, completion=19, total=110
2025-05-10 21:47:55,316 - INFO - Processing query: 'Dans quel délai un importateur peut-il demander le remboursement des droits perçus en dépassement de la marge de dumping ou du montant réel de la subvention, selon la législation tunisienne ?' for conversation 219
2025-05-10 21:47:55,320 - INFO - Query received: Dans quel délai un importateur peut-il demander le remboursement des droits perçus en dépassement de la marge de dumping ou du montant réel de la subvention, selon la législation tunisienne ?
2025-05-10 21:47:55,840 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.6574)
2025-05-10 21:47:55,897 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:47:55,897 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:47:57,766 - INFO - Token usage: prompt=2458, completion=337, total=2795
2025-05-10 21:47:57,773 - INFO - Agent workflow completed in 3.06s
2025-05-10 21:47:57,807 - INFO - Request processed in 3.10s (thinking: 1.88s)
2025-05-10 21:47:57,808 - INFO - 127.0.0.1 - - [10/May/2025 21:47:57] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:54:05,083 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:54:06,508 - INFO - Token usage: prompt=91, completion=21, total=112
2025-05-10 21:54:06,552 - INFO - Processing query: 'Dans quel délai un importateur peut-il demander le remboursement des droits perçus en dépassement de la marge de dumping ou du montant réel de la subvention, selon la législation tunisienne ?' for conversation 220
2025-05-10 21:54:06,555 - INFO - Query received: Dans quel délai un importateur peut-il demander le remboursement des droits perçus en dépassement de la marge de dumping ou du montant réel de la subvention, selon la législation tunisienne ?
2025-05-10 21:54:07,041 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.6574)
2025-05-10 21:54:07,094 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:54:07,094 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:54:09,712 - INFO - Token usage: prompt=2458, completion=554, total=3012
2025-05-10 21:54:09,717 - INFO - Agent workflow completed in 4.63s
2025-05-10 21:54:09,751 - INFO - Request processed in 4.67s (thinking: 2.63s)
2025-05-10 21:54:09,752 - INFO - 127.0.0.1 - - [10/May/2025 21:54:09] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:54:19,841 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:54:20,585 - INFO - Token usage: prompt=83, completion=19, total=102
2025-05-10 21:54:20,633 - INFO - Processing query: 'Selon la législation tunisienne, quelles obligations peuvent être imposées aux exportateurs après l'acceptation d'un engagement en matière de prix ou de subvention ?' for conversation 221
2025-05-10 21:54:20,635 - INFO - Query received: Selon la législation tunisienne, quelles obligations peuvent être imposées aux exportateurs après l'acceptation d'un engagement en matière de prix ou de subvention ?
2025-05-10 21:54:21,101 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.6779)
2025-05-10 21:54:21,153 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:54:21,153 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:54:25,705 - INFO - Token usage: prompt=2501, completion=1005, total=3506
2025-05-10 21:54:25,712 - INFO - Agent workflow completed in 5.87s
2025-05-10 21:54:25,799 - INFO - Request processed in 5.96s (thinking: 4.56s)
2025-05-10 21:54:25,800 - INFO - 127.0.0.1 - - [10/May/2025 21:54:25] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:54:35,847 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:54:36,504 - INFO - Token usage: prompt=85, completion=25, total=110
2025-05-10 21:54:36,544 - INFO - Processing query: 'Dans quelles conditions un droit antidumping ou un droit compensateur définitif peut-il être institué en Tunisie, et comment son montant est-il déterminé selon la loi ?' for conversation 222
2025-05-10 21:54:36,545 - INFO - Query received: Dans quelles conditions un droit antidumping ou un droit compensateur définitif peut-il être institué en Tunisie, et comment son montant est-il déterminé selon la loi ?
2025-05-10 21:54:37,199 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6831)
2025-05-10 21:54:37,253 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:54:37,253 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:54:39,837 - INFO - Token usage: prompt=1567, completion=468, total=2035
2025-05-10 21:54:39,844 - INFO - Agent workflow completed in 4.00s
2025-05-10 21:54:39,880 - INFO - Request processed in 4.03s (thinking: 2.60s)
2025-05-10 21:54:39,882 - INFO - 127.0.0.1 - - [10/May/2025 21:54:39] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:54:49,923 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:54:50,407 - INFO - Token usage: prompt=81, completion=18, total=99
2025-05-10 21:54:50,440 - INFO - Processing query: 'Quelles sont les conditions requises pour qu'un engagement en matière de prix soit accepté dans le cadre d'une enquête pour dumping ou subvention en Tunisie ?' for conversation 223
2025-05-10 21:54:50,442 - INFO - Query received: Quelles sont les conditions requises pour qu'un engagement en matière de prix soit accepté dans le cadre d'une enquête pour dumping ou subvention en Tunisie ?
2025-05-10 21:54:50,909 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6418)
2025-05-10 21:54:50,972 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:54:50,973 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:54:55,137 - INFO - Token usage: prompt=1563, completion=863, total=2426
2025-05-10 21:54:55,144 - INFO - Agent workflow completed in 5.22s
2025-05-10 21:54:55,196 - INFO - Request processed in 5.27s (thinking: 4.18s)
2025-05-10 21:54:55,196 - INFO - 127.0.0.1 - - [10/May/2025 21:54:55] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:55:05,238 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:55:05,861 - INFO - Token usage: prompt=97, completion=25, total=122
2025-05-10 21:55:05,905 - INFO - Processing query: 'Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?' for conversation 224
2025-05-10 21:55:05,906 - INFO - Query received: Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?
2025-05-10 21:55:06,346 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7009)
2025-05-10 21:55:06,402 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:55:06,402 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:55:07,011 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:55:07,011 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:55:10,251 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:55:10,251 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:55:16,215 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:55:16,215 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:55:16,216 - INFO - Agent workflow completed in 10.98s
2025-05-10 21:55:16,216 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:55:16,218 - INFO - 127.0.0.1 - - [10/May/2025 21:55:16] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:55:19,226 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:55:19,767 - INFO - Token usage: prompt=97, completion=20, total=117
2025-05-10 21:55:19,812 - INFO - Processing query: 'Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?' for conversation 225
2025-05-10 21:55:19,814 - INFO - Query received: Quelles sont les obligations des exportateurs après l’acceptation d’un engagement en matière de prix ou de subvention, et quelles sont les conséquences juridiques en cas de violation ou de retrait de cet engagement selon la législation tunisienne ?
2025-05-10 21:55:20,318 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.7009)
2025-05-10 21:55:20,377 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:55:20,378 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:55:20,798 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:55:20,798 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:55:23,972 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:55:23,973 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:55:32,569 - INFO - Token usage: prompt=2519, completion=1053, total=3572
2025-05-10 21:55:32,577 - INFO - Agent workflow completed in 13.35s
2025-05-10 21:55:32,671 - INFO - Request processed in 13.45s (thinking: 12.21s)
2025-05-10 21:55:32,673 - INFO - 127.0.0.1 - - [10/May/2025 21:55:32] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:55:42,741 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:55:44,144 - INFO - Token usage: prompt=81, completion=20, total=101
2025-05-10 21:55:44,191 - INFO - Processing query: 'Quels sont les recours juridiques possibles pour contester les décisions prises dans le cadre des procédures antidumping ou de subvention, selon la législation tunisienne ?' for conversation 226
2025-05-10 21:55:44,193 - INFO - Query received: Quels sont les recours juridiques possibles pour contester les décisions prises dans le cadre des procédures antidumping ou de subvention, selon la législation tunisienne ?
2025-05-10 21:55:44,699 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.7332)
2025-05-10 21:55:44,747 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:55:44,747 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:55:47,314 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:55:47,314 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:55:49,617 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:55:49,618 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:55:56,500 - INFO - Token usage: prompt=1570, completion=607, total=2177
2025-05-10 21:55:56,510 - INFO - Agent workflow completed in 13.77s
2025-05-10 21:55:56,562 - INFO - Request processed in 13.82s (thinking: 11.77s)
2025-05-10 21:55:56,563 - INFO - 127.0.0.1 - - [10/May/2025 21:55:56] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:56:06,625 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:56:07,341 - INFO - Token usage: prompt=79, completion=27, total=106
2025-05-10 21:56:07,372 - INFO - Processing query: 'Quelles dispositions légales antérieures sont abrogées par la loi tunisienne relative à la défense contre les pratiques déloyales à l'importation ?' for conversation 227
2025-05-10 21:56:07,373 - INFO - Query received: Quelles dispositions légales antérieures sont abrogées par la loi tunisienne relative à la défense contre les pratiques déloyales à l'importation ?
2025-05-10 21:56:07,845 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.8111)
2025-05-10 21:56:07,897 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:56:07,898 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:56:08,656 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:56:08,657 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:56:10,796 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:56:10,797 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:56:19,313 - INFO - Token usage: prompt=1934, completion=634, total=2568
2025-05-10 21:56:19,326 - INFO - Agent workflow completed in 12.70s
2025-05-10 21:56:19,371 - INFO - Request processed in 12.75s (thinking: 11.43s)
2025-05-10 21:56:19,372 - INFO - 127.0.0.1 - - [10/May/2025 21:56:19] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:56:29,412 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:56:30,635 - INFO - Token usage: prompt=70, completion=15, total=85
2025-05-10 21:56:30,680 - INFO - Processing query: 'Quel est le délai accordé au ministère des finances pour procéder au remboursement selon l'article 48 ?' for conversation 228
2025-05-10 21:56:30,682 - INFO - Query received: Quel est le délai accordé au ministère des finances pour procéder au remboursement selon l'article 48 ?
2025-05-10 21:56:31,153 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3369)
2025-05-10 21:56:31,192 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:56:31,192 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:56:32,578 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:56:32,578 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:56:34,972 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:56:34,972 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:56:43,638 - INFO - Token usage: prompt=1556, completion=333, total=1889
2025-05-10 21:56:43,649 - INFO - Agent workflow completed in 14.24s
2025-05-10 21:56:43,683 - INFO - Request processed in 14.27s (thinking: 12.46s)
2025-05-10 21:56:43,684 - INFO - 127.0.0.1 - - [10/May/2025 21:56:43] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:56:53,755 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:56:55,312 - INFO - Token usage: prompt=78, completion=21, total=99
2025-05-10 21:56:55,363 - INFO - Processing query: 'Dans quelles conditions les droits antidumping et compensateurs définitifs peuvent-ils être réexaminés selon l'article 42 ?' for conversation 229
2025-05-10 21:56:55,365 - INFO - Query received: Dans quelles conditions les droits antidumping et compensateurs définitifs peuvent-ils être réexaminés selon l'article 42 ?
2025-05-10 21:56:56,612 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6171)
2025-05-10 21:56:56,745 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:56:56,746 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:56:57,127 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:56:57,127 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:56:59,287 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:56:59,287 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:57:09,545 - INFO - Token usage: prompt=1941, completion=721, total=2662
2025-05-10 21:57:09,562 - INFO - Agent workflow completed in 15.81s
2025-05-10 21:57:09,637 - INFO - Request processed in 15.88s (thinking: 12.83s)
2025-05-10 21:57:09,639 - INFO - 127.0.0.1 - - [10/May/2025 21:57:09] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:57:19,721 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:57:20,254 - INFO - Token usage: prompt=66, completion=10, total=76
2025-05-10 21:57:20,306 - INFO - Processing query: 'Quel est le principe général régissant les importations et les exportations de produits?' for conversation 230
2025-05-10 21:57:20,308 - INFO - Query received: Quel est le principe général régissant les importations et les exportations de produits?
2025-05-10 21:57:21,479 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6423)
2025-05-10 21:57:21,594 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:57:21,594 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:57:22,779 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:57:22,779 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:57:25,420 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:57:25,420 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:57:29,867 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:57:29,867 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:57:29,870 - INFO - Agent workflow completed in 10.15s
2025-05-10 21:57:29,870 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:57:29,873 - INFO - 127.0.0.1 - - [10/May/2025 21:57:29] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:57:32,899 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:57:33,589 - INFO - Token usage: prompt=66, completion=13, total=79
2025-05-10 21:57:33,639 - INFO - Processing query: 'Quel est le principe général régissant les importations et les exportations de produits?' for conversation 231
2025-05-10 21:57:33,642 - INFO - Query received: Quel est le principe général régissant les importations et les exportations de produits?
2025-05-10 21:57:34,760 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6423)
2025-05-10 21:57:34,866 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:57:34,866 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:57:36,376 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:57:36,376 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:57:42,926 - INFO - Token usage: prompt=2974, completion=1037, total=4011
2025-05-10 21:57:42,938 - INFO - Agent workflow completed in 10.04s
2025-05-10 21:57:43,112 - INFO - Request processed in 10.21s (thinking: 8.08s)
2025-05-10 21:57:43,114 - INFO - 127.0.0.1 - - [10/May/2025 21:57:43] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:57:53,219 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:57:53,556 - INFO - Token usage: prompt=63, completion=16, total=79
2025-05-10 21:57:53,603 - INFO - Processing query: 'La liberté de commerce extérieur est-elle totale et inconditionnelle?' for conversation 232
2025-05-10 21:57:53,606 - INFO - Query received: La liberté de commerce extérieur est-elle totale et inconditionnelle?
2025-05-10 21:57:54,828 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5763)
2025-05-10 21:57:54,941 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:57:54,941 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:57:55,084 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:57:55,085 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:57:57,220 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:57:57,221 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:58:01,434 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:58:01,434 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:58:01,436 - INFO - Agent workflow completed in 8.22s
2025-05-10 21:58:01,436 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:58:01,439 - INFO - 127.0.0.1 - - [10/May/2025 21:58:01] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:58:04,453 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:58:04,799 - INFO - Token usage: prompt=63, completion=16, total=79
2025-05-10 21:58:04,845 - INFO - Processing query: 'La liberté de commerce extérieur est-elle totale et inconditionnelle?' for conversation 233
2025-05-10 21:58:04,849 - INFO - Query received: La liberté de commerce extérieur est-elle totale et inconditionnelle?
2025-05-10 21:58:06,117 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5763)
2025-05-10 21:58:06,227 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:58:06,227 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:58:09,790 - INFO - Token usage: prompt=1597, completion=886, total=2483
2025-05-10 21:58:09,803 - INFO - Agent workflow completed in 5.35s
2025-05-10 21:58:09,976 - INFO - Request processed in 5.52s (thinking: 3.58s)
2025-05-10 21:58:09,978 - INFO - 127.0.0.1 - - [10/May/2025 21:58:09] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:58:20,082 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:58:21,432 - INFO - Token usage: prompt=65, completion=15, total=80
2025-05-10 21:58:21,487 - INFO - Processing query: 'Quelles sont les implications du principe de liberté du commerce extérieur pour les acteurs économiques?' for conversation 234
2025-05-10 21:58:21,489 - INFO - Query received: Quelles sont les implications du principe de liberté du commerce extérieur pour les acteurs économiques?
2025-05-10 21:58:22,695 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6284)
2025-05-10 21:58:22,811 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:58:22,811 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:58:24,298 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:58:24,298 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:58:26,972 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:58:26,972 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:58:34,735 - INFO - Token usage: prompt=1647, completion=926, total=2573
2025-05-10 21:58:34,747 - INFO - Agent workflow completed in 14.66s
2025-05-10 21:58:34,919 - INFO - Request processed in 14.84s (thinking: 11.94s)
2025-05-10 21:58:34,922 - INFO - 127.0.0.1 - - [10/May/2025 21:58:34] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:58:45,029 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:58:45,817 - INFO - Token usage: prompt=67, completion=15, total=82
2025-05-10 21:58:45,870 - INFO - Processing query: 'Quelles catégories de produits sont explicitement exclues du régime de la liberté de commerce extérieur?' for conversation 235
2025-05-10 21:58:45,875 - INFO - Query received: Quelles catégories de produits sont explicitement exclues du régime de la liberté de commerce extérieur?
2025-05-10 21:58:47,195 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6783)
2025-05-10 21:58:47,302 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:58:47,302 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:58:47,742 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:58:47,742 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:58:49,882 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:58:49,882 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:58:54,048 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:58:54,049 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 21:58:54,050 - INFO - Agent workflow completed in 9.02s
2025-05-10 21:58:54,052 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 21:58:54,055 - INFO - 127.0.0.1 - - [10/May/2025 21:58:54] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 21:58:57,070 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:58:57,687 - INFO - Token usage: prompt=67, completion=13, total=80
2025-05-10 21:58:57,738 - INFO - Processing query: 'Quelles catégories de produits sont explicitement exclues du régime de la liberté de commerce extérieur?' for conversation 236
2025-05-10 21:58:57,741 - INFO - Query received: Quelles catégories de produits sont explicitement exclues du régime de la liberté de commerce extérieur?
2025-05-10 21:58:59,018 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6783)
2025-05-10 21:58:59,148 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:58:59,148 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:59:04,654 - INFO - Token usage: prompt=1604, completion=1124, total=2728
2025-05-10 21:59:04,670 - INFO - Agent workflow completed in 7.60s
2025-05-10 21:59:04,893 - INFO - Request processed in 7.82s (thinking: 5.53s)
2025-05-10 21:59:04,895 - INFO - 127.0.0.1 - - [10/May/2025 21:59:04] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:59:15,017 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:59:15,565 - INFO - Token usage: prompt=70, completion=19, total=89
2025-05-10 21:59:15,609 - INFO - Processing query: 'Comment la liste précise des produits exclus du régime de la liberté de commerce est-elle déterminée?' for conversation 237
2025-05-10 21:59:15,612 - INFO - Query received: Comment la liste précise des produits exclus du régime de la liberté de commerce est-elle déterminée?
2025-05-10 21:59:16,845 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6279)
2025-05-10 21:59:16,962 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:59:16,962 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:59:17,353 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:59:17,354 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:59:19,737 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:59:19,738 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 21:59:27,687 - INFO - Token usage: prompt=1449, completion=836, total=2285
2025-05-10 21:59:27,702 - INFO - Agent workflow completed in 12.68s
2025-05-10 21:59:27,826 - INFO - Request processed in 12.81s (thinking: 10.75s)
2025-05-10 21:59:27,828 - INFO - 127.0.0.1 - - [10/May/2025 21:59:27] "POST /ask HTTP/1.1" 200 -
2025-05-10 21:59:37,935 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 21:59:38,604 - INFO - Token usage: prompt=71, completion=14, total=85
2025-05-10 21:59:38,652 - INFO - Processing query: 'Quelle est la justification derrière l'exclusion de certaines catégories de produits du régime de la liberté de commerce extérieur?' for conversation 238
2025-05-10 21:59:38,657 - INFO - Query received: Quelle est la justification derrière l'exclusion de certaines catégories de produits du régime de la liberté de commerce extérieur?
2025-05-10 21:59:39,584 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6760)
2025-05-10 21:59:39,689 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 21:59:39,689 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 21:59:40,586 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:59:40,587 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 21:59:42,988 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 21:59:42,988 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:00:01,490 - ERROR - HTTP error occurred: 500 Server Error: Internal Server Error for url: https://api.groq.com/openai/v1/chat/completions (Status code: 500)
2025-05-10 22:00:01,491 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 500 Server Error: Internal Server Error for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:00:01,493 - INFO - Agent workflow completed in 23.56s
2025-05-10 22:00:01,494 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:00:01,497 - INFO - 127.0.0.1 - - [10/May/2025 22:00:01] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:00:04,516 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:00:05,322 - INFO - Token usage: prompt=71, completion=14, total=85
2025-05-10 22:00:05,362 - INFO - Processing query: 'Quelle est la justification derrière l'exclusion de certaines catégories de produits du régime de la liberté de commerce extérieur?' for conversation 239
2025-05-10 22:00:05,366 - INFO - Query received: Quelle est la justification derrière l'exclusion de certaines catégories de produits du régime de la liberté de commerce extérieur?
2025-05-10 22:00:06,552 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6760)
2025-05-10 22:00:06,679 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:00:06,680 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:00:12,401 - INFO - Token usage: prompt=1610, completion=841, total=2451
2025-05-10 22:00:12,414 - INFO - Agent workflow completed in 7.90s
2025-05-10 22:00:12,511 - INFO - Request processed in 7.99s (thinking: 5.75s)
2025-05-10 22:00:12,513 - INFO - 127.0.0.1 - - [10/May/2025 22:00:12] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:00:22,619 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:00:23,491 - INFO - Token usage: prompt=78, completion=14, total=92
2025-05-10 22:00:23,543 - INFO - Processing query: 'Qui est habilité à réaliser des opérations d'importation et d'exportation de produits, en dehors des opérations occasionnelles sans caractère commercial?' for conversation 240
2025-05-10 22:00:23,547 - INFO - Query received: Qui est habilité à réaliser des opérations d'importation et d'exportation de produits, en dehors des opérations occasionnelles sans caractère commercial?
2025-05-10 22:00:24,788 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5360)
2025-05-10 22:00:24,905 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:00:24,905 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:00:29,037 - INFO - Token usage: prompt=1485, completion=778, total=2263
2025-05-10 22:00:29,047 - INFO - Agent workflow completed in 6.43s
2025-05-10 22:00:29,154 - INFO - Request processed in 6.53s (thinking: 4.15s)
2025-05-10 22:00:29,155 - INFO - 127.0.0.1 - - [10/May/2025 22:00:29] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:00:39,246 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:00:39,852 - INFO - Token usage: prompt=76, completion=15, total=91
2025-05-10 22:00:39,900 - INFO - Processing query: 'Des conditions spécifiques sont-elles imposées aux personnes physiques ou morales souhaitant effectuer des opérations d'importation ou d'exportation?' for conversation 241
2025-05-10 22:00:39,902 - INFO - Query received: Des conditions spécifiques sont-elles imposées aux personnes physiques ou morales souhaitant effectuer des opérations d'importation ou d'exportation?
2025-05-10 22:00:41,090 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5669)
2025-05-10 22:00:41,348 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:00:41,349 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:00:47,562 - INFO - Token usage: prompt=1543, completion=690, total=2233
2025-05-10 22:00:47,574 - INFO - Agent workflow completed in 8.33s
2025-05-10 22:00:47,643 - INFO - Request processed in 8.40s (thinking: 6.25s)
2025-05-10 22:00:47,646 - INFO - 127.0.0.1 - - [10/May/2025 22:00:47] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:00:57,709 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:00:58,614 - INFO - Token usage: prompt=74, completion=13, total=87
2025-05-10 22:00:58,658 - INFO - Processing query: 'Une exception est-elle prévue concernant les personnes habilitées à réaliser des opérations d'importation et d'exportation?' for conversation 242
2025-05-10 22:00:58,660 - INFO - Query received: Une exception est-elle prévue concernant les personnes habilitées à réaliser des opérations d'importation et d'exportation?
2025-05-10 22:00:59,988 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5915)
2025-05-10 22:01:00,112 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:01:00,112 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:01:03,040 - INFO - Token usage: prompt=1410, completion=692, total=2102
2025-05-10 22:01:03,052 - INFO - Agent workflow completed in 5.34s
2025-05-10 22:01:03,151 - INFO - Request processed in 5.44s (thinking: 2.95s)
2025-05-10 22:01:03,153 - INFO - 127.0.0.1 - - [10/May/2025 22:01:03] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:01:13,243 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:01:14,199 - INFO - Token usage: prompt=74, completion=12, total=86
2025-05-10 22:01:14,245 - INFO - Processing query: 'Quel mécanisme est mis en place pour l'importation ou l'exportation des produits exclus du régime de la liberté?' for conversation 243
2025-05-10 22:01:14,248 - INFO - Query received: Quel mécanisme est mis en place pour l'importation ou l'exportation des produits exclus du régime de la liberté?
2025-05-10 22:01:15,456 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6960)
2025-05-10 22:01:15,579 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:01:15,579 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:01:18,993 - INFO - Token usage: prompt=1610, completion=751, total=2361
2025-05-10 22:01:19,004 - INFO - Agent workflow completed in 5.76s
2025-05-10 22:01:19,095 - INFO - Request processed in 5.85s (thinking: 3.44s)
2025-05-10 22:01:19,098 - INFO - 127.0.0.1 - - [10/May/2025 22:01:19] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:01:29,184 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:01:29,750 - INFO - Token usage: prompt=78, completion=19, total=97
2025-05-10 22:01:29,796 - INFO - Processing query: 'Quelle autorité est compétente pour accorder les autorisations d'importation et d'exportation des produits exclus du régime de la liberté?' for conversation 244
2025-05-10 22:01:29,798 - INFO - Query received: Quelle autorité est compétente pour accorder les autorisations d'importation et d'exportation des produits exclus du régime de la liberté?
2025-05-10 22:01:31,005 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6835)
2025-05-10 22:01:31,144 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:01:31,145 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:01:31,569 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:01:31,569 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:01:34,338 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:01:34,338 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:01:38,759 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:01:38,760 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:01:38,763 - INFO - Agent workflow completed in 9.58s
2025-05-10 22:01:38,763 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:01:38,766 - INFO - 127.0.0.1 - - [10/May/2025 22:01:38] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:01:41,791 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:01:42,339 - INFO - Token usage: prompt=78, completion=19, total=97
2025-05-10 22:01:42,380 - INFO - Processing query: 'Quelle autorité est compétente pour accorder les autorisations d'importation et d'exportation des produits exclus du régime de la liberté?' for conversation 245
2025-05-10 22:01:42,384 - INFO - Query received: Quelle autorité est compétente pour accorder les autorisations d'importation et d'exportation des produits exclus du régime de la liberté?
2025-05-10 22:01:43,597 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6835)
2025-05-10 22:01:43,732 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:01:43,733 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:01:47,113 - INFO - Token usage: prompt=1613, completion=659, total=2272
2025-05-10 22:01:47,128 - INFO - Agent workflow completed in 5.34s
2025-05-10 22:01:47,186 - INFO - Request processed in 5.40s (thinking: 3.41s)
2025-05-10 22:01:47,188 - INFO - 127.0.0.1 - - [10/May/2025 22:01:47] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:01:57,269 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:01:57,777 - INFO - Token usage: prompt=82, completion=24, total=106
2025-05-10 22:01:57,829 - INFO - Processing query: 'Quelle est la conséquence directe de l'exclusion d'un produit du régime de la liberté en ce qui concerne sa procédure d'importation ou d'exportation?' for conversation 246
2025-05-10 22:01:57,832 - INFO - Query received: Quelle est la conséquence directe de l'exclusion d'un produit du régime de la liberté en ce qui concerne sa procédure d'importation ou d'exportation?
2025-05-10 22:01:59,208 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6673)
2025-05-10 22:01:59,343 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:01:59,344 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:01:59,606 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:01:59,607 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:02:01,766 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:02:01,766 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:02:10,396 - INFO - Token usage: prompt=1708, completion=915, total=2623
2025-05-10 22:02:10,412 - INFO - Agent workflow completed in 13.14s
2025-05-10 22:02:10,515 - INFO - Request processed in 13.24s (thinking: 11.08s)
2025-05-10 22:02:10,516 - INFO - 127.0.0.1 - - [10/May/2025 22:02:10] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:02:20,603 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:02:21,603 - INFO - Token usage: prompt=70, completion=15, total=85
2025-05-10 22:02:21,655 - INFO - Processing query: 'Comment sont déterminées les modalités relatives à la réalisation des opérations d'importation et d'exportation?' for conversation 247
2025-05-10 22:02:21,657 - INFO - Query received: Comment sont déterminées les modalités relatives à la réalisation des opérations d'importation et d'exportation?
2025-05-10 22:02:22,858 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5693)
2025-05-10 22:02:22,976 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:02:22,976 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:02:23,120 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:02:23,121 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:02:25,656 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:02:25,657 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:02:29,812 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:02:29,813 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:02:29,815 - INFO - Agent workflow completed in 9.21s
2025-05-10 22:02:29,816 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:02:29,819 - INFO - 127.0.0.1 - - [10/May/2025 22:02:29] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:02:32,846 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:02:33,438 - INFO - Token usage: prompt=70, completion=15, total=85
2025-05-10 22:02:33,486 - INFO - Processing query: 'Comment sont déterminées les modalités relatives à la réalisation des opérations d'importation et d'exportation?' for conversation 248
2025-05-10 22:02:33,490 - INFO - Query received: Comment sont déterminées les modalités relatives à la réalisation des opérations d'importation et d'exportation?
2025-05-10 22:02:34,775 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.5693)
2025-05-10 22:02:34,898 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:02:34,899 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:02:35,040 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:02:35,040 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:02:41,777 - INFO - Token usage: prompt=2533, completion=1029, total=3562
2025-05-10 22:02:41,787 - INFO - Agent workflow completed in 8.94s
2025-05-10 22:02:41,982 - INFO - Request processed in 9.14s (thinking: 6.89s)
2025-05-10 22:02:41,984 - INFO - 127.0.0.1 - - [10/May/2025 22:02:41] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:02:52,106 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:02:52,809 - INFO - Token usage: prompt=81, completion=16, total=97
2025-05-10 22:02:52,851 - INFO - Processing query: 'Quel type d'informations peut-on s'attendre à trouver dans le décret mentionné concernant les modalités des opérations d'importation et d'exportation?' for conversation 249
2025-05-10 22:02:52,853 - INFO - Query received: Quel type d'informations peut-on s'attendre à trouver dans le décret mentionné concernant les modalités des opérations d'importation et d'exportation?
2025-05-10 22:02:54,070 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5906)
2025-05-10 22:02:55,349 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:02:55,350 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:02:55,980 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:02:55,980 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:02:58,629 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:02:58,629 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:03:08,052 - INFO - Token usage: prompt=1486, completion=732, total=2218
2025-05-10 22:03:08,065 - INFO - Agent workflow completed in 15.96s
2025-05-10 22:03:08,162 - INFO - Request processed in 16.06s (thinking: 12.74s)
2025-05-10 22:03:08,164 - INFO - 127.0.0.1 - - [10/May/2025 22:03:08] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:03:18,253 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:03:18,766 - INFO - Token usage: prompt=73, completion=20, total=93
2025-05-10 22:03:18,803 - INFO - Processing query: 'Pourquoi est-il nécessaire de fixer par décret les modalités de réalisation des opérations d'importation et d'exportation?' for conversation 250
2025-05-10 22:03:18,810 - INFO - Query received: Pourquoi est-il nécessaire de fixer par décret les modalités de réalisation des opérations d'importation et d'exportation?
2025-05-10 22:03:19,944 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6145)
2025-05-10 22:03:20,056 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:03:20,056 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:03:20,417 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:03:20,417 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:03:23,100 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:03:23,100 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:03:31,290 - INFO - Token usage: prompt=1639, completion=770, total=2409
2025-05-10 22:03:31,304 - INFO - Agent workflow completed in 13.05s
2025-05-10 22:03:31,387 - INFO - Request processed in 13.13s (thinking: 11.25s)
2025-05-10 22:03:31,390 - INFO - 127.0.0.1 - - [10/May/2025 22:03:31] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:03:41,462 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:03:42,497 - INFO - Token usage: prompt=72, completion=11, total=83
2025-05-10 22:03:42,541 - INFO - Processing query: 'À quelles procédures et modalités de règlement les opérations d'importation et d'exportation sont-elles soumises?' for conversation 251
2025-05-10 22:03:42,543 - INFO - Query received: À quelles procédures et modalités de règlement les opérations d'importation et d'exportation sont-elles soumises?
2025-05-10 22:03:43,171 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6107)
2025-05-10 22:03:43,233 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:03:43,234 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:03:47,928 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:03:47,929 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:03:50,255 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:03:50,255 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:03:54,741 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:03:54,742 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:03:54,743 - INFO - Agent workflow completed in 13.28s
2025-05-10 22:03:54,743 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:03:54,746 - INFO - 127.0.0.1 - - [10/May/2025 22:03:54] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:03:57,770 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:03:58,633 - INFO - Token usage: prompt=72, completion=18, total=90
2025-05-10 22:03:58,678 - INFO - Processing query: 'À quelles procédures et modalités de règlement les opérations d'importation et d'exportation sont-elles soumises?' for conversation 252
2025-05-10 22:03:58,681 - INFO - Query received: À quelles procédures et modalités de règlement les opérations d'importation et d'exportation sont-elles soumises?
2025-05-10 22:03:59,878 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6107)
2025-05-10 22:04:00,015 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:04:00,015 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:04:05,903 - INFO - Token usage: prompt=2246, completion=1268, total=3514
2025-05-10 22:04:05,917 - INFO - Agent workflow completed in 8.15s
2025-05-10 22:04:06,147 - INFO - Request processed in 8.38s (thinking: 5.92s)
2025-05-10 22:04:06,149 - INFO - 127.0.0.1 - - [10/May/2025 22:04:06] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:04:16,238 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:04:16,857 - INFO - Token usage: prompt=71, completion=12, total=83
2025-05-10 22:04:16,906 - INFO - Processing query: 'Quelle est l'importance de la législation de change pour les opérations d'importation et d'exportation?' for conversation 253
2025-05-10 22:04:16,911 - INFO - Query received: Quelle est l'importance de la législation de change pour les opérations d'importation et d'exportation?
2025-05-10 22:04:18,164 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5981)
2025-05-10 22:04:18,289 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:04:18,290 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:04:19,106 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:04:19,106 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:04:21,402 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:04:21,402 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:04:25,530 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:04:25,531 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:04:25,534 - INFO - Agent workflow completed in 9.30s
2025-05-10 22:04:25,534 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:04:25,537 - INFO - 127.0.0.1 - - [10/May/2025 22:04:25] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:04:28,554 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:04:28,971 - INFO - Token usage: prompt=71, completion=12, total=83
2025-05-10 22:04:29,024 - INFO - Processing query: 'Quelle est l'importance de la législation de change pour les opérations d'importation et d'exportation?' for conversation 254
2025-05-10 22:04:29,026 - INFO - Query received: Quelle est l'importance de la législation de change pour les opérations d'importation et d'exportation?
2025-05-10 22:04:30,201 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5981)
2025-05-10 22:04:30,328 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:04:30,328 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:04:30,714 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:04:30,714 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:04:35,203 - INFO - Token usage: prompt=2509, completion=493, total=3002
2025-05-10 22:04:35,217 - INFO - Agent workflow completed in 6.66s
2025-05-10 22:04:35,273 - INFO - Request processed in 6.72s (thinking: 4.90s)
2025-05-10 22:04:35,275 - INFO - 127.0.0.1 - - [10/May/2025 22:04:35] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:04:45,347 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:04:45,941 - INFO - Token usage: prompt=77, completion=19, total=96
2025-05-10 22:04:45,986 - INFO - Processing query: 'Quelles pourraient être les conséquences du non-respect de la législation de change lors d'opérations d'importation ou d'exportation?' for conversation 255
2025-05-10 22:04:45,988 - INFO - Query received: Quelles pourraient être les conséquences du non-respect de la législation de change lors d'opérations d'importation ou d'exportation?
2025-05-10 22:04:47,338 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5677)
2025-05-10 22:04:47,468 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:04:47,470 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:04:47,623 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:04:47,624 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:04:50,181 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:04:50,181 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:04:54,579 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:04:54,581 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:04:54,582 - INFO - Agent workflow completed in 9.23s
2025-05-10 22:04:54,583 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:04:54,585 - INFO - 127.0.0.1 - - [10/May/2025 22:04:54] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:04:57,604 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:04:57,916 - INFO - Token usage: prompt=77, completion=15, total=92
2025-05-10 22:04:57,968 - INFO - Processing query: 'Quelles pourraient être les conséquences du non-respect de la législation de change lors d'opérations d'importation ou d'exportation?' for conversation 256
2025-05-10 22:04:57,972 - INFO - Query received: Quelles pourraient être les conséquences du non-respect de la législation de change lors d'opérations d'importation ou d'exportation?
2025-05-10 22:04:59,463 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5677)
2025-05-10 22:04:59,594 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:04:59,594 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:05:00,981 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:05:00,981 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:05:03,351 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:05:03,351 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:05:10,620 - INFO - Token usage: prompt=2610, completion=684, total=3294
2025-05-10 22:05:10,631 - INFO - Agent workflow completed in 13.03s
2025-05-10 22:05:10,691 - INFO - Request processed in 13.09s (thinking: 11.05s)
2025-05-10 22:05:10,694 - INFO - 127.0.0.1 - - [10/May/2025 22:05:10] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:05:20,774 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:05:22,152 - INFO - Token usage: prompt=64, completion=10, total=74
2025-05-10 22:05:22,199 - INFO - Processing query: 'À quel type de contrôle les produits importés peuvent-ils être soumis?' for conversation 257
2025-05-10 22:05:22,201 - INFO - Query received: À quel type de contrôle les produits importés peuvent-ils être soumis?
2025-05-10 22:05:23,412 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6335)
2025-05-10 22:05:23,544 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:05:23,544 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:05:23,973 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:05:23,974 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:05:26,390 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:05:26,390 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:05:30,895 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:05:30,895 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:05:30,896 - INFO - Agent workflow completed in 10.12s
2025-05-10 22:05:30,897 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:05:30,899 - INFO - 127.0.0.1 - - [10/May/2025 22:05:30] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:05:33,948 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:05:34,455 - INFO - Token usage: prompt=64, completion=10, total=74
2025-05-10 22:05:34,500 - INFO - Processing query: 'À quel type de contrôle les produits importés peuvent-ils être soumis?' for conversation 258
2025-05-10 22:05:34,504 - INFO - Query received: À quel type de contrôle les produits importés peuvent-ils être soumis?
2025-05-10 22:05:35,723 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6335)
2025-05-10 22:05:35,845 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:05:35,845 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:05:39,653 - INFO - Token usage: prompt=2043, completion=890, total=2933
2025-05-10 22:05:39,669 - INFO - Agent workflow completed in 5.72s
2025-05-10 22:05:39,909 - INFO - Request processed in 5.96s (thinking: 3.84s)
2025-05-10 22:05:39,910 - INFO - 127.0.0.1 - - [10/May/2025 22:05:39] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:05:50,062 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:05:51,742 - INFO - Token usage: prompt=66, completion=20, total=86
2025-05-10 22:05:51,789 - INFO - Processing query: 'Quels sont les référentiels de conformité pour le contrôle technique des produits importés?' for conversation 259
2025-05-10 22:05:51,792 - INFO - Query received: Quels sont les référentiels de conformité pour le contrôle technique des produits importés?
2025-05-10 22:05:53,045 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5741)
2025-05-10 22:05:53,164 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:05:53,164 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:05:54,037 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:05:54,038 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:05:56,496 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:05:56,496 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:06:00,900 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:06:00,900 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:06:00,903 - INFO - Agent workflow completed in 10.84s
2025-05-10 22:06:00,904 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:06:00,906 - INFO - 127.0.0.1 - - [10/May/2025 22:06:00] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:06:03,925 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:06:04,885 - INFO - Token usage: prompt=66, completion=20, total=86
2025-05-10 22:06:04,938 - INFO - Processing query: 'Quels sont les référentiels de conformité pour le contrôle technique des produits importés?' for conversation 260
2025-05-10 22:06:04,942 - INFO - Query received: Quels sont les référentiels de conformité pour le contrôle technique des produits importés?
2025-05-10 22:06:06,195 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5741)
2025-05-10 22:06:06,315 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:06:06,315 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:06:07,176 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:06:07,177 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:06:12,164 - INFO - Token usage: prompt=2781, completion=643, total=3424
2025-05-10 22:06:12,174 - INFO - Agent workflow completed in 8.25s
2025-05-10 22:06:12,227 - INFO - Request processed in 8.30s (thinking: 5.86s)
2025-05-10 22:06:12,230 - INFO - 127.0.0.1 - - [10/May/2025 22:06:12] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:06:22,286 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:06:22,644 - INFO - Token usage: prompt=76, completion=17, total=93
2025-05-10 22:06:22,691 - INFO - Processing query: 'Dans quel but le contrôle technique à l'importation est-il instauré, notamment par rapport à l'intérêt du consommateur?' for conversation 261
2025-05-10 22:06:22,693 - INFO - Query received: Dans quel but le contrôle technique à l'importation est-il instauré, notamment par rapport à l'intérêt du consommateur?
2025-05-10 22:06:23,875 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6349)
2025-05-10 22:06:23,995 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:06:23,995 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:06:24,116 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:06:24,116 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:06:26,349 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:06:26,349 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:06:31,281 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:06:31,281 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:06:31,284 - INFO - Agent workflow completed in 9.00s
2025-05-10 22:06:31,284 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:06:31,287 - INFO - 127.0.0.1 - - [10/May/2025 22:06:31] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:06:34,300 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:06:35,182 - INFO - Token usage: prompt=76, completion=22, total=98
2025-05-10 22:06:35,231 - INFO - Processing query: 'Dans quel but le contrôle technique à l'importation est-il instauré, notamment par rapport à l'intérêt du consommateur?' for conversation 262
2025-05-10 22:06:35,234 - INFO - Query received: Dans quel but le contrôle technique à l'importation est-il instauré, notamment par rapport à l'intérêt du consommateur?
2025-05-10 22:06:36,670 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6349)
2025-05-10 22:06:36,832 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:06:36,832 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:06:43,220 - INFO - Token usage: prompt=1780, completion=714, total=2494
2025-05-10 22:06:43,230 - INFO - Agent workflow completed in 8.93s
2025-05-10 22:06:43,323 - INFO - Request processed in 9.02s (thinking: 6.41s)
2025-05-10 22:06:43,324 - INFO - 127.0.0.1 - - [10/May/2025 22:06:43] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:06:53,401 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:06:53,764 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 22:06:53,811 - INFO - Processing query: 'Les produits exportés peuvent-ils également faire l'objet d'un contrôle technique?' for conversation 263
2025-05-10 22:06:53,815 - INFO - Query received: Les produits exportés peuvent-ils également faire l'objet d'un contrôle technique?
2025-05-10 22:06:55,077 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5389)
2025-05-10 22:06:55,192 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:06:55,192 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:06:55,333 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:06:55,333 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:06:57,556 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:06:57,556 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:07:01,717 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:07:01,717 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:07:01,718 - INFO - Agent workflow completed in 8.32s
2025-05-10 22:07:01,720 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:07:01,722 - INFO - 127.0.0.1 - - [10/May/2025 22:07:01] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:07:04,759 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:07:05,222 - INFO - Token usage: prompt=67, completion=11, total=78
2025-05-10 22:07:05,271 - INFO - Processing query: 'Les produits exportés peuvent-ils également faire l'objet d'un contrôle technique?' for conversation 264
2025-05-10 22:07:05,273 - INFO - Query received: Les produits exportés peuvent-ils également faire l'objet d'un contrôle technique?
2025-05-10 22:07:06,600 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5389)
2025-05-10 22:07:06,710 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:07:06,710 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:07:06,832 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:07:06,832 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:07:13,097 - INFO - Token usage: prompt=2954, completion=634, total=3588
2025-05-10 22:07:13,111 - INFO - Agent workflow completed in 8.35s
2025-05-10 22:07:13,176 - INFO - Request processed in 8.42s (thinking: 6.41s)
2025-05-10 22:07:13,178 - INFO - 127.0.0.1 - - [10/May/2025 22:07:13] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:07:23,239 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:07:23,617 - INFO - Token usage: prompt=65, completion=14, total=79
2025-05-10 22:07:23,667 - INFO - Processing query: 'Quels sont les différents critères de conformité pour le contrôle technique des produits exportés?' for conversation 265
2025-05-10 22:07:23,670 - INFO - Query received: Quels sont les différents critères de conformité pour le contrôle technique des produits exportés?
2025-05-10 22:07:24,851 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5324)
2025-05-10 22:07:24,969 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:07:24,969 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:07:25,609 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:07:25,610 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:07:27,993 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:07:27,994 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:07:32,247 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:07:32,248 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:07:32,249 - INFO - Agent workflow completed in 9.01s
2025-05-10 22:07:32,250 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:07:32,253 - INFO - 127.0.0.1 - - [10/May/2025 22:07:32] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:07:35,271 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:07:35,626 - INFO - Token usage: prompt=65, completion=18, total=83
2025-05-10 22:07:35,675 - INFO - Processing query: 'Quels sont les différents critères de conformité pour le contrôle technique des produits exportés?' for conversation 266
2025-05-10 22:07:35,677 - INFO - Query received: Quels sont les différents critères de conformité pour le contrôle technique des produits exportés?
2025-05-10 22:07:36,862 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5324)
2025-05-10 22:07:36,971 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:07:36,971 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:07:37,091 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:07:37,092 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:07:39,251 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:07:39,251 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:07:47,098 - INFO - Token usage: prompt=2780, completion=362, total=3142
2025-05-10 22:07:47,110 - INFO - Agent workflow completed in 11.84s
2025-05-10 22:07:47,155 - INFO - Request processed in 11.88s (thinking: 10.15s)
2025-05-10 22:07:47,156 - INFO - 127.0.0.1 - - [10/May/2025 22:07:47] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:07:57,231 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:07:57,561 - INFO - Token usage: prompt=66, completion=13, total=79
2025-05-10 22:07:57,634 - INFO - Processing query: 'Pourquoi un contrôle technique serait-il appliqué aux produits destinés à l'exportation?' for conversation 267
2025-05-10 22:07:57,636 - INFO - Query received: Pourquoi un contrôle technique serait-il appliqué aux produits destinés à l'exportation?
2025-05-10 22:07:58,883 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5588)
2025-05-10 22:07:58,997 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:07:58,998 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:07:59,125 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:07:59,125 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:08:02,538 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:08:02,539 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:08:06,698 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:08:06,698 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:08:06,700 - INFO - Agent workflow completed in 9.47s
2025-05-10 22:08:06,700 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:08:06,703 - INFO - 127.0.0.1 - - [10/May/2025 22:08:06] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:08:09,749 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:08:10,065 - INFO - Token usage: prompt=66, completion=15, total=81
2025-05-10 22:08:10,112 - INFO - Processing query: 'Pourquoi un contrôle technique serait-il appliqué aux produits destinés à l'exportation?' for conversation 268
2025-05-10 22:08:10,114 - INFO - Query received: Pourquoi un contrôle technique serait-il appliqué aux produits destinés à l'exportation?
2025-05-10 22:08:11,310 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5588)
2025-05-10 22:08:11,414 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:08:11,414 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:08:11,566 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:08:11,567 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:08:13,811 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:08:13,811 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:08:21,697 - INFO - Token usage: prompt=2868, completion=685, total=3553
2025-05-10 22:08:21,709 - INFO - Agent workflow completed in 11.96s
2025-05-10 22:08:21,804 - INFO - Request processed in 12.06s (thinking: 10.30s)
2025-05-10 22:08:21,806 - INFO - 127.0.0.1 - - [10/May/2025 22:08:21] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:08:31,895 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:08:32,861 - INFO - Token usage: prompt=76, completion=18, total=94
2025-05-10 22:08:32,910 - INFO - Processing query: 'Les contrôles techniques à l'importation et à l'exportation se substituent-ils aux autres contrôles spécifiques existants?' for conversation 269
2025-05-10 22:08:32,913 - INFO - Query received: Les contrôles techniques à l'importation et à l'exportation se substituent-ils aux autres contrôles spécifiques existants?
2025-05-10 22:08:34,116 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5517)
2025-05-10 22:08:34,239 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:08:34,239 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:08:34,421 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:08:34,421 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:08:36,855 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:08:36,855 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:08:40,981 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:08:40,981 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:08:40,984 - INFO - Agent workflow completed in 9.09s
2025-05-10 22:08:40,985 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:08:40,986 - INFO - 127.0.0.1 - - [10/May/2025 22:08:40] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:08:44,012 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:08:44,330 - INFO - Token usage: prompt=76, completion=17, total=93
2025-05-10 22:08:44,381 - INFO - Processing query: 'Les contrôles techniques à l'importation et à l'exportation se substituent-ils aux autres contrôles spécifiques existants?' for conversation 270
2025-05-10 22:08:44,383 - INFO - Query received: Les contrôles techniques à l'importation et à l'exportation se substituent-ils aux autres contrôles spécifiques existants?
2025-05-10 22:08:45,602 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5517)
2025-05-10 22:08:45,727 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:08:45,728 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:08:50,932 - INFO - Token usage: prompt=2252, completion=824, total=3076
2025-05-10 22:08:50,946 - INFO - Agent workflow completed in 6.93s
2025-05-10 22:08:51,062 - INFO - Request processed in 7.05s (thinking: 5.23s)
2025-05-10 22:08:51,064 - INFO - 127.0.0.1 - - [10/May/2025 22:08:51] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:09:01,184 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:09:01,538 - INFO - Token usage: prompt=68, completion=16, total=84
2025-05-10 22:09:01,593 - INFO - Processing query: 'Quels exemples de contrôles spécifiques sont mentionnés comme étant distincts des contrôles techniques généraux?' for conversation 271
2025-05-10 22:09:01,596 - INFO - Query received: Quels exemples de contrôles spécifiques sont mentionnés comme étant distincts des contrôles techniques généraux?
2025-05-10 22:09:02,815 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3435)
2025-05-10 22:09:02,954 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:09:02,954 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:09:03,786 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:09:03,786 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:09:06,323 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:09:06,323 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:09:11,876 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:09:11,877 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:09:11,879 - INFO - Agent workflow completed in 10.70s
2025-05-10 22:09:11,881 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:09:11,883 - INFO - 127.0.0.1 - - [10/May/2025 22:09:11] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:09:14,897 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:09:15,624 - INFO - Token usage: prompt=68, completion=15, total=83
2025-05-10 22:09:15,673 - INFO - Processing query: 'Quels exemples de contrôles spécifiques sont mentionnés comme étant distincts des contrôles techniques généraux?' for conversation 272
2025-05-10 22:09:15,676 - INFO - Query received: Quels exemples de contrôles spécifiques sont mentionnés comme étant distincts des contrôles techniques généraux?
2025-05-10 22:09:17,051 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3435)
2025-05-10 22:09:17,169 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:09:17,169 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:09:23,573 - INFO - Token usage: prompt=2089, completion=951, total=3040
2025-05-10 22:09:23,585 - INFO - Agent workflow completed in 8.69s
2025-05-10 22:09:23,750 - INFO - Request processed in 8.85s (thinking: 6.43s)
2025-05-10 22:09:23,753 - INFO - 127.0.0.1 - - [10/May/2025 22:09:23] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:09:33,857 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:09:34,189 - INFO - Token usage: prompt=75, completion=15, total=90
2025-05-10 22:09:34,244 - INFO - Processing query: 'Quelle est l'implication de la coexistence des contrôles techniques généraux et des contrôles spécifiques pour les opérateurs du commerce extérieur?' for conversation 273
2025-05-10 22:09:34,247 - INFO - Query received: Quelle est l'implication de la coexistence des contrôles techniques généraux et des contrôles spécifiques pour les opérateurs du commerce extérieur?
2025-05-10 22:09:35,541 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5195)
2025-05-10 22:09:35,656 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:09:35,656 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:09:35,770 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:09:35,770 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:09:37,946 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:09:37,946 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:09:42,096 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:09:42,096 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:09:42,099 - INFO - Agent workflow completed in 8.24s
2025-05-10 22:09:42,099 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:09:42,102 - INFO - 127.0.0.1 - - [10/May/2025 22:09:42] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:09:45,112 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:09:45,425 - INFO - Token usage: prompt=75, completion=17, total=92
2025-05-10 22:09:45,472 - INFO - Processing query: 'Quelle est l'implication de la coexistence des contrôles techniques généraux et des contrôles spécifiques pour les opérateurs du commerce extérieur?' for conversation 274
2025-05-10 22:09:45,475 - INFO - Query received: Quelle est l'implication de la coexistence des contrôles techniques généraux et des contrôles spécifiques pour les opérateurs du commerce extérieur?
2025-05-10 22:09:46,693 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5195)
2025-05-10 22:09:46,831 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:09:46,831 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:09:52,618 - INFO - Token usage: prompt=1931, completion=1002, total=2933
2025-05-10 22:09:52,628 - INFO - Agent workflow completed in 7.52s
2025-05-10 22:09:52,820 - INFO - Request processed in 7.71s (thinking: 5.81s)
2025-05-10 22:09:52,821 - INFO - 127.0.0.1 - - [10/May/2025 22:09:52] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:10:02,936 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:10:04,158 - INFO - Token usage: prompt=69, completion=18, total=87
2025-05-10 22:10:04,205 - INFO - Processing query: 'Comment sont déterminées les modalités de contrôle technique et les organismes habilités à l'exercer?' for conversation 275
2025-05-10 22:10:04,208 - INFO - Query received: Comment sont déterminées les modalités de contrôle technique et les organismes habilités à l'exercer?
2025-05-10 22:10:05,412 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4048)
2025-05-10 22:10:05,648 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:10:05,648 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:10:05,980 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:10:05,980 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:10:08,920 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:10:08,920 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:10:16,043 - INFO - Token usage: prompt=1816, completion=678, total=2494
2025-05-10 22:10:16,059 - INFO - Agent workflow completed in 13.12s
2025-05-10 22:10:16,144 - INFO - Request processed in 13.21s (thinking: 10.42s)
2025-05-10 22:10:16,146 - INFO - 127.0.0.1 - - [10/May/2025 22:10:16] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:10:26,240 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:10:26,833 - INFO - Token usage: prompt=63, completion=14, total=77
2025-05-10 22:10:26,889 - INFO - Processing query: 'Comment la liste des produits soumis au contrôle technique est-elle établie?' for conversation 276
2025-05-10 22:10:26,891 - INFO - Query received: Comment la liste des produits soumis au contrôle technique est-elle établie?
2025-05-10 22:10:28,106 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3907)
2025-05-10 22:10:28,236 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:10:28,237 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:10:28,358 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:10:28,358 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:10:30,498 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:10:30,498 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:10:34,645 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:10:34,645 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:10:34,647 - INFO - Agent workflow completed in 8.41s
2025-05-10 22:10:34,647 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:10:34,650 - INFO - 127.0.0.1 - - [10/May/2025 22:10:34] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:10:37,682 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:10:38,032 - INFO - Token usage: prompt=63, completion=15, total=78
2025-05-10 22:10:38,089 - INFO - Processing query: 'Comment la liste des produits soumis au contrôle technique est-elle établie?' for conversation 277
2025-05-10 22:10:38,093 - INFO - Query received: Comment la liste des produits soumis au contrôle technique est-elle établie?
2025-05-10 22:10:39,376 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.3907)
2025-05-10 22:10:39,482 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:10:39,483 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:10:39,980 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:10:39,981 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:10:44,328 - INFO - Token usage: prompt=2248, completion=328, total=2576
2025-05-10 22:10:44,341 - INFO - Agent workflow completed in 6.66s
2025-05-10 22:10:44,379 - INFO - Request processed in 6.70s (thinking: 4.87s)
2025-05-10 22:10:44,382 - INFO - 127.0.0.1 - - [10/May/2025 22:10:44] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:10:54,427 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:10:55,298 - INFO - Token usage: prompt=72, completion=13, total=85
2025-05-10 22:10:55,350 - INFO - Processing query: 'Quelle est la différence entre un décret et un arrêté dans le contexte de la mise en place des contrôles techniques?' for conversation 278
2025-05-10 22:10:55,352 - INFO - Query received: Quelle est la différence entre un décret et un arrêté dans le contexte de la mise en place des contrôles techniques?
2025-05-10 22:10:56,583 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4531)
2025-05-10 22:10:56,708 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:10:56,709 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:10:57,550 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:10:57,551 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:10:59,762 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:10:59,762 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:11:04,046 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:11:04,046 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:11:04,049 - INFO - Agent workflow completed in 9.62s
2025-05-10 22:11:04,049 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:11:04,052 - INFO - 127.0.0.1 - - [10/May/2025 22:11:04] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:11:07,081 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:11:07,631 - INFO - Token usage: prompt=72, completion=13, total=85
2025-05-10 22:11:07,680 - INFO - Processing query: 'Quelle est la différence entre un décret et un arrêté dans le contexte de la mise en place des contrôles techniques?' for conversation 279
2025-05-10 22:11:07,683 - INFO - Query received: Quelle est la différence entre un décret et un arrêté dans le contexte de la mise en place des contrôles techniques?
2025-05-10 22:11:08,868 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4531)
2025-05-10 22:11:09,005 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:11:09,006 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:11:12,202 - INFO - Token usage: prompt=2469, completion=649, total=3118
2025-05-10 22:11:12,216 - INFO - Agent workflow completed in 5.14s
2025-05-10 22:11:12,313 - INFO - Request processed in 5.23s (thinking: 3.22s)
2025-05-10 22:11:12,314 - INFO - 127.0.0.1 - - [10/May/2025 22:11:12] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:11:22,422 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:11:22,919 - INFO - Token usage: prompt=62, completion=12, total=74
2025-05-10 22:11:22,966 - INFO - Processing query: 'Quelle est la principale mission du Conseil National du Commerce Extérieur?' for conversation 280
2025-05-10 22:11:22,970 - INFO - Query received: Quelle est la principale mission du Conseil National du Commerce Extérieur?
2025-05-10 22:11:24,171 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4651)
2025-05-10 22:11:24,300 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:11:24,300 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:11:24,624 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:11:24,624 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:11:27,100 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:11:27,102 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:11:31,595 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:11:31,595 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:11:31,596 - INFO - Agent workflow completed in 9.18s
2025-05-10 22:11:31,597 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:11:31,600 - INFO - 127.0.0.1 - - [10/May/2025 22:11:31] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:11:34,613 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:11:35,237 - INFO - Token usage: prompt=62, completion=12, total=74
2025-05-10 22:11:35,301 - INFO - Processing query: 'Quelle est la principale mission du Conseil National du Commerce Extérieur?' for conversation 281
2025-05-10 22:11:35,305 - INFO - Query received: Quelle est la principale mission du Conseil National du Commerce Extérieur?
2025-05-10 22:11:36,508 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4651)
2025-05-10 22:11:36,635 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:11:36,635 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:11:38,789 - INFO - Token usage: prompt=1970, completion=396, total=2366
2025-05-10 22:11:38,799 - INFO - Agent workflow completed in 4.19s
2025-05-10 22:11:38,835 - INFO - Request processed in 4.22s (thinking: 2.17s)
2025-05-10 22:11:38,836 - INFO - 127.0.0.1 - - [10/May/2025 22:11:38] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:11:48,891 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:11:49,775 - INFO - Token usage: prompt=81, completion=14, total=95
2025-05-10 22:11:49,818 - INFO - Processing query: 'Quelles sont les responsabilités spécifiques du Conseil National du Commerce Extérieur en matière de pratiques commerciales, d'équilibre commercial et d'organisation d'événements?' for conversation 282
2025-05-10 22:11:49,821 - INFO - Query received: Quelles sont les responsabilités spécifiques du Conseil National du Commerce Extérieur en matière de pratiques commerciales, d'équilibre commercial et d'organisation d'événements?
2025-05-10 22:11:51,129 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5570)
2025-05-10 22:11:51,283 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:11:51,284 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:11:52,382 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:11:52,382 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:11:54,793 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:11:54,793 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:11:58,946 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:11:58,946 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:11:58,947 - INFO - Agent workflow completed in 10.06s
2025-05-10 22:11:58,947 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:11:58,949 - INFO - 127.0.0.1 - - [10/May/2025 22:11:58] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:12:01,965 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:12:02,283 - INFO - Token usage: prompt=81, completion=13, total=94
2025-05-10 22:12:02,316 - INFO - Processing query: 'Quelles sont les responsabilités spécifiques du Conseil National du Commerce Extérieur en matière de pratiques commerciales, d'équilibre commercial et d'organisation d'événements?' for conversation 283
2025-05-10 22:12:02,317 - INFO - Query received: Quelles sont les responsabilités spécifiques du Conseil National du Commerce Extérieur en matière de pratiques commerciales, d'équilibre commercial et d'organisation d'événements?
2025-05-10 22:12:02,763 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5570)
2025-05-10 22:12:02,811 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:12:02,812 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:12:04,776 - INFO - Token usage: prompt=2091, completion=433, total=2524
2025-05-10 22:12:04,784 - INFO - Agent workflow completed in 2.82s
2025-05-10 22:12:04,814 - INFO - Request processed in 2.85s (thinking: 1.98s)
2025-05-10 22:12:04,815 - INFO - 127.0.0.1 - - [10/May/2025 22:12:04] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:12:14,843 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:12:15,153 - INFO - Token usage: prompt=68, completion=16, total=84
2025-05-10 22:12:15,204 - INFO - Processing query: 'Comment la composition et le fonctionnement du Conseil National du Commerce Extérieur sont-ils établis?' for conversation 284
2025-05-10 22:12:15,206 - INFO - Query received: Comment la composition et le fonctionnement du Conseil National du Commerce Extérieur sont-ils établis?
2025-05-10 22:12:15,702 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.4547)
2025-05-10 22:12:15,746 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:12:15,747 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:12:15,864 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:12:15,864 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:12:18,029 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:12:18,029 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:12:22,177 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:12:22,178 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:12:22,178 - INFO - Agent workflow completed in 7.34s
2025-05-10 22:12:22,180 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:12:22,181 - INFO - 127.0.0.1 - - [10/May/2025 22:12:22] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:12:25,198 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:12:25,549 - INFO - Token usage: prompt=68, completion=16, total=84
2025-05-10 22:12:25,585 - INFO - Processing query: 'Comment la composition et le fonctionnement du Conseil National du Commerce Extérieur sont-ils établis?' for conversation 285
2025-05-10 22:12:25,586 - INFO - Query received: Comment la composition et le fonctionnement du Conseil National du Commerce Extérieur sont-ils établis?
2025-05-10 22:12:26,071 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.4547)
2025-05-10 22:12:26,113 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:12:26,113 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:12:26,219 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:12:26,219 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:12:28,339 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:12:28,339 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:12:34,597 - INFO - Token usage: prompt=2417, completion=507, total=2924
2025-05-10 22:12:34,605 - INFO - Agent workflow completed in 9.41s
2025-05-10 22:12:34,637 - INFO - Request processed in 9.44s (thinking: 8.49s)
2025-05-10 22:12:34,638 - INFO - 127.0.0.1 - - [10/May/2025 22:12:34] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:12:44,682 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:12:44,983 - INFO - Token usage: prompt=63, completion=13, total=76
2025-05-10 22:12:45,017 - INFO - Processing query: 'Comment la loi définit-elle les foires et manifestations commerciales?' for conversation 286
2025-05-10 22:12:45,018 - INFO - Query received: Comment la loi définit-elle les foires et manifestations commerciales?
2025-05-10 22:12:45,467 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5797)
2025-05-10 22:12:45,513 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:12:45,513 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:12:45,625 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:12:45,625 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:12:47,773 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:12:47,773 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:12:51,903 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:12:51,903 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:12:51,904 - INFO - Agent workflow completed in 7.22s
2025-05-10 22:12:51,905 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:12:51,906 - INFO - 127.0.0.1 - - [10/May/2025 22:12:51] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:12:54,931 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:12:55,257 - INFO - Token usage: prompt=63, completion=16, total=79
2025-05-10 22:12:55,306 - INFO - Processing query: 'Comment la loi définit-elle les foires et manifestations commerciales?' for conversation 287
2025-05-10 22:12:55,309 - INFO - Query received: Comment la loi définit-elle les foires et manifestations commerciales?
2025-05-10 22:12:55,783 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5797)
2025-05-10 22:12:55,825 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:12:55,825 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:12:57,869 - INFO - Token usage: prompt=1985, completion=444, total=2429
2025-05-10 22:12:57,878 - INFO - Agent workflow completed in 2.95s
2025-05-10 22:12:57,915 - INFO - Request processed in 2.98s (thinking: 2.06s)
2025-05-10 22:12:57,916 - INFO - 127.0.0.1 - - [10/May/2025 22:12:57] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:13:07,938 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:13:08,277 - INFO - Token usage: prompt=66, completion=19, total=85
2025-05-10 22:13:08,312 - INFO - Processing query: 'Quels sont les buts principaux d'une foire ou manifestation selon cette définition légale?' for conversation 288
2025-05-10 22:13:08,313 - INFO - Query received: Quels sont les buts principaux d'une foire ou manifestation selon cette définition légale?
2025-05-10 22:13:08,808 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5284)
2025-05-10 22:13:08,856 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:13:08,856 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:13:09,008 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:13:09,008 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:13:11,129 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:13:11,129 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:13:15,266 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:13:15,266 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:13:15,267 - INFO - Agent workflow completed in 7.33s
2025-05-10 22:13:15,267 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:13:15,268 - INFO - 127.0.0.1 - - [10/May/2025 22:13:15] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:13:18,282 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:13:18,593 - INFO - Token usage: prompt=66, completion=17, total=83
2025-05-10 22:13:18,628 - INFO - Processing query: 'Quels sont les buts principaux d'une foire ou manifestation selon cette définition légale?' for conversation 289
2025-05-10 22:13:18,631 - INFO - Query received: Quels sont les buts principaux d'une foire ou manifestation selon cette définition légale?
2025-05-10 22:13:19,197 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5284)
2025-05-10 22:13:19,234 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:13:19,234 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:13:19,351 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:13:19,351 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:13:21,495 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:13:21,495 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:13:27,513 - INFO - Token usage: prompt=2812, completion=415, total=3227
2025-05-10 22:13:27,520 - INFO - Agent workflow completed in 9.24s
2025-05-10 22:13:27,546 - INFO - Request processed in 9.26s (thinking: 8.29s)
2025-05-10 22:13:27,548 - INFO - 127.0.0.1 - - [10/May/2025 22:13:27] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:13:37,569 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:13:37,908 - INFO - Token usage: prompt=70, completion=14, total=84
2025-05-10 22:13:37,940 - INFO - Processing query: 'Comment sont déterminées les modalités de classification, d'organisation et de fonctionnement des foires et expositions?' for conversation 290
2025-05-10 22:13:37,941 - INFO - Query received: Comment sont déterminées les modalités de classification, d'organisation et de fonctionnement des foires et expositions?
2025-05-10 22:13:38,391 - INFO - Routing query to code: texte_code_societes_commerciales (similarity: 0.4184)
2025-05-10 22:13:38,441 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:13:38,442 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:13:38,555 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:13:38,555 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:13:40,678 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:13:40,678 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:13:44,856 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:13:44,857 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:13:44,858 - INFO - Agent workflow completed in 7.29s
2025-05-10 22:13:44,858 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:13:44,859 - INFO - 127.0.0.1 - - [10/May/2025 22:13:44] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:13:47,879 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:13:48,219 - INFO - Token usage: prompt=70, completion=19, total=89
2025-05-10 22:13:48,253 - INFO - Processing query: 'Comment sont déterminées les modalités de classification, d'organisation et de fonctionnement des foires et expositions?' for conversation 291
2025-05-10 22:13:48,253 - INFO - Query received: Comment sont déterminées les modalités de classification, d'organisation et de fonctionnement des foires et expositions?
2025-05-10 22:13:48,694 - INFO - Routing query to code: texte_code_societes_commerciales (similarity: 0.4184)
2025-05-10 22:13:48,737 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:13:48,738 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:13:48,844 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:13:48,845 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:13:53,250 - INFO - Token usage: prompt=1967, completion=551, total=2518
2025-05-10 22:13:53,256 - INFO - Agent workflow completed in 5.38s
2025-05-10 22:13:53,286 - INFO - Request processed in 5.41s (thinking: 4.52s)
2025-05-10 22:13:53,286 - INFO - 127.0.0.1 - - [10/May/2025 22:13:53] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:14:03,318 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:14:03,658 - INFO - Token usage: prompt=77, completion=16, total=93
2025-05-10 22:14:03,695 - INFO - Processing query: 'Quelles sont les conséquences pour les importations ou exportations de produits qui enfreignent certaines procédures et formalités prévues par la loi?' for conversation 292
2025-05-10 22:14:03,697 - INFO - Query received: Quelles sont les conséquences pour les importations ou exportations de produits qui enfreignent certaines procédures et formalités prévues par la loi?
2025-05-10 22:14:04,174 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.7161)
2025-05-10 22:14:04,217 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:14:04,218 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:14:04,338 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:14:04,338 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:14:06,469 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:14:06,469 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:14:10,604 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:14:10,604 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:14:10,606 - INFO - Agent workflow completed in 7.29s
2025-05-10 22:14:10,607 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:14:10,608 - INFO - 127.0.0.1 - - [10/May/2025 22:14:10] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:14:13,620 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:14:13,954 - INFO - Token usage: prompt=77, completion=16, total=93
2025-05-10 22:14:13,994 - INFO - Processing query: 'Quelles sont les conséquences pour les importations ou exportations de produits qui enfreignent certaines procédures et formalités prévues par la loi?' for conversation 293
2025-05-10 22:14:13,995 - INFO - Query received: Quelles sont les conséquences pour les importations ou exportations de produits qui enfreignent certaines procédures et formalités prévues par la loi?
2025-05-10 22:14:14,489 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.7161)
2025-05-10 22:14:14,534 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:14:14,535 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:14:14,656 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:14:14,657 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:14:16,797 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:14:16,797 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:14:21,139 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:14:21,140 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:14:21,142 - INFO - Agent workflow completed in 7.52s
2025-05-10 22:14:21,142 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:14:21,144 - INFO - 127.0.0.1 - - [10/May/2025 22:14:21] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:14:27,178 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:14:27,545 - INFO - Token usage: prompt=77, completion=22, total=99
2025-05-10 22:14:27,577 - INFO - Processing query: 'Quelles sont les conséquences pour les importations ou exportations de produits qui enfreignent certaines procédures et formalités prévues par la loi?' for conversation 294
2025-05-10 22:14:27,580 - INFO - Query received: Quelles sont les conséquences pour les importations ou exportations de produits qui enfreignent certaines procédures et formalités prévues par la loi?
2025-05-10 22:14:28,576 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.7161)
2025-05-10 22:14:28,679 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:14:28,680 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:14:28,814 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:14:28,814 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:14:38,550 - INFO - Token usage: prompt=3469, completion=1043, total=4512
2025-05-10 22:14:38,559 - INFO - Agent workflow completed in 11.38s
2025-05-10 22:14:38,672 - INFO - Request processed in 11.49s (thinking: 9.89s)
2025-05-10 22:14:38,672 - INFO - 127.0.0.1 - - [10/May/2025 22:14:38] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:14:48,755 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:14:49,066 - INFO - Token usage: prompt=74, completion=14, total=88
2025-05-10 22:14:49,100 - INFO - Processing query: 'Quels types de législations peuvent être invoqués pour réprimer les infractions aux procédures d'importation ou d'exportation?' for conversation 295
2025-05-10 22:14:49,102 - INFO - Query received: Quels types de législations peuvent être invoqués pour réprimer les infractions aux procédures d'importation ou d'exportation?
2025-05-10 22:14:49,644 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.7697)
2025-05-10 22:14:49,703 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:14:49,703 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:14:49,814 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:14:49,814 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:14:51,937 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:14:51,937 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:14:56,101 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:14:56,101 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:14:56,103 - INFO - Agent workflow completed in 7.35s
2025-05-10 22:14:56,104 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:14:56,105 - INFO - 127.0.0.1 - - [10/May/2025 22:14:56] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:14:59,134 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:14:59,491 - INFO - Token usage: prompt=74, completion=17, total=91
2025-05-10 22:14:59,528 - INFO - Processing query: 'Quels types de législations peuvent être invoqués pour réprimer les infractions aux procédures d'importation ou d'exportation?' for conversation 296
2025-05-10 22:14:59,529 - INFO - Query received: Quels types de législations peuvent être invoqués pour réprimer les infractions aux procédures d'importation ou d'exportation?
2025-05-10 22:15:00,204 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.7697)
2025-05-10 22:15:00,354 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:15:00,354 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:15:00,488 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:15:00,488 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:15:02,632 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:15:02,633 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:15:06,747 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:15:06,747 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:15:06,747 - INFO - Agent workflow completed in 7.61s
2025-05-10 22:15:06,747 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:15:06,748 - INFO - 127.0.0.1 - - [10/May/2025 22:15:06] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:15:12,782 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:15:13,152 - INFO - Token usage: prompt=74, completion=16, total=90
2025-05-10 22:15:13,189 - INFO - Processing query: 'Quels types de législations peuvent être invoqués pour réprimer les infractions aux procédures d'importation ou d'exportation?' for conversation 297
2025-05-10 22:15:13,190 - INFO - Query received: Quels types de législations peuvent être invoqués pour réprimer les infractions aux procédures d'importation ou d'exportation?
2025-05-10 22:15:13,588 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.7697)
2025-05-10 22:15:13,628 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:15:13,628 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:15:19,937 - INFO - Token usage: prompt=3049, completion=964, total=4013
2025-05-10 22:15:19,940 - INFO - Agent workflow completed in 7.16s
2025-05-10 22:15:19,973 - INFO - Request processed in 7.19s (thinking: 6.31s)
2025-05-10 22:15:19,975 - INFO - 127.0.0.1 - - [10/May/2025 22:15:19] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:15:30,005 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:15:30,319 - INFO - Token usage: prompt=67, completion=13, total=80
2025-05-10 22:15:30,352 - INFO - Processing query: 'Quelles sont les procédures et formalités dont l'infraction peut entraîner une répression?' for conversation 298
2025-05-10 22:15:30,353 - INFO - Query received: Quelles sont les procédures et formalités dont l'infraction peut entraîner une répression?
2025-05-10 22:15:30,752 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4314)
2025-05-10 22:15:30,792 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:15:30,792 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:15:30,905 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:15:30,907 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:15:33,041 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:15:33,041 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:15:39,976 - INFO - Token usage: prompt=1552, completion=709, total=2261
2025-05-10 22:15:39,983 - INFO - Agent workflow completed in 9.98s
2025-05-10 22:15:40,033 - INFO - Request processed in 10.03s (thinking: 9.19s)
2025-05-10 22:15:40,034 - INFO - 127.0.0.1 - - [10/May/2025 22:15:40] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:15:50,082 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:15:50,421 - INFO - Token usage: prompt=75, completion=13, total=88
2025-05-10 22:15:50,454 - INFO - Processing query: 'Quelle mesure peut être prise à l'encontre d'une importation de produits non conformes à certaines dispositions de la loi?' for conversation 299
2025-05-10 22:15:50,455 - INFO - Query received: Quelle mesure peut être prise à l'encontre d'une importation de produits non conformes à certaines dispositions de la loi?
2025-05-10 22:15:50,946 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.7476)
2025-05-10 22:15:50,996 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:15:50,996 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:15:51,103 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:15:51,103 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:15:53,257 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:15:53,257 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:15:57,447 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:15:57,447 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:15:57,448 - INFO - Agent workflow completed in 7.37s
2025-05-10 22:15:57,448 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:15:57,450 - INFO - 127.0.0.1 - - [10/May/2025 22:15:57] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:16:00,471 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:16:00,770 - INFO - Token usage: prompt=75, completion=13, total=88
2025-05-10 22:16:00,802 - INFO - Processing query: 'Quelle mesure peut être prise à l'encontre d'une importation de produits non conformes à certaines dispositions de la loi?' for conversation 300
2025-05-10 22:16:00,804 - INFO - Query received: Quelle mesure peut être prise à l'encontre d'une importation de produits non conformes à certaines dispositions de la loi?
2025-05-10 22:16:01,400 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.7476)
2025-05-10 22:16:01,450 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:16:01,450 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:16:01,565 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:16:01,566 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:16:03,717 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:16:03,717 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:16:07,868 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:16:07,868 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:16:07,870 - INFO - Agent workflow completed in 7.40s
2025-05-10 22:16:07,870 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:16:07,872 - INFO - 127.0.0.1 - - [10/May/2025 22:16:07] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:16:13,906 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:16:14,220 - INFO - Token usage: prompt=75, completion=13, total=88
2025-05-10 22:16:14,261 - INFO - Processing query: 'Quelle mesure peut être prise à l'encontre d'une importation de produits non conformes à certaines dispositions de la loi?' for conversation 301
2025-05-10 22:16:14,263 - INFO - Query received: Quelle mesure peut être prise à l'encontre d'une importation de produits non conformes à certaines dispositions de la loi?
2025-05-10 22:16:14,883 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.7476)
2025-05-10 22:16:14,937 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:16:14,938 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:16:18,251 - ERROR - HTTP error occurred: 500 Server Error: Internal Server Error for url: https://api.groq.com/openai/v1/chat/completions (Status code: 500)
2025-05-10 22:16:24,455 - INFO - Token usage: prompt=2816, completion=1015, total=3831
2025-05-10 22:16:24,459 - INFO - Agent workflow completed in 10.55s
2025-05-10 22:16:24,574 - INFO - Request processed in 10.67s (thinking: 9.53s)
2025-05-10 22:16:24,575 - INFO - 127.0.0.1 - - [10/May/2025 22:16:24] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:16:34,645 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:16:34,976 - INFO - Token usage: prompt=69, completion=17, total=86
2025-05-10 22:16:35,017 - INFO - Processing query: 'Quelles sont les non-conformités spécifiques qui peuvent entraîner le refoulement de produits importés?' for conversation 302
2025-05-10 22:16:35,019 - INFO - Query received: Quelles sont les non-conformités spécifiques qui peuvent entraîner le refoulement de produits importés?
2025-05-10 22:16:35,544 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5678)
2025-05-10 22:16:35,601 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:16:35,602 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:16:35,745 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:16:35,745 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:16:37,894 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:16:37,895 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:16:42,097 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:16:42,098 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:16:42,099 - INFO - Agent workflow completed in 7.45s
2025-05-10 22:16:42,099 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:16:42,100 - INFO - 127.0.0.1 - - [10/May/2025 22:16:42] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:16:45,123 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:16:45,457 - INFO - Token usage: prompt=69, completion=17, total=86
2025-05-10 22:16:45,493 - INFO - Processing query: 'Quelles sont les non-conformités spécifiques qui peuvent entraîner le refoulement de produits importés?' for conversation 303
2025-05-10 22:16:45,495 - INFO - Query received: Quelles sont les non-conformités spécifiques qui peuvent entraîner le refoulement de produits importés?
2025-05-10 22:16:46,091 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5678)
2025-05-10 22:16:46,151 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:16:46,151 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:16:51,582 - INFO - Token usage: prompt=2414, completion=858, total=3272
2025-05-10 22:16:51,586 - INFO - Agent workflow completed in 6.46s
2025-05-10 22:16:51,635 - INFO - Request processed in 6.51s (thinking: 5.44s)
2025-05-10 22:16:51,635 - INFO - 127.0.0.1 - - [10/May/2025 22:16:51] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:17:01,696 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:17:02,007 - INFO - Token usage: prompt=69, completion=17, total=86
2025-05-10 22:17:02,043 - INFO - Processing query: 'Quelle est la base légale pour la mesure de refoulement des produits importés non conformes?' for conversation 304
2025-05-10 22:17:02,045 - INFO - Query received: Quelle est la base légale pour la mesure de refoulement des produits importés non conformes?
2025-05-10 22:17:02,650 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6822)
2025-05-10 22:17:02,699 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:17:02,699 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:17:02,839 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:17:02,839 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:17:04,995 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:17:04,995 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:17:09,157 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:17:09,157 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:17:09,158 - INFO - Agent workflow completed in 7.46s
2025-05-10 22:17:09,158 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:17:09,159 - INFO - 127.0.0.1 - - [10/May/2025 22:17:09] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:17:12,190 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:17:12,508 - INFO - Token usage: prompt=69, completion=17, total=86
2025-05-10 22:17:12,551 - INFO - Processing query: 'Quelle est la base légale pour la mesure de refoulement des produits importés non conformes?' for conversation 305
2025-05-10 22:17:12,554 - INFO - Query received: Quelle est la base légale pour la mesure de refoulement des produits importés non conformes?
2025-05-10 22:17:13,194 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6822)
2025-05-10 22:17:13,248 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:17:13,248 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:17:13,370 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:17:13,370 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:17:15,511 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:17:15,511 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:17:19,675 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:17:19,675 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:17:19,676 - INFO - Agent workflow completed in 7.49s
2025-05-10 22:17:19,676 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:17:19,678 - INFO - 127.0.0.1 - - [10/May/2025 22:17:19] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:17:25,694 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:17:26,015 - INFO - Token usage: prompt=69, completion=17, total=86
2025-05-10 22:17:26,051 - INFO - Processing query: 'Quelle est la base légale pour la mesure de refoulement des produits importés non conformes?' for conversation 306
2025-05-10 22:17:26,053 - INFO - Query received: Quelle est la base légale pour la mesure de refoulement des produits importés non conformes?
2025-05-10 22:17:26,639 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.6822)
2025-05-10 22:17:26,680 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:17:26,680 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:17:27,982 - INFO - Token usage: prompt=3266, completion=205, total=3471
2025-05-10 22:17:27,987 - INFO - Agent workflow completed in 2.29s
2025-05-10 22:17:28,014 - INFO - Request processed in 2.32s (thinking: 1.31s)
2025-05-10 22:17:28,016 - INFO - 127.0.0.1 - - [10/May/2025 22:17:28] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:17:38,044 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:17:38,359 - INFO - Token usage: prompt=71, completion=11, total=82
2025-05-10 22:17:38,398 - INFO - Processing query: 'Comment les infractions aux dispositions de la présente loi et de ses textes d'application sont-elles constatées?' for conversation 307
2025-05-10 22:17:38,400 - INFO - Query received: Comment les infractions aux dispositions de la présente loi et de ses textes d'application sont-elles constatées?
2025-05-10 22:17:38,958 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4942)
2025-05-10 22:17:39,017 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:17:39,017 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:17:39,129 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:17:39,129 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:17:41,275 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:17:41,275 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:17:47,195 - INFO - Token usage: prompt=1651, completion=425, total=2076
2025-05-10 22:17:47,202 - INFO - Agent workflow completed in 9.16s
2025-05-10 22:17:47,234 - INFO - Request processed in 9.19s (thinking: 8.19s)
2025-05-10 22:17:47,235 - INFO - 127.0.0.1 - - [10/May/2025 22:17:47] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:17:57,362 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:17:57,712 - INFO - Token usage: prompt=67, completion=18, total=85
2025-05-10 22:17:57,751 - INFO - Processing query: 'Quels sont les agents habilités à établir les procès-verbaux constatant les infractions?' for conversation 308
2025-05-10 22:17:57,752 - INFO - Query received: Quels sont les agents habilités à établir les procès-verbaux constatant les infractions?
2025-05-10 22:17:58,283 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4080)
2025-05-10 22:17:58,348 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:17:58,348 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:17:58,454 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:17:58,454 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:18:00,597 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:18:00,597 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:18:04,753 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:18:04,753 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:18:04,754 - INFO - Agent workflow completed in 7.39s
2025-05-10 22:18:04,755 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:18:04,756 - INFO - 127.0.0.1 - - [10/May/2025 22:18:04] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:18:07,792 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:18:08,106 - INFO - Token usage: prompt=67, completion=18, total=85
2025-05-10 22:18:08,139 - INFO - Processing query: 'Quels sont les agents habilités à établir les procès-verbaux constatant les infractions?' for conversation 309
2025-05-10 22:18:08,140 - INFO - Query received: Quels sont les agents habilités à établir les procès-verbaux constatant les infractions?
2025-05-10 22:18:08,661 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4080)
2025-05-10 22:18:08,709 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:18:08,709 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:18:11,595 - INFO - Token usage: prompt=1799, completion=700, total=2499
2025-05-10 22:18:11,609 - INFO - Agent workflow completed in 3.82s
2025-05-10 22:18:11,731 - INFO - Request processed in 3.94s (thinking: 2.91s)
2025-05-10 22:18:11,731 - INFO - 127.0.0.1 - - [10/May/2025 22:18:11] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:18:21,784 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:18:22,091 - INFO - Token usage: prompt=67, completion=17, total=84
2025-05-10 22:18:22,126 - INFO - Processing query: 'Quel est le rôle des procès-verbaux dans la procédure de répression des infractions?' for conversation 310
2025-05-10 22:18:22,126 - INFO - Query received: Quel est le rôle des procès-verbaux dans la procédure de répression des infractions?
2025-05-10 22:18:22,631 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4555)
2025-05-10 22:18:22,673 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:18:22,673 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:18:22,814 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:18:22,814 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:18:25,089 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:18:25,089 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:18:29,242 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:18:29,243 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:18:29,243 - INFO - Agent workflow completed in 7.46s
2025-05-10 22:18:29,244 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:18:29,246 - INFO - 127.0.0.1 - - [10/May/2025 22:18:29] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:18:32,263 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:18:32,589 - INFO - Token usage: prompt=67, completion=17, total=84
2025-05-10 22:18:32,629 - INFO - Processing query: 'Quel est le rôle des procès-verbaux dans la procédure de répression des infractions?' for conversation 311
2025-05-10 22:18:32,631 - INFO - Query received: Quel est le rôle des procès-verbaux dans la procédure de répression des infractions?
2025-05-10 22:18:33,104 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4555)
2025-05-10 22:18:33,141 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:18:33,141 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:18:33,261 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:18:33,262 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:18:38,569 - INFO - Token usage: prompt=2120, completion=802, total=2922
2025-05-10 22:18:38,571 - INFO - Agent workflow completed in 6.31s
2025-05-10 22:18:38,606 - INFO - Request processed in 6.34s (thinking: 5.44s)
2025-05-10 22:18:38,607 - INFO - 127.0.0.1 - - [10/May/2025 22:18:38] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:18:48,656 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:18:48,990 - INFO - Token usage: prompt=75, completion=18, total=93
2025-05-10 22:18:49,027 - INFO - Processing query: 'Un régime transitoire d'autorisation d'importation est-il prévu pour certains produits, malgré les principes de liberté énoncés?' for conversation 312
2025-05-10 22:18:49,028 - INFO - Query received: Un régime transitoire d'autorisation d'importation est-il prévu pour certains produits, malgré les principes de liberté énoncés?
2025-05-10 22:18:49,543 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6122)
2025-05-10 22:18:49,597 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:18:49,597 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:18:49,705 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:18:49,705 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:18:51,828 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:18:51,828 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:18:56,023 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:18:56,023 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:18:56,024 - INFO - Agent workflow completed in 7.37s
2025-05-10 22:18:56,024 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:18:56,025 - INFO - 127.0.0.1 - - [10/May/2025 22:18:56] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:18:59,050 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:18:59,376 - INFO - Token usage: prompt=75, completion=18, total=93
2025-05-10 22:18:59,412 - INFO - Processing query: 'Un régime transitoire d'autorisation d'importation est-il prévu pour certains produits, malgré les principes de liberté énoncés?' for conversation 313
2025-05-10 22:18:59,413 - INFO - Query received: Un régime transitoire d'autorisation d'importation est-il prévu pour certains produits, malgré les principes de liberté énoncés?
2025-05-10 22:18:59,780 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.6122)
2025-05-10 22:18:59,816 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:18:59,816 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:18:59,931 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:18:59,931 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:19:05,560 - INFO - Token usage: prompt=1701, completion=895, total=2596
2025-05-10 22:19:05,568 - INFO - Agent workflow completed in 6.52s
2025-05-10 22:19:05,627 - INFO - Request processed in 6.58s (thinking: 5.75s)
2025-05-10 22:19:05,628 - INFO - 127.0.0.1 - - [10/May/2025 22:19:05] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:19:15,668 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:19:16,005 - INFO - Token usage: prompt=87, completion=18, total=105
2025-05-10 22:19:16,040 - INFO - Processing query: 'Comment la liste des produits soumis à ce régime transitoire d'autorisation d'importation est-elle fixée, et pour combien de temps ce régime s'applique-t-il?' for conversation 314
2025-05-10 22:19:16,040 - INFO - Query received: Comment la liste des produits soumis à ce régime transitoire d'autorisation d'importation est-elle fixée, et pour combien de temps ce régime s'applique-t-il?
2025-05-10 22:19:16,428 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4688)
2025-05-10 22:19:16,475 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:19:16,475 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:19:16,594 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:19:16,594 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:19:18,739 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:19:18,739 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:19:22,882 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:19:22,882 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:19:22,883 - INFO - Agent workflow completed in 7.22s
2025-05-10 22:19:22,884 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:19:22,885 - INFO - 127.0.0.1 - - [10/May/2025 22:19:22] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:19:25,910 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:19:26,300 - INFO - Token usage: prompt=87, completion=20, total=107
2025-05-10 22:19:26,329 - INFO - Processing query: 'Comment la liste des produits soumis à ce régime transitoire d'autorisation d'importation est-elle fixée, et pour combien de temps ce régime s'applique-t-il?' for conversation 315
2025-05-10 22:19:26,330 - INFO - Query received: Comment la liste des produits soumis à ce régime transitoire d'autorisation d'importation est-elle fixée, et pour combien de temps ce régime s'applique-t-il?
2025-05-10 22:19:26,748 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4688)
2025-05-10 22:19:26,794 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:19:26,794 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:19:26,946 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:19:26,946 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:19:29,079 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:19:29,079 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:19:33,224 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:19:33,224 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:19:33,225 - INFO - Agent workflow completed in 7.31s
2025-05-10 22:19:33,226 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:19:33,227 - INFO - 127.0.0.1 - - [10/May/2025 22:19:33] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:19:39,250 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:19:39,587 - INFO - Token usage: prompt=87, completion=20, total=107
2025-05-10 22:19:39,630 - INFO - Processing query: 'Comment la liste des produits soumis à ce régime transitoire d'autorisation d'importation est-elle fixée, et pour combien de temps ce régime s'applique-t-il?' for conversation 316
2025-05-10 22:19:39,630 - INFO - Query received: Comment la liste des produits soumis à ce régime transitoire d'autorisation d'importation est-elle fixée, et pour combien de temps ce régime s'applique-t-il?
2025-05-10 22:19:39,970 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.4688)
2025-05-10 22:19:40,007 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:19:40,008 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:19:44,805 - INFO - Token usage: prompt=3003, completion=1069, total=4072
2025-05-10 22:19:44,810 - INFO - Agent workflow completed in 5.56s
2025-05-10 22:19:44,835 - INFO - Request processed in 5.59s (thinking: 4.80s)
2025-05-10 22:19:44,836 - INFO - 127.0.0.1 - - [10/May/2025 22:19:44] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:19:54,886 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:19:55,207 - INFO - Token usage: prompt=71, completion=15, total=86
2025-05-10 22:19:55,243 - INFO - Processing query: 'Quelle est la raison d'être de ce régime transitoire d'autorisation d'importation pour certains produits?' for conversation 317
2025-05-10 22:19:55,244 - INFO - Query received: Quelle est la raison d'être de ce régime transitoire d'autorisation d'importation pour certains produits?
2025-05-10 22:19:55,587 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5738)
2025-05-10 22:19:55,617 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:19:55,617 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:19:55,722 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:19:55,722 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:19:57,875 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:19:57,875 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:20:01,995 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:20:01,995 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:20:01,996 - INFO - Agent workflow completed in 7.11s
2025-05-10 22:20:01,996 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:20:01,997 - INFO - 127.0.0.1 - - [10/May/2025 22:20:01] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:20:05,027 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:20:05,406 - INFO - Token usage: prompt=71, completion=17, total=88
2025-05-10 22:20:05,440 - INFO - Processing query: 'Quelle est la raison d'être de ce régime transitoire d'autorisation d'importation pour certains produits?' for conversation 318
2025-05-10 22:20:05,441 - INFO - Query received: Quelle est la raison d'être de ce régime transitoire d'autorisation d'importation pour certains produits?
2025-05-10 22:20:05,844 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5738)
2025-05-10 22:20:05,882 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:20:05,882 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:20:08,672 - INFO - Token usage: prompt=1494, completion=675, total=2169
2025-05-10 22:20:08,679 - INFO - Agent workflow completed in 3.65s
2025-05-10 22:20:08,706 - INFO - Request processed in 3.68s (thinking: 2.80s)
2025-05-10 22:20:08,707 - INFO - 127.0.0.1 - - [10/May/2025 22:20:08] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:20:18,735 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:20:19,055 - INFO - Token usage: prompt=67, completion=10, total=77
2025-05-10 22:20:19,089 - INFO - Processing query: 'À partir de quelle date les dispositions de la présente loi entrent-elles en vigueur?' for conversation 319
2025-05-10 22:20:19,090 - INFO - Query received: À partir de quelle date les dispositions de la présente loi entrent-elles en vigueur?
2025-05-10 22:20:19,490 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4006)
2025-05-10 22:20:19,532 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:20:19,532 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:20:19,637 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:20:19,637 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:20:21,780 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:20:21,781 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:20:25,931 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:20:25,931 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:20:25,932 - INFO - Agent workflow completed in 7.20s
2025-05-10 22:20:25,933 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:20:25,934 - INFO - 127.0.0.1 - - [10/May/2025 22:20:25] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:20:28,945 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:20:29,276 - INFO - Token usage: prompt=67, completion=10, total=77
2025-05-10 22:20:29,308 - INFO - Processing query: 'À partir de quelle date les dispositions de la présente loi entrent-elles en vigueur?' for conversation 320
2025-05-10 22:20:29,310 - INFO - Query received: À partir de quelle date les dispositions de la présente loi entrent-elles en vigueur?
2025-05-10 22:20:29,747 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4006)
2025-05-10 22:20:29,793 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:20:29,793 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:20:32,075 - INFO - Token usage: prompt=1549, completion=495, total=2044
2025-05-10 22:20:32,079 - INFO - Agent workflow completed in 3.13s
2025-05-10 22:20:32,102 - INFO - Request processed in 3.16s (thinking: 2.29s)
2025-05-10 22:20:32,102 - INFO - 127.0.0.1 - - [10/May/2025 22:20:32] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:20:42,142 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:20:42,475 - INFO - Token usage: prompt=68, completion=14, total=82
2025-05-10 22:20:42,508 - INFO - Processing query: 'Quelles sont les conséquences de l'entrée en vigueur de cette loi sur les dispositions antérieures?' for conversation 321
2025-05-10 22:20:42,509 - INFO - Query received: Quelles sont les conséquences de l'entrée en vigueur de cette loi sur les dispositions antérieures?
2025-05-10 22:20:42,849 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5122)
2025-05-10 22:20:42,882 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:20:42,882 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:20:42,987 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:20:42,987 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:20:45,108 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:20:45,108 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:20:49,228 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:20:49,228 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:20:49,229 - INFO - Agent workflow completed in 7.09s
2025-05-10 22:20:49,229 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:20:49,230 - INFO - 127.0.0.1 - - [10/May/2025 22:20:49] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:20:52,250 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:20:52,607 - INFO - Token usage: prompt=68, completion=14, total=82
2025-05-10 22:20:52,642 - INFO - Processing query: 'Quelles sont les conséquences de l'entrée en vigueur de cette loi sur les dispositions antérieures?' for conversation 322
2025-05-10 22:20:52,643 - INFO - Query received: Quelles sont les conséquences de l'entrée en vigueur de cette loi sur les dispositions antérieures?
2025-05-10 22:20:53,161 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.5122)
2025-05-10 22:20:53,217 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:20:53,217 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:20:55,785 - INFO - Token usage: prompt=2099, completion=353, total=2452
2025-05-10 22:20:55,794 - INFO - Agent workflow completed in 3.54s
2025-05-10 22:20:55,823 - INFO - Request processed in 3.57s (thinking: 2.58s)
2025-05-10 22:20:55,824 - INFO - 127.0.0.1 - - [10/May/2025 22:20:55] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:21:05,859 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:21:06,163 - INFO - Token usage: prompt=69, completion=13, total=82
2025-05-10 22:21:06,205 - INFO - Processing query: 'Quels textes législatifs spécifiques sont notamment abrogés par l'entrée en vigueur de cette loi?' for conversation 323
2025-05-10 22:21:06,207 - INFO - Query received: Quels textes législatifs spécifiques sont notamment abrogés par l'entrée en vigueur de cette loi?
2025-05-10 22:21:06,899 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5665)
2025-05-10 22:21:06,965 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:21:06,965 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:21:07,092 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:21:07,092 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:21:09,248 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:21:09,248 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:21:13,406 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:21:13,407 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:21:13,408 - INFO - Agent workflow completed in 7.55s
2025-05-10 22:21:13,408 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:21:13,409 - INFO - 127.0.0.1 - - [10/May/2025 22:21:13] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:21:16,431 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:21:16,738 - INFO - Token usage: prompt=69, completion=14, total=83
2025-05-10 22:21:16,780 - INFO - Processing query: 'Quels textes législatifs spécifiques sont notamment abrogés par l'entrée en vigueur de cette loi?' for conversation 324
2025-05-10 22:21:16,782 - INFO - Query received: Quels textes législatifs spécifiques sont notamment abrogés par l'entrée en vigueur de cette loi?
2025-05-10 22:21:17,389 - INFO - Routing query to code: loi_relative_commerce_exterieur (similarity: 0.5665)
2025-05-10 22:21:17,444 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:21:17,444 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:21:19,794 - INFO - Token usage: prompt=1854, completion=537, total=2391
2025-05-10 22:21:19,805 - INFO - Agent workflow completed in 3.37s
2025-05-10 22:21:19,849 - INFO - Request processed in 3.42s (thinking: 2.37s)
2025-05-10 22:21:19,850 - INFO - 127.0.0.1 - - [10/May/2025 22:21:19] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:21:29,918 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:21:30,245 - INFO - Token usage: prompt=67, completion=12, total=79
2025-05-10 22:21:30,288 - INFO - Processing query: 'À partir de quelle date une société commerciale acquiert-elle la personnalité morale en Tunisie ?' for conversation 325
2025-05-10 22:21:30,290 - INFO - Query received: À partir de quelle date une société commerciale acquiert-elle la personnalité morale en Tunisie ?
2025-05-10 22:21:30,919 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5751)
2025-05-10 22:21:30,971 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:21:30,971 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:21:31,082 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:21:31,082 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:21:33,272 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:21:33,272 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:21:40,844 - INFO - Token usage: prompt=1550, completion=889, total=2439
2025-05-10 22:21:40,849 - INFO - Agent workflow completed in 10.93s
2025-05-10 22:21:40,899 - INFO - Request processed in 10.98s (thinking: 9.88s)
2025-05-10 22:21:40,901 - INFO - 127.0.0.1 - - [10/May/2025 22:21:40] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:21:50,954 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:21:51,280 - INFO - Token usage: prompt=77, completion=22, total=99
2025-05-10 22:21:51,313 - INFO - Processing query: 'Une société commerciale en Tunisie dont le capital social n’est pas totalement libéré peut-elle émettre des titres d’emprunt ?' for conversation 326
2025-05-10 22:21:51,315 - INFO - Query received: Une société commerciale en Tunisie dont le capital social n’est pas totalement libéré peut-elle émettre des titres d’emprunt ?
2025-05-10 22:21:51,836 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6404)
2025-05-10 22:21:51,897 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:21:51,897 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:21:52,011 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:21:52,011 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:21:54,131 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:21:54,131 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:21:58,252 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:21:58,252 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:21:58,254 - INFO - Agent workflow completed in 7.30s
2025-05-10 22:21:58,254 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:21:58,256 - INFO - 127.0.0.1 - - [10/May/2025 22:21:58] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:22:01,285 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:22:01,600 - INFO - Token usage: prompt=77, completion=23, total=100
2025-05-10 22:22:01,636 - INFO - Processing query: 'Une société commerciale en Tunisie dont le capital social n’est pas totalement libéré peut-elle émettre des titres d’emprunt ?' for conversation 327
2025-05-10 22:22:01,638 - INFO - Query received: Une société commerciale en Tunisie dont le capital social n’est pas totalement libéré peut-elle émettre des titres d’emprunt ?
2025-05-10 22:22:02,220 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.6404)
2025-05-10 22:22:02,271 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:22:02,271 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:22:05,046 - INFO - Token usage: prompt=1560, completion=670, total=2230
2025-05-10 22:22:05,054 - INFO - Agent workflow completed in 3.77s
2025-05-10 22:22:05,111 - INFO - Request processed in 3.83s (thinking: 2.79s)
2025-05-10 22:22:05,113 - INFO - 127.0.0.1 - - [10/May/2025 22:22:05] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:22:15,159 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:22:15,482 - INFO - Token usage: prompt=70, completion=15, total=85
2025-05-10 22:22:15,511 - INFO - Processing query: 'Comment se calculent les droits de vote d’un associé et peut-il déléguer son vote ?' for conversation 328
2025-05-10 22:22:15,512 - INFO - Query received: Comment se calculent les droits de vote d’un associé et peut-il déléguer son vote ?
2025-05-10 22:22:15,921 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3164)
2025-05-10 22:22:15,960 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:22:15,960 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:22:16,063 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:22:16,063 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:22:18,207 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:22:18,207 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:22:22,351 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:22:22,351 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:22:22,352 - INFO - Agent workflow completed in 7.19s
2025-05-10 22:22:22,353 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:22:22,354 - INFO - 127.0.0.1 - - [10/May/2025 22:22:22] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:22:25,382 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:22:25,698 - INFO - Token usage: prompt=70, completion=13, total=83
2025-05-10 22:22:25,729 - INFO - Processing query: 'Comment se calculent les droits de vote d’un associé et peut-il déléguer son vote ?' for conversation 329
2025-05-10 22:22:25,730 - INFO - Query received: Comment se calculent les droits de vote d’un associé et peut-il déléguer son vote ?
2025-05-10 22:22:26,107 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3164)
2025-05-10 22:22:26,149 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:22:26,149 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:22:36,353 - INFO - Token usage: prompt=1550, completion=626, total=2176
2025-05-10 22:22:36,357 - INFO - Agent workflow completed in 10.98s
2025-05-10 22:22:36,379 - INFO - Request processed in 11.00s (thinking: 10.21s)
2025-05-10 22:22:36,380 - INFO - 127.0.0.1 - - [10/May/2025 22:22:36] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:22:46,409 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:22:46,763 - INFO - Token usage: prompt=83, completion=28, total=111
2025-05-10 22:22:46,795 - INFO - Processing query: 'La société à responsabilité limitée peut-elle être dissoute par le décès, le redressement judiciaire, la faillite ou la perte de capacité d’un associé ?' for conversation 330
2025-05-10 22:22:46,796 - INFO - Query received: La société à responsabilité limitée peut-elle être dissoute par le décès, le redressement judiciaire, la faillite ou la perte de capacité d’un associé ?
2025-05-10 22:22:47,165 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4863)
2025-05-10 22:22:47,213 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:22:47,213 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:22:51,894 - INFO - Token usage: prompt=1570, completion=1197, total=2767
2025-05-10 22:22:51,899 - INFO - Agent workflow completed in 5.49s
2025-05-10 22:22:51,935 - INFO - Request processed in 5.53s (thinking: 4.69s)
2025-05-10 22:22:51,936 - INFO - 127.0.0.1 - - [10/May/2025 22:22:51] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:23:01,968 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:23:02,331 - INFO - Token usage: prompt=78, completion=25, total=103
2025-05-10 22:23:02,364 - INFO - Processing query: 'Qu’est-ce qu’une société unipersonnelle à responsabilité limitée selon l’article 150 du code tunisien ?' for conversation 331
2025-05-10 22:23:02,365 - INFO - Query received: Qu’est-ce qu’une société unipersonnelle à responsabilité limitée selon l’article 150 du code tunisien ?
2025-05-10 22:23:02,730 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.7633)
2025-05-10 22:23:02,766 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:23:02,766 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:23:02,879 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:23:02,879 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:23:05,067 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:23:05,067 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:23:09,232 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:23:09,233 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:23:09,234 - INFO - Agent workflow completed in 7.27s
2025-05-10 22:23:09,234 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:23:09,235 - INFO - 127.0.0.1 - - [10/May/2025 22:23:09] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:23:12,243 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:23:12,606 - INFO - Token usage: prompt=78, completion=27, total=105
2025-05-10 22:23:12,641 - INFO - Processing query: 'Qu’est-ce qu’une société unipersonnelle à responsabilité limitée selon l’article 150 du code tunisien ?' for conversation 332
2025-05-10 22:23:12,641 - INFO - Query received: Qu’est-ce qu’une société unipersonnelle à responsabilité limitée selon l’article 150 du code tunisien ?
2025-05-10 22:23:12,984 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.7633)
2025-05-10 22:23:13,025 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:23:13,026 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:23:16,717 - INFO - Token usage: prompt=1555, completion=772, total=2327
2025-05-10 22:23:16,722 - INFO - Agent workflow completed in 4.48s
2025-05-10 22:23:16,759 - INFO - Request processed in 4.52s (thinking: 3.70s)
2025-05-10 22:23:16,759 - INFO - 127.0.0.1 - - [10/May/2025 22:23:16] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:23:26,786 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:23:27,129 - INFO - Token usage: prompt=75, completion=24, total=99
2025-05-10 22:23:27,170 - INFO - Processing query: 'Que prévoit le code des sociétés commerciales en cas d'empêchement temporaire ou de décès du Président du conseil d’administration ?' for conversation 333
2025-05-10 22:23:27,171 - INFO - Query received: Que prévoit le code des sociétés commerciales en cas d'empêchement temporaire ou de décès du Président du conseil d’administration ?
2025-05-10 22:23:27,551 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5288)
2025-05-10 22:23:27,605 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:23:27,605 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:23:27,715 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:23:27,715 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:23:29,836 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:23:29,836 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:23:33,973 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:23:33,973 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:23:33,974 - INFO - Agent workflow completed in 7.19s
2025-05-10 22:23:33,974 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:23:33,975 - INFO - 127.0.0.1 - - [10/May/2025 22:23:33] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:23:36,993 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:23:37,344 - INFO - Token usage: prompt=75, completion=26, total=101
2025-05-10 22:23:37,383 - INFO - Processing query: 'Que prévoit le code des sociétés commerciales en cas d'empêchement temporaire ou de décès du Président du conseil d’administration ?' for conversation 334
2025-05-10 22:23:37,384 - INFO - Query received: Que prévoit le code des sociétés commerciales en cas d'empêchement temporaire ou de décès du Président du conseil d’administration ?
2025-05-10 22:23:37,747 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5288)
2025-05-10 22:23:37,787 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:23:37,787 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:23:40,036 - INFO - Token usage: prompt=1566, completion=528, total=2094
2025-05-10 22:23:40,039 - INFO - Agent workflow completed in 3.05s
2025-05-10 22:23:40,064 - INFO - Request processed in 3.07s (thinking: 2.26s)
2025-05-10 22:23:40,064 - INFO - 127.0.0.1 - - [10/May/2025 22:23:40] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:23:50,105 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:23:50,423 - INFO - Token usage: prompt=63, completion=12, total=75
2025-05-10 22:23:50,456 - INFO - Processing query: 'Quelles conditions doivent être remplies avant l'émission de nouvelles actions ?' for conversation 335
2025-05-10 22:23:50,457 - INFO - Query received: Quelles conditions doivent être remplies avant l'émission de nouvelles actions ?
2025-05-10 22:23:50,815 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4354)
2025-05-10 22:23:50,848 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:23:50,848 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:23:50,955 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:23:50,955 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:23:53,105 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:23:53,106 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:24:02,485 - INFO - Token usage: prompt=1543, completion=809, total=2352
2025-05-10 22:24:02,489 - INFO - Agent workflow completed in 12.39s
2025-05-10 22:24:02,521 - INFO - Request processed in 12.42s (thinking: 11.64s)
2025-05-10 22:24:02,521 - INFO - 127.0.0.1 - - [10/May/2025 22:24:02] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:24:12,559 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:24:12,890 - INFO - Token usage: prompt=70, completion=19, total=89
2025-05-10 22:24:12,923 - INFO - Processing query: 'Quelles informations doivent être fournies aux souscripteurs en cas d'appel public à l'épargne ?' for conversation 336
2025-05-10 22:24:12,923 - INFO - Query received: Quelles informations doivent être fournies aux souscripteurs en cas d'appel public à l'épargne ?
2025-05-10 22:24:13,362 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4113)
2025-05-10 22:24:13,405 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:24:13,405 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:24:13,518 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:24:13,519 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:24:15,663 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:24:15,663 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:24:19,821 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:24:19,821 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:24:19,822 - INFO - Agent workflow completed in 7.26s
2025-05-10 22:24:19,822 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:24:19,824 - INFO - 127.0.0.1 - - [10/May/2025 22:24:19] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:24:22,837 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:24:23,173 - INFO - Token usage: prompt=70, completion=23, total=93
2025-05-10 22:24:23,207 - INFO - Processing query: 'Quelles informations doivent être fournies aux souscripteurs en cas d'appel public à l'épargne ?' for conversation 337
2025-05-10 22:24:23,208 - INFO - Query received: Quelles informations doivent être fournies aux souscripteurs en cas d'appel public à l'épargne ?
2025-05-10 22:24:23,578 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.4113)
2025-05-10 22:24:23,610 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:24:23,611 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:24:26,223 - INFO - Token usage: prompt=1552, completion=591, total=2143
2025-05-10 22:24:26,226 - INFO - Agent workflow completed in 3.39s
2025-05-10 22:24:26,252 - INFO - Request processed in 3.41s (thinking: 2.62s)
2025-05-10 22:24:26,253 - INFO - 127.0.0.1 - - [10/May/2025 22:24:26] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:24:36,293 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:24:36,615 - INFO - Token usage: prompt=69, completion=20, total=89
2025-05-10 22:24:36,640 - INFO - Processing query: 'La société émettrice peut-elle imposer un remboursement anticipé des obligations aux obligataires ?' for conversation 338
2025-05-10 22:24:36,643 - INFO - Query received: La société émettrice peut-elle imposer un remboursement anticipé des obligations aux obligataires ?
2025-05-10 22:24:37,038 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.2798)
2025-05-10 22:24:37,089 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:24:37,089 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:24:37,273 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:24:37,273 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:24:39,424 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:24:39,425 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:24:45,613 - INFO - Token usage: prompt=1552, completion=507, total=2059
2025-05-10 22:24:45,618 - INFO - Agent workflow completed in 9.33s
2025-05-10 22:24:45,645 - INFO - Request processed in 9.35s (thinking: 8.54s)
2025-05-10 22:24:45,646 - INFO - 127.0.0.1 - - [10/May/2025 22:24:45] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:24:55,683 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:24:56,016 - INFO - Token usage: prompt=64, completion=20, total=84
2025-05-10 22:24:56,049 - INFO - Processing query: 'Que statue l'assemblée générale spéciale et qui est lié par ses décisions ?' for conversation 339
2025-05-10 22:24:56,050 - INFO - Query received: Que statue l'assemblée générale spéciale et qui est lié par ses décisions ?
2025-05-10 22:24:56,445 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3227)
2025-05-10 22:24:56,485 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:24:56,486 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:24:56,643 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:24:56,643 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:24:58,773 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:24:58,773 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:25:05,782 - INFO - Token usage: prompt=1549, completion=712, total=2261
2025-05-10 22:25:05,788 - INFO - Agent workflow completed in 10.11s
2025-05-10 22:25:05,818 - INFO - Request processed in 10.13s (thinking: 9.30s)
2025-05-10 22:25:05,818 - INFO - 127.0.0.1 - - [10/May/2025 22:25:05] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:25:15,847 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:25:16,444 - INFO - Token usage: prompt=63, completion=16, total=79
2025-05-10 22:25:16,475 - INFO - Processing query: 'Que peut décider l’assemblée générale extraordinaire d’une société anonyme ?' for conversation 340
2025-05-10 22:25:16,476 - INFO - Query received: Que peut décider l’assemblée générale extraordinaire d’une société anonyme ?
2025-05-10 22:25:16,834 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5218)
2025-05-10 22:25:16,864 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:25:16,864 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:25:17,004 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:25:17,004 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:25:19,216 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:25:19,217 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:25:23,351 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:25:23,351 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:25:23,352 - INFO - Agent workflow completed in 7.50s
2025-05-10 22:25:23,352 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:25:23,353 - INFO - 127.0.0.1 - - [10/May/2025 22:25:23] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:25:26,379 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:25:26,724 - INFO - Token usage: prompt=63, completion=17, total=80
2025-05-10 22:25:26,764 - INFO - Processing query: 'Que peut décider l’assemblée générale extraordinaire d’une société anonyme ?' for conversation 341
2025-05-10 22:25:26,765 - INFO - Query received: Que peut décider l’assemblée générale extraordinaire d’une société anonyme ?
2025-05-10 22:25:27,111 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5218)
2025-05-10 22:25:27,143 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:25:27,143 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:25:29,569 - INFO - Token usage: prompt=1548, completion=569, total=2117
2025-05-10 22:25:29,575 - INFO - Agent workflow completed in 3.20s
2025-05-10 22:25:29,602 - INFO - Request processed in 3.22s (thinking: 2.43s)
2025-05-10 22:25:29,603 - INFO - 127.0.0.1 - - [10/May/2025 22:25:29] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:25:39,640 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:25:39,988 - INFO - Token usage: prompt=67, completion=15, total=82
2025-05-10 22:25:40,027 - INFO - Processing query: 'Quelles règles s’appliquent à la dissolution de la société en commandite par actions ?' for conversation 342
2025-05-10 22:25:40,027 - INFO - Query received: Quelles règles s’appliquent à la dissolution de la société en commandite par actions ?
2025-05-10 22:25:40,376 - INFO - Routing query to code: texte_code_societes_commerciales (similarity: 0.5297)
2025-05-10 22:25:40,414 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:25:40,415 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:25:40,561 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:25:40,561 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:25:42,684 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:25:42,684 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:25:49,992 - INFO - Token usage: prompt=1410, completion=796, total=2206
2025-05-10 22:25:49,995 - INFO - Agent workflow completed in 10.36s
2025-05-10 22:25:50,038 - INFO - Request processed in 10.40s (thinking: 9.58s)
2025-05-10 22:25:50,038 - INFO - 127.0.0.1 - - [10/May/2025 22:25:50] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:26:00,079 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:26:00,410 - INFO - Token usage: prompt=75, completion=13, total=88
2025-05-10 22:26:00,445 - INFO - Processing query: 'À quelles règles est soumise la fusion entre sociétés privées et entreprises publiques ou les sociétés faisant appel public à l’épargne ?' for conversation 343
2025-05-10 22:26:00,446 - INFO - Query received: À quelles règles est soumise la fusion entre sociétés privées et entreprises publiques ou les sociétés faisant appel public à l’épargne ?
2025-05-10 22:26:00,792 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5537)
2025-05-10 22:26:00,829 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:26:00,829 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:26:00,980 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:26:00,981 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:26:03,134 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:26:03,134 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:26:07,280 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:26:07,280 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:26:07,281 - INFO - Agent workflow completed in 7.20s
2025-05-10 22:26:07,282 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:26:07,283 - INFO - 127.0.0.1 - - [10/May/2025 22:26:07] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:26:10,298 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:26:10,623 - INFO - Token usage: prompt=75, completion=13, total=88
2025-05-10 22:26:10,653 - INFO - Processing query: 'À quelles règles est soumise la fusion entre sociétés privées et entreprises publiques ou les sociétés faisant appel public à l’épargne ?' for conversation 344
2025-05-10 22:26:10,655 - INFO - Query received: À quelles règles est soumise la fusion entre sociétés privées et entreprises publiques ou les sociétés faisant appel public à l’épargne ?
2025-05-10 22:26:11,116 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.5537)
2025-05-10 22:26:11,156 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:26:11,156 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:26:13,705 - INFO - Token usage: prompt=1564, completion=605, total=2169
2025-05-10 22:26:13,709 - INFO - Agent workflow completed in 3.41s
2025-05-10 22:26:13,735 - INFO - Request processed in 3.44s (thinking: 2.56s)
2025-05-10 22:26:13,735 - INFO - 127.0.0.1 - - [10/May/2025 22:26:13] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:26:23,766 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:26:24,095 - INFO - Token usage: prompt=62, completion=14, total=76
2025-05-10 22:26:24,130 - INFO - Processing query: 'Quelles sont les conséquences de l'annulation d'une fusion ?' for conversation 345
2025-05-10 22:26:24,131 - INFO - Query received: Quelles sont les conséquences de l'annulation d'une fusion ?
2025-05-10 22:26:24,492 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.2545)
2025-05-10 22:26:24,525 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:26:24,525 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:26:24,645 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:26:24,645 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:26:26,787 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:26:26,787 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:26:30,939 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:26:30,939 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:26:30,941 - INFO - Agent workflow completed in 7.18s
2025-05-10 22:26:30,941 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:26:30,943 - INFO - 127.0.0.1 - - [10/May/2025 22:26:30] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:26:33,965 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:26:34,288 - INFO - Token usage: prompt=62, completion=14, total=76
2025-05-10 22:26:34,326 - INFO - Processing query: 'Quelles sont les conséquences de l'annulation d'une fusion ?' for conversation 346
2025-05-10 22:26:34,326 - INFO - Query received: Quelles sont les conséquences de l'annulation d'une fusion ?
2025-05-10 22:26:34,633 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.2545)
2025-05-10 22:26:34,662 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:26:34,662 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:26:34,828 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:26:34,828 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:26:37,090 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:26:37,090 - WARNING - Rate limited. Waiting 4s before retry.
2025-05-10 22:26:41,231 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:26:41,231 - ERROR - Error generating answer: Failed to get response from Groq API after 3 attempts: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions
2025-05-10 22:26:41,232 - INFO - Agent workflow completed in 7.27s
2025-05-10 22:26:41,233 - ERROR - Exception on /ask [POST]
Traceback (most recent call last):
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\chtar\AppData\Local\Programs\Python\Python310\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "c:\Users\chtar\Desktop\bouba - rang fusion\app.py", line 1649, in ask
    add_message(conversation_id, "assistant", assistant_html)
UnboundLocalError: local variable 'assistant_html' referenced before assignment
2025-05-10 22:26:41,235 - INFO - 127.0.0.1 - - [10/May/2025 22:26:41] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2025-05-10 22:26:47,253 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:26:47,633 - INFO - Token usage: prompt=62, completion=14, total=76
2025-05-10 22:26:47,671 - INFO - Processing query: 'Quelles sont les conséquences de l'annulation d'une fusion ?' for conversation 347
2025-05-10 22:26:47,672 - INFO - Query received: Quelles sont les conséquences de l'annulation d'une fusion ?
2025-05-10 22:26:47,973 - INFO - Routing query to code: loi_defense_contre_pratiques_deloyales_importation (similarity: 0.2545)
2025-05-10 22:26:48,005 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:26:48,005 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:26:49,539 - INFO - Token usage: prompt=2858, completion=277, total=3135
2025-05-10 22:26:49,546 - INFO - Agent workflow completed in 2.29s
2025-05-10 22:26:49,565 - INFO - Request processed in 2.31s (thinking: 1.54s)
2025-05-10 22:26:49,566 - INFO - 127.0.0.1 - - [10/May/2025 22:26:49] "POST /ask HTTP/1.1" 200 -
2025-05-10 22:26:59,606 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-10 22:27:00,158 - INFO - Token usage: prompt=60, completion=11, total=71
2025-05-10 22:27:00,189 - INFO - Processing query: 'Quelle instance prend la décision de transformation de la société ?' for conversation 348
2025-05-10 22:27:00,191 - INFO - Query received: Quelle instance prend la décision de transformation de la société ?
2025-05-10 22:27:00,568 - INFO - Routing query to code: loi_societes_ligne (similarity: 0.3414)
2025-05-10 22:27:00,597 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-10 22:27:00,597 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-10 22:27:00,708 - ERROR - HTTP error occurred: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions (Status code: 429)
2025-05-10 22:27:00,708 - WARNING - Rate limited. Waiting 2s before retry.
2025-05-10 22:27:05,019 - INFO - Token usage: prompt=1541, completion=495, total=2036
2025-05-10 22:27:05,023 - INFO - Agent workflow completed in 5.42s
2025-05-10 22:27:05,045 - INFO - Request processed in 5.44s (thinking: 4.43s)
2025-05-10 22:27:05,045 - INFO - 127.0.0.1 - - [10/May/2025 22:27:05] "POST /ask HTTP/1.1" 200 -
2025-05-11 15:56:46,987 - INFO - Use pytorch device_name: cpu
2025-05-11 15:56:46,987 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-11 15:56:53,001 - INFO - Source file D:\projet_sem2\malek_chedli\bouba-main\legal_codes\loi_defense_contre_pratiques_deloyales_importation.txt modified. Rebuild needed.
2025-05-11 15:56:53,008 - INFO - Use pytorch device_name: cpu
2025-05-11 15:56:53,008 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-11 15:57:22,566 - INFO - Saved build metadata to D:\projet_sem2\malek_chedli\bouba-main\stores\build_metadata.json
2025-05-11 15:57:22,587 - INFO - Use pytorch device_name: cpu
2025-05-11 15:57:22,587 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
2025-05-11 15:57:25,407 - INFO - Loading code-specific vector stores from stores...
2025-05-11 15:57:25,407 - INFO - Using langchain_community.vectorstores FAISS
2025-05-11 15:57:25,425 - INFO - Loaded FAISS store for loi_defense_contre_pratiques_deloyales_importation
2025-05-11 15:57:25,435 - INFO - Loaded BM25 index for loi_defense_contre_pratiques_deloyales_importation
2025-05-11 15:57:25,435 - INFO - Using langchain_community.vectorstores FAISS
2025-05-11 15:57:25,451 - INFO - Loaded FAISS store for loi_relative_commerce_exterieur
2025-05-11 15:57:25,458 - INFO - Loaded BM25 index for loi_relative_commerce_exterieur
2025-05-11 15:57:25,458 - INFO - Using langchain_community.vectorstores FAISS
2025-05-11 15:57:25,471 - INFO - Loaded FAISS store for loi_relative_Startups
2025-05-11 15:57:25,479 - INFO - Loaded BM25 index for loi_relative_Startups
2025-05-11 15:57:25,480 - INFO - Using langchain_community.vectorstores FAISS
2025-05-11 15:57:25,492 - INFO - Loaded FAISS store for loi_societes_commerce_international
2025-05-11 15:57:25,500 - INFO - Loaded BM25 index for loi_societes_commerce_international
2025-05-11 15:57:25,500 - INFO - Using langchain_community.vectorstores FAISS
2025-05-11 15:57:25,512 - INFO - Loaded FAISS store for loi_societes_ligne
2025-05-11 15:57:25,514 - INFO - Loaded BM25 index for loi_societes_ligne
2025-05-11 15:57:25,514 - INFO - Using langchain_community.vectorstores FAISS
2025-05-11 15:57:25,529 - INFO - Loaded FAISS store for texte_code_societes_commerciales
2025-05-11 15:57:25,559 - INFO - Loaded BM25 index for texte_code_societes_commerciales
2025-05-11 15:57:25,559 - INFO - Initialization complete:
2025-05-11 15:57:25,559 - INFO - Loaded 6 FAISS stores: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-11 15:57:25,559 - INFO - Loaded 6 BM25 indexes: loi_defense_contre_pratiques_deloyales_importation, loi_relative_commerce_exterieur, loi_relative_Startups, loi_societes_commerce_international, loi_societes_ligne, texte_code_societes_commerciales
2025-05-11 15:57:25,579 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.16.1.235:5000
2025-05-11 15:57:25,579 - INFO - [33mPress CTRL+C to quit[0m
2025-05-11 15:57:54,819 - INFO - 127.0.0.1 - - [11/May/2025 15:57:54] "GET / HTTP/1.1" 200 -
2025-05-11 15:57:54,834 - INFO - 127.0.0.1 - - [11/May/2025 15:57:54] "GET /js/article_popup.js HTTP/1.1" 200 -
2025-05-11 15:57:54,898 - INFO - 127.0.0.1 - - [11/May/2025 15:57:54] "GET /get_conversations HTTP/1.1" 200 -
2025-05-11 15:57:54,964 - INFO - 127.0.0.1 - - [11/May/2025 15:57:54] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-05-11 15:57:58,802 - INFO - Sending request to Groq API: model=gemma2-9b-it, temperature=0.7, max_tokens=1000
2025-05-11 15:57:59,578 - INFO - Token usage: prompt=60, completion=11, total=71
2025-05-11 15:57:59,831 - INFO - Processing query: 'What are the requirements for starting a business in Tunisia?' for conversation 349
2025-05-11 15:57:59,834 - INFO - Query received: What are the requirements for starting a business in Tunisia?
2025-05-11 15:58:01,748 - INFO - Routing query to code: loi_societes_commerce_international (similarity: 0.6663)
2025-05-11 15:58:01,806 - INFO - Sending request to Groq API with model: deepseek-r1-distill-llama-70b
2025-05-11 15:58:01,807 - INFO - Sending request to Groq API: model=deepseek-r1-distill-llama-70b, temperature=0.1, max_tokens=2048
2025-05-11 15:58:05,766 - INFO - Token usage: prompt=2328, completion=679, total=3007
2025-05-11 15:58:05,772 - INFO - Agent workflow completed in 6.97s
2025-05-11 15:58:05,972 - INFO - Request processed in 7.17s (thinking: 3.97s)
2025-05-11 15:58:05,973 - INFO - 127.0.0.1 - - [11/May/2025 15:58:05] "POST /ask HTTP/1.1" 200 -
